{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlb_tools.nwb_interface import NWBDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "\n",
    "from Area2_analysis.lr_funcs import angle_between, pred_with_new_weights\n",
    "from Area2_analysis.lr_funcs import nans, fit_and_predict, gaussian_filter1d_oneside\n",
    "from Area2_analysis.lr_funcs import sub_and_predict,calc_proj,get_sses_mean, get_sses_pred\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib\n",
    "matplotlib.rc('font', size=18)\n",
    "\n",
    "# import importlib\n",
    "# import Area2_analysis.lr_funcs\n",
    "# importlib.reload(Area2_analysis.lr_funcs)\n",
    "# from Area2_analysis.lr_funcs import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(0.0,x)\n",
    "thresh = 7\n",
    "x = np.array(range(20))\n",
    "x_inh = relu(x-5)\n",
    "y = relu(x-thresh)\n",
    "y_inh = relu(x_inh - thresh)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.plot(y,color ='red')\n",
    "plt.plot(y_inh,color ='k')\n",
    "plt.xlabel('Time')\n",
    "plt.legend(['No Inhibition','Inhibition'])\n",
    "plt.tight_layout()\n",
    "figDir = '/Users/sherryan/area2_population_analysis/figures_plus/'\n",
    "plt.savefig(figDir + 'relu.pdf', dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = \"~/area2_population_analysis/s1-kinematics/actpas_NWB/\"\n",
    "# monkey = \"Han_20171207\"\n",
    "# filename = foldername + monkey + \"_COactpas_TD.nwb\"\n",
    "\n",
    "# monkey = \"Chips_20170913\"\n",
    "# filename = foldername + monkey + \"_COactpas_TD.nwb\"\n",
    "\n",
    "monkey = 'Duncan_20190710'\n",
    "filename = foldername + monkey + \"_COactpas_reformat.nwb\"\n",
    "\n",
    "dataset_10ms = NWBDataset(filename, split_heldout=False)\n",
    "\n",
    "dataset_10ms.resample(10) #in 10-ms bin, has to resample first to avoid NaNs\n",
    "bin_width = dataset_10ms.bin_width\n",
    "print(bin_width)\n",
    "\n",
    "# speed = np.sqrt(np.sum(dataset_10ms.data['hand_vel'][:].T**2,axis=0)).to_numpy().reshape((-1,1))\n",
    "# dataset_10ms.add_continuous_data(speed,'speed')\n",
    "# acceleration = np.diff(speed, axis = 0, prepend=[speed[0]])\n",
    "# dataset_10ms.add_continuous_data(acceleration,'acceleration') #technically change of speed, for timing plots\n",
    "\n",
    "xy_vel = dataset_10ms.data['hand_vel'].to_numpy()\n",
    "# xy_acc = np.diff(xy_vel, axis = 0, prepend=[xy_vel[0]])\n",
    "# dataset_10ms.add_continuous_data(xy_acc,'hand_acc',chan_names = ['x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xyz_force = np.array([dataset_5ms.data['force']['x'].to_numpy(), dataset_5ms.data['force']['y'].to_numpy(), dataset_5ms.data['force']['z'].to_numpy()]).T\n",
    "# dataset_5ms.add_continuous_data(xyz_force,'manip_force',chan_names = ['x','y','z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_20ms = NWBDataset(filename, split_heldout=False)\n",
    "# xy_vel = dataset_20ms.data['hand_vel'].to_numpy()\n",
    "# xy_acc = np.diff(xy_vel, axis = 0, prepend=[xy_vel[0]])\n",
    "# dataset_20ms.add_continuous_data(xy_acc,'hand_acc',chan_names = ['x','y'])\n",
    "# # vel_acc = np.append(xy_vel, xy_acc, axis = 1)\n",
    "# # dataset_20ms.add_continuous_data(vel_acc,'vel_acc')\n",
    "# dataset_20ms.resample(20)\n",
    "# bin_width = dataset_20ms.bin_width\n",
    "# print(bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_10ms.smooth_spk(40, name='smth_40')\n",
    "n_dims = 20 # for PCA\n",
    "\n",
    "# trial_mask = active_mask\n",
    "n_trials = dataset_10ms.trial_info.shape[0]\n",
    "print(n_trials,'total trials')\n",
    "n_neurons = dataset_10ms.data.spikes.shape[1]\n",
    "print(n_neurons,'neurons')\n",
    "\n",
    "# all_data = np.array(dataset_5ms.data.spikes_smth_20_oneside)\n",
    "# print(all_data.shape)\n",
    "# if not np.isnan(all_data).any():\n",
    "#     scaler = StandardScaler()\n",
    "#     X = scaler.fit_transform(all_data)\n",
    "#     pca = PCA(n_components=n_dims,random_state = 42)\n",
    "#     PCA_data = pca.fit_transform(X)\n",
    "# print(PCA_data.shape)\n",
    "\n",
    "# dataset_5ms.add_continuous_data(PCA_data,'PCA_20_oneside')\n",
    "# print('PCA total var explained:',sum(pca.explained_variance_ratio_))\n",
    "\n",
    "all_data = np.array(dataset_10ms.data.spikes_smth_40)\n",
    "print(all_data.shape)\n",
    "if not np.isnan(all_data).any():\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(all_data)\n",
    "    pca = PCA(n_components=n_dims,random_state = 42)\n",
    "    PCA_data = pca.fit_transform(X)\n",
    "print(PCA_data.shape)\n",
    "dataset_10ms.add_continuous_data(PCA_data,'PCA_40')\n",
    "print('PCA total var explained:',sum(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data = np.array(dataset_20ms.data.spikes)\n",
    "# print(all_data.shape)\n",
    "\n",
    "# if not np.isnan(all_data).any():\n",
    "#     scaler = StandardScaler()\n",
    "#     X = scaler.fit_transform(all_data)\n",
    "#     pca = PCA(n_components=n_dims,random_state = 42)\n",
    "#     PCA_data = pca.fit_transform(X)\n",
    "\n",
    "# print(PCA_data.shape)\n",
    "# dataset_20ms.add_continuous_data(PCA_data,'PCA')\n",
    "# print('PCA total var explained:',sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussian_kernel_width = 20 #in ms\n",
    "# sigma = int(gaussian_kernel_width/bin_width)\n",
    "# data_smoothed = gaussian_filter1d_oneside(dataset_5ms.data.spikes.to_numpy().astype(np.float64),sigma,axis=0)\n",
    "# dataset_5ms.add_continuous_data(data_smoothed,'spikes_smth_20_oneside')\n",
    "\n",
    "# all_data = np.array(dataset_5ms.data.spikes_smth_20_oneside)\n",
    "# print(all_data.shape)\n",
    "# if not np.isnan(all_data).any():\n",
    "#     scaler = StandardScaler()\n",
    "#     X = scaler.fit_transform(all_data)\n",
    "#     pca = PCA(n_components=n_dims,random_state = 42)\n",
    "#     PCA_data = pca.fit_transform(X)\n",
    "# print(PCA_data.shape)\n",
    "# dataset_5ms.add_continuous_data(PCA_data,'PCA_20_oneside')\n",
    "# print('PCA total var explained:',sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dictionary for trial condition (reaching directions) for Stratified CV\n",
    "dataset = dataset_10ms\n",
    "active_mask = (dataset.trial_info.ctr_hold_bump==0) & (dataset.trial_info['split'] != 'none')\n",
    "passive_mask = (dataset.trial_info.ctr_hold_bump==1) & (dataset.trial_info['split'] != 'none')\n",
    "nan_mask = (np.isnan(dataset.trial_info.ctr_hold_bump)) & (dataset.trial_info['split'] != 'none')\n",
    "all_mask = (dataset.trial_info['split'] != 'none')\n",
    "\n",
    "trial_mask = all_mask\n",
    "valid_n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "print(valid_n_trials,'valid trials')\n",
    "\n",
    "\n",
    "trial_mask = active_mask\n",
    "active_trials_idx = np.array(dataset.trial_info.loc[trial_mask]['trial_id'])\n",
    "active_n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "print(active_n_trials,'active trials')\n",
    "\n",
    "trial_mask = passive_mask\n",
    "passive_trials_idx = np.array(dataset.trial_info.loc[trial_mask]['trial_id'])\n",
    "passive_n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "print(passive_n_trials,'passive trials')\n",
    "\n",
    "trial_mask = nan_mask\n",
    "nan_trials_idx = np.array(dataset.trial_info.loc[trial_mask]['trial_id'])\n",
    "nan_n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "print(nan_n_trials,'reach bump trials')\n",
    "\n",
    "active_cond_dir_idx = []\n",
    "passive_cond_dir_idx = []\n",
    "nan_cond_dir_idx = []\n",
    "nan_bump_cond_dir_idx = []\n",
    "for direction in [0,45,90,135,180,225,270,315]:\n",
    "# for direction in [0,90,180,270]:\n",
    "    active_cond_dir_idx.append(np.where((dataset.trial_info['cond_dir']%360 == direction) & (dataset.trial_info['ctr_hold_bump'] == 0) & \\\n",
    "           (dataset.trial_info['split'] != 'none'))[0])\n",
    "    passive_cond_dir_idx.append(np.where((dataset.trial_info['cond_dir']%360 == direction) & (dataset.trial_info['ctr_hold_bump'] == 1) & \\\n",
    "           (dataset.trial_info['split'] != 'none'))[0])\n",
    "    nan_cond_dir_idx.append(np.where((dataset.trial_info['cond_dir']%360 == direction) & (np.isnan(dataset.trial_info.ctr_hold_bump)) & \\\n",
    "           (dataset.trial_info['split'] != 'none'))[0])\n",
    "    nan_bump_cond_dir_idx.append(np.where((dataset.trial_info['bump_dir']%360 == direction) & (np.isnan(dataset.trial_info.ctr_hold_bump)) & \\\n",
    "           (dataset.trial_info['split'] != 'none'))[0])\n",
    "\n",
    "active_cond_dict = nans([active_n_trials])\n",
    "i = 0\n",
    "for idx in active_trials_idx:\n",
    "    for cond in range(0,len(active_cond_dir_idx)):\n",
    "        if idx in active_cond_dir_idx[cond]:\n",
    "            active_cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(active_cond_dict)\n",
    "print(len(active_cond_dict))\n",
    "\n",
    "passive_cond_dict = nans([passive_n_trials])\n",
    "i = 0\n",
    "for idx in passive_trials_idx:\n",
    "    for cond in range(0,len(passive_cond_dir_idx)):\n",
    "        if idx in passive_cond_dir_idx[cond]:\n",
    "            passive_cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(passive_cond_dict)\n",
    "print(len(passive_cond_dict))\n",
    "\n",
    "nan_cond_dict = nans([nan_n_trials])\n",
    "i = 0\n",
    "for idx in nan_trials_idx:\n",
    "    for cond in range(0,len(nan_cond_dir_idx)):\n",
    "        if idx in nan_cond_dir_idx[cond]:\n",
    "            nan_cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(nan_cond_dict)\n",
    "print(len(nan_cond_dict))\n",
    "\n",
    "nan_bump_cond_dict = nans([nan_n_trials])\n",
    "i = 0\n",
    "for idx in nan_trials_idx:\n",
    "    for cond in range(0,len(nan_bump_cond_dir_idx)):\n",
    "        if idx in nan_bump_cond_dir_idx[cond]:\n",
    "            nan_bump_cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(nan_bump_cond_dict)\n",
    "print(len(nan_bump_cond_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.cos(math.radians(450))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cond_dict*45 - nan_bump_cond_dict*45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_df = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range = (-100,1000), ignored_trials = ~active_mask)\n",
    "set(active_trials_idx) - set(active_df['trial_id'].unique())\n",
    "print('was',active_n_trials,'active trials')\n",
    "active_n_trials = active_n_trials - len(list(set(active_trials_idx) - set(active_df['trial_id'].unique())))\n",
    "active_cond_dict = np.delete(active_cond_dict,list(set(active_trials_idx) - set(active_df['trial_id'].unique())))\n",
    "print('now',active_n_trials,'active trials')\n",
    "print(len(active_cond_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_10ms.add_continuous_data(data['CD_FB_proj_pca40'],'CD_FB_proj')\n",
    "dataset_10ms.add_continuous_data(data['CD_proj_pca40'],'CD_proj')\n",
    "dataset_10ms.add_continuous_data(data['FB_proj_pca40'],'FB_proj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(monkey+'_hand_vel_r2s.npz')\n",
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(-300, 300, 20)[np.argmax(data['y_r2_cd_fb'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Heat map of how decoders at different lags work for each other\n",
    "# dataset = dataset_5ms\n",
    "# trial_mask = active_mask\n",
    "# x_field = 'PCA_40'\n",
    "# y_field = 'hand_acc'\n",
    "# lag_axis = np.arange(-200,201,20)\n",
    "# r2_map_array = nans([len(lag_axis),len(lag_axis)])\n",
    "# train_range = (-100, 500)\n",
    "\n",
    "# for i in range(len(lag_axis)):\n",
    "#     lag = lag_axis[i]\n",
    "#     r2,weights,_ = fit_and_predict(dataset, trial_mask, 'move_onset_time', train_range, lag, x_field, y_field)\n",
    "#     train_lag_range = (train_range[0]+lag, train_range[1]+lag)\n",
    "#     for j in range(len(lag_axis)):\n",
    "#         lag = lag_axis[j]\n",
    "#         r2,_,_,_,_ = pred_with_new_weights(dataset, trial_mask, 'move_onset_time',train_range, lag,\n",
    "#                                            x_field,y_field, weights, train_range, train_lag_range, trial_mask)\n",
    "#         r2_map_array[i][j] = r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12, 12))\n",
    "# vmin = r2_map_array.min()\n",
    "# vmax = r2_map_array.max()\n",
    "# from matplotlib import colors\n",
    "# norm=colors.TwoSlopeNorm(vmin=vmin, vcenter=0., vmax=vmax)\n",
    "\n",
    "# im = plt.imshow(r2_map_array, origin='lower', cmap='RdBu_r', norm=norm)\n",
    "# plt.colorbar()\n",
    "# ax.set_xlabel('Predicting time lag (ms)')\n",
    "# ax.set_ylabel('Training time lag (ms)')\n",
    "\n",
    "# ax.set_xticks(np.arange(len(lag_axis)))\n",
    "# ax.set_yticks(np.flip(np.arange(len(lag_axis))))\n",
    "# ax.set_xticklabels(labels=lag_axis,fontsize=12)\n",
    "# ax.set_yticklabels(labels=np.flip(lag_axis),fontsize=12)\n",
    "\n",
    "# for i in range(len(lag_axis)):\n",
    "#     for j in range(len(lag_axis)):\n",
    "#         text = ax.text(j, i, str(int(r2_map_array[i, j]*100)/100),\n",
    "#                         ha=\"center\", va=\"center\", color=\"w\", fontsize=10)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = np.argwhere(lag_axis==-60)[0,0]\n",
    "# auto = r2_map_array[idx]\n",
    "# diag = r2_map_array[range(len(lag_axis)), range(len(lag_axis))]\n",
    "# plt.plot(lag_axis, diag, label = 'Original')\n",
    "# diag_corr = diag - auto * (auto>0)\n",
    "# plt.plot(lag_axis, diag_corr, label = 'Corrected')\n",
    "# plt.xlabel('Time lag (ms)')\n",
    "# plt.ylabel('R2')\n",
    "# plt.legend()\n",
    "# plt.axvline(lag_axis[np.argwhere(lag_axis== 0)], color = 'k', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # decoders angle\n",
    "# dataset = dataset_5ms\n",
    "# x_field = 'PCA_40'\n",
    "# y_field ='hand_acc'\n",
    "\n",
    "# dim = n_dims \n",
    "# act_lag_axis = np.arange(-200,201,20)\n",
    "# pas_lag_axis = np.arange(-200,201,20)\n",
    "\n",
    "# act_coef_array = nans([len(act_lag_axis),2,dim])\n",
    "# pas_coef_array = nans([len(pas_lag_axis),2,dim])\n",
    "\n",
    "# trial_mask = passive_mask\n",
    "# cond_dict = passive_cond_dict\n",
    "# for i in range(len(act_lag_axis)):\n",
    "#     lag = act_lag_axis[i]\n",
    "#     _, coef, _, _ = fit_and_predict(dataset, trial_mask, 'move_onset_time', (-100, 500), lag, x_field, y_field, cond_dict)\n",
    "#     act_coef_array[i,:,:] = coef\n",
    "\n",
    "# # trial_mask = active_mask\n",
    "# # cond_dict = active_cond_dict\n",
    "# trial_mask = passive_mask\n",
    "# cond_dict = passive_cond_dict\n",
    "# for i in range(len(pas_lag_axis)):\n",
    "#     lag = pas_lag_axis[i]\n",
    "#     _, coef, _,_ = fit_and_predict(dataset, trial_mask, 'move_onset_time', (200, 500), lag, x_field, y_field, cond_dict)\n",
    "#     pas_coef_array[i,:,:] = coef\n",
    "\n",
    "\n",
    "# act_t_label = act_lag_axis\n",
    "# pas_t_label = pas_lag_axis\n",
    "# act_X_coef_array = act_coef_array[:,0,:]\n",
    "# pas_X_coef_array = pas_coef_array[:,0,:]\n",
    "# angDist_array = nans([len(act_t_label),len(pas_t_label)])\n",
    "\n",
    "# for i in range(len(act_t_label)):\n",
    "#     for j in range(len(pas_t_label)):\n",
    "#         angDist_array[i,j] = math.degrees(angle_between(act_X_coef_array[i,:],pas_X_coef_array[j,:]))\n",
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# im = ax.imshow(angDist_array)\n",
    "# ax.set_xlabel('Passive lag time (ms)')\n",
    "# # ax.set_xlabel('Active lag time (ms)')\n",
    "# ax.set_ylabel('Passive lag time (ms)')\n",
    "\n",
    "# ax.set_xticks(np.arange(len(pas_t_label)))\n",
    "# ax.set_yticks(np.arange(len(act_t_label)))\n",
    "# ax.set_xticklabels(labels=pas_t_label)\n",
    "# ax.set_yticklabels(labels=act_t_label)\n",
    "\n",
    "# ax.set_title(\"Angle between decoder weights\")\n",
    "\n",
    "# for i in range(len(act_t_label)):\n",
    "#     for j in range(len(pas_t_label)):\n",
    "#         text = ax.text(j, i, str(int(angDist_array[i, j])),\n",
    "#                         ha=\"center\", va=\"center\", color=\"w\", fontsize=14)\n",
    "# plt.tight_layout()\n",
    "# # figDir = '/Users/sherryan/area2_population_analysis/figures_plus/'\n",
    "# # plt.savefig(figDir + monkey + '_decoder_angle.pdf', dpi = 'figure')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Variance at each timepoint (across trials) on decoding axes\n",
    "# dataset = dataset_20ms\n",
    "# x_field = 'spikes'\n",
    "# y_field = 'hand_vel'\n",
    "# dim = n_neurons\n",
    "\n",
    "dataset = dataset_10ms\n",
    "# x_field = \n",
    "y_field = 'hand_vel'\n",
    "dim = n_neurons\n",
    "\n",
    "negative_lag = -60\n",
    "positive_lag = 40\n",
    "fit_range = (-100, 1000)\n",
    "\n",
    "_, aff_weights, _,_,_,_ = fit_and_predict(dataset, active_mask, 'move_onset_time', fit_range, positive_lag, \"FB_proj\", y_field)\n",
    "_, eff_weights, _,_,_,_  = fit_and_predict(dataset, active_mask, 'move_onset_time', fit_range, negative_lag,\"CD_proj\",y_field)\n",
    "\n",
    "\n",
    "# _, eff_weights, _,_ = fit_and_predict(dataset, active_mask, 'move_onset_time', fit_range, negative_lag, x_field, y_field)\n",
    "# _, aff_weights, _,_ = sub_and_predict(dataset, active_mask, 'move_onset_time', fit_range, positive_lag,x_field,y_field,eff_weights)\n",
    "\n",
    "# _, aff_weights, _,_ = fit_and_predict(dataset, active_mask, 'move_onset_time', fit_range, positive_lag, x_field, y_field)\n",
    "# _, eff_weights, _,_ = sub_and_predict(dataset, active_mask, 'move_onset_time', fit_range, negative_lag,x_field,y_field,aff_weights)\n",
    "\n",
    "pred_range = (-100,1000)\n",
    "passive_df = dataset.make_trial_data(align_field='move_onset_time', align_range=pred_range, ignored_trials=~passive_mask,allow_overlap=True)\n",
    "active_df = dataset.make_trial_data(align_field='move_onset_time', align_range=pred_range, ignored_trials=~active_mask,allow_overlap=True)\n",
    "\n",
    "#plot Active var\n",
    "n_trials = len(active_cond_dict)\n",
    "n_timepoints = int((pred_range[1] - pred_range[0])/dataset.bin_width)\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset.bin_width)\n",
    "\n",
    "# aff_proj = pca.inverse_transform(calc_proj(active_df[x_field].to_numpy(),aff_weights.T).T.reshape(-1,n_dims)).reshape(n_trials, n_timepoints,n_neurons)\n",
    "aff_proj = calc_proj(active_df['FB_proj'].to_numpy(),aff_weights.T).T.reshape(n_trials, n_timepoints,dim)\n",
    "aff_var = nans([n_timepoints])\n",
    "for i in range(n_timepoints):\n",
    "    # var = np.sum(get_sses_mean(aff_proj[:,i,:]))\n",
    "    var = np.sum(np.square(aff_proj[:,i,:]))\n",
    "    aff_var[i] = var\n",
    "aff_var = aff_var - np.min(aff_var)\n",
    "\n",
    "# eff_proj = pca.inverse_transform(calc_proj(active_df[x_field].to_numpy(),eff_weights.T).T.reshape(-1,n_dims)).reshape(n_trials, n_timepoints,n_neurons)\n",
    "eff_proj = calc_proj(active_df['CD_proj'].to_numpy(),eff_weights.T).T.reshape(n_trials, n_timepoints,dim)\n",
    "eff_var = nans([n_timepoints])\n",
    "for i in range(n_timepoints):\n",
    "    # var = np.sum(get_sses_mean(eff_proj[:,i,:]))\n",
    "    var = np.sum(np.square(eff_proj[:,i,:])) \n",
    "    eff_var[i] = var\n",
    "eff_var = eff_var - np.min(eff_var)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.plot(x_axis, aff_var,color = 'magenta',label = 'Aff')\n",
    "plt.plot(x_axis, eff_var,color = 'green',label = 'Eff')\n",
    "# plt.plot(x_axis, aff_var_explained + eff_var_explained,color = 'red',label = 'Sum')\n",
    "plt.axvline(0, color = 'k',linestyle = '--')\n",
    "plt.axvline(500, color = 'k',linestyle = '--')\n",
    "# plt.xlim([-500,600])\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Mean squared activity')\n",
    "plt.title('Active')\n",
    "# plt.legend()\n",
    "plt.tight_layout()\n",
    "# figDir = '/Users/sherryan/area2_population_analysis/'\n",
    "# plt.savefig(figDir + monkey + '_vel_var_act.pdf', dpi = 'figure')\n",
    "plt.show()\n",
    "\n",
    "#plot Passive var\n",
    "n_trials = len(passive_cond_dict)\n",
    "# aff_proj = pca.inverse_transform(calc_proj(passive_df[x_field].to_numpy(),aff_weights.T).T.reshape(-1,n_dims)).reshape(n_trials, n_timepoints,n_neurons)\n",
    "aff_proj = calc_proj(passive_df[\"FB_proj\"].to_numpy(),aff_weights.T).T.reshape(n_trials, n_timepoints,dim)\n",
    "aff_var = nans([n_timepoints])\n",
    "for i in range(n_timepoints):\n",
    "    # var = np.sum(get_sses_mean(aff_proj[:,i,:]))\n",
    "    var = np.sum(np.square(aff_proj[:,i,:]))\n",
    "    aff_var[i] = var\n",
    "aff_var = aff_var - np.min(aff_var)\n",
    "\n",
    "# eff_proj = pca.inverse_transform(calc_proj(passive_df[x_field].to_numpy(),eff_weights.T).T.reshape(-1,n_dims)).reshape(n_trials, n_timepoints,n_neurons)\n",
    "eff_proj = calc_proj(passive_df[\"CD_proj\"].to_numpy(),eff_weights.T).T.reshape(n_trials, n_timepoints,dim)\n",
    "eff_var = nans([n_timepoints])\n",
    "for i in range(n_timepoints):\n",
    "    # var = np.sum(get_sses_mean(eff_proj[:,i,:]))\n",
    "    var = np.sum(np.square(eff_proj[:,i,:])) \n",
    "    eff_var[i] = var\n",
    "eff_var = eff_var - np.min(eff_var)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.plot(x_axis, aff_var,color = 'magenta',label = 'Aff')\n",
    "plt.plot(x_axis, eff_var,color = 'green',label = 'Eff')\n",
    "plt.title('Passive')\n",
    "# plt.plot(x_axis, aff_var_explained + eff_var_explained,color = 'red',label = 'Sum')\n",
    "plt.axvline(0, color = 'k',linestyle = '--')\n",
    "plt.axvline(120, color = 'k',linestyle = '--')\n",
    "# plt.axvline(180, color = 'k',linestyle = '--')\n",
    "# plt.axvline(500, color = 'k',linestyle = '--')\n",
    "# plt.xlim([-500,600])\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Mean squared activity')\n",
    "# plt.title('')\n",
    "# plt.legend()\n",
    "plt.tight_layout()\n",
    "# figDir = '/Users/sherryan/area2_population_analysis/'\n",
    "# plt.savefig(figDir + monkey + '_vel_var_pas.pdf', dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_with_new_weights(dataset, trial_mask, align_field, align_range, lag, x_field, y_field, weights, offset, train_range, train_lag_range, train_mask):\n",
    "    \"\"\" Returns R2, r, and predictions using given weights, basically a matrix multiplication \"\"\"\n",
    "    vel_df = dataset.make_trial_data(align_field=align_field, align_range=align_range, ignored_trials=~trial_mask)\n",
    "    lag_align_range = (align_range[0] + lag, align_range[1] + lag)\n",
    "    rates_df = dataset.make_trial_data(align_field=align_field, align_range=lag_align_range, ignored_trials=~trial_mask)\n",
    "\n",
    "    rates_array = rates_df[x_field].to_numpy()\n",
    "    vel_array = vel_df[y_field].to_numpy()\n",
    "\n",
    "    train_rates_df = dataset.make_trial_data(align_field=align_field, align_range=train_lag_range, ignored_trials=~train_mask)\n",
    "    train_rates_array = train_rates_df[x_field].to_numpy()\n",
    "\n",
    "    X = (rates_array - np.nanmean(train_rates_array,axis=0))/np.nanstd(train_rates_array,axis=0)\n",
    "    Y_hat = X@weights.T + offset\n",
    "\n",
    "    train_vel_df = dataset.make_trial_data(align_field=align_field, align_range=train_range, ignored_trials=~train_mask)\n",
    "    train_vel_array = train_vel_df[y_field].to_numpy()\n",
    "\n",
    "    pred_vel = Y_hat + np.nanmean(train_vel_array,axis=0)\n",
    "            \n",
    "    sses =get_sses_pred(vel_array[:,0],pred_vel[:,0])\n",
    "    sses_mean=get_sses_mean(vel_array[:,0])\n",
    "    x_R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    \n",
    "    sses =get_sses_pred(vel_array[:,1],pred_vel[:,1])\n",
    "    sses_mean=get_sses_mean(vel_array[:,1])\n",
    "    y_R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    \n",
    "    sses =get_sses_pred(vel_array,pred_vel)\n",
    "    sses_mean=get_sses_mean(vel_array)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    \n",
    "    r = scipy.stats.pearsonr(vel_array.reshape(-1), pred_vel.reshape(-1))[0]\n",
    "    \n",
    "    if vel_array.shape[-1] == 2:\n",
    "        vel_df = pd.concat([vel_df, pd.DataFrame(pred_vel, columns=dataset._make_midx('pred_vel', ['x', 'y'], 2))], axis=1)\n",
    "    elif vel_array.shape[-1] == 3:\n",
    "        vel_df = pd.concat([vel_df, pd.DataFrame(pred_vel, columns=dataset._make_midx('pred_vel', ['x', 'y','z'], 3))], axis=1)\n",
    "    else:\n",
    "        vel_df = pd.concat([vel_df, pd.DataFrame(pred_vel, columns=dataset._make_midx('pred_vel', num_channels=vel_array.shape[-1]))], axis=1)\n",
    "    \n",
    "    \n",
    "    return R2, r, x_R2, y_R2, vel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-decoding\n",
    "\n",
    "dataset = dataset_10ms\n",
    "# all_mask = dataset.trial_info.split != 'none'\n",
    "\n",
    "\n",
    "positive_lag = 0\n",
    "negative_lag = -180\n",
    "\n",
    "# x_field = 'spikes_smth_40'\n",
    "y_field ='hand_vel'\n",
    "train_range = (-100,1000)\n",
    "train_pos_lag_range = (train_range[0]+positive_lag, train_range[1]+positive_lag)\n",
    "train_neg_lag_range = (train_range[0]+negative_lag, train_range[1]+negative_lag)\n",
    "train_mask = active_mask\n",
    "\n",
    "_, aff_weights, aff_offset, act_aff_vel_df,_,_ = fit_and_predict(dataset, train_mask, 'move_onset_time', train_range, positive_lag, 'FB_proj', y_field)\n",
    "_, eff_weights, eff_offset, act_eff_vel_df,_,_ = fit_and_predict(dataset, train_mask, 'move_onset_time', train_range, negative_lag,'CD_proj',y_field)\n",
    "_, both_weights, both_offset, act_both_vel_df,_,_ = fit_and_predict(dataset, train_mask, 'move_onset_time', train_range, -20,'CD_FB_proj',y_field)\n",
    "\n",
    "#pred active\n",
    "pred_range = (-100,1000)\n",
    "active_x_axis = np.arange(train_range[0], train_range[1], dataset.bin_width)\n",
    "_, _, _,_,act_aff_vel_df = pred_with_new_weights(dataset, active_mask, 'move_onset_time',pred_range, 0,'FB_proj',\n",
    "                                                 y_field, aff_weights, aff_offset, train_range, train_pos_lag_range, train_mask)\n",
    "_, _, _,_,act_eff_vel_df = pred_with_new_weights(dataset, active_mask, 'move_onset_time',pred_range, 0,'CD_proj',\n",
    "                                                 y_field, eff_weights, eff_offset, train_range, train_neg_lag_range, train_mask)\n",
    "_, _, _,_,act_both_vel_df = pred_with_new_weights(dataset, active_mask, 'move_onset_time',pred_range, 0,'CD_FB_proj',\n",
    "                                                 y_field, both_weights, both_offset, train_range, train_neg_lag_range, train_mask)\n",
    "# #pred passive\n",
    "# pred_range = (-100, 500)\n",
    "# passive_x_axis = np.arange(pred_range[0], pred_range[1], dataset.bin_width)\n",
    "# _, _, _,_,pas_aff_vel_df = pred_with_new_weights(dataset, passive_mask, 'move_onset_time',pred_range, 0,'FB_proj',\n",
    "#                                                  y_field, aff_weights, aff_offset, train_range, train_pos_lag_range, train_mask)\n",
    "# _, _, _,_,pas_eff_vel_df = pred_with_new_weights(dataset, passive_mask, 'move_onset_time',pred_range, 0,'CD_proj',\n",
    "#                                                  y_field, eff_weights, eff_offset, train_range, train_neg_lag_range, train_mask)\n",
    "# _, _, _,_,pas_both_vel_df = pred_with_new_weights(dataset, passive_mask, 'move_onset_time',pred_range, 0,'CD_FB_proj',\n",
    "#                                                  y_field, both_weights, both_offset, train_range, train_neg_lag_range, train_mask)\n",
    "\n",
    "#pred nan\n",
    "pred_range = (-100, 1000)\n",
    "passive_x_axis = np.arange(pred_range[0], pred_range[1], dataset.bin_width)\n",
    "_, _, _,_,pas_aff_vel_df = pred_with_new_weights(dataset, nan_mask, 'move_onset_time',pred_range, 0,'FB_proj',\n",
    "                                                 y_field, aff_weights, aff_offset, train_range, train_pos_lag_range, train_mask)\n",
    "_, _, _,_,pas_eff_vel_df = pred_with_new_weights(dataset, nan_mask, 'move_onset_time',pred_range, 0,'CD_proj',\n",
    "                                                 y_field, eff_weights, eff_offset, train_range, train_neg_lag_range, train_mask)\n",
    "_, _, _,_,pas_both_vel_df = pred_with_new_weights(dataset, nan_mask, 'move_onset_time',pred_range, 0,'CD_FB_proj',\n",
    "                                                 y_field, both_weights, both_offset, train_range, train_neg_lag_range, train_mask)\n",
    "\n",
    "plot_dir = [0.0, 180.0] # limit plot directions to reduce cluttering\n",
    "colors = ['gray','gray']\n",
    "plot_dim = 'x'\n",
    "fig, axs = plt.subplots(6, 4, sharex=False, sharey=True, figsize=(18, 18))\n",
    "plt.ylim(-40,40)\n",
    "i = 0\n",
    "alpha = 0.5\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset.trial_info[dataset.trial_info.cond_dir%360 == trial_dir].trial_id\n",
    "    for _, trial in act_eff_vel_df[np.isin(act_eff_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[0][i].plot(active_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[0][i].plot(active_x_axis, trial.pred_vel[plot_dim], color='green', alpha = alpha, linewidth=0.5)\n",
    "    for _, trial in act_aff_vel_df[np.isin(act_aff_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[1][i].plot(active_x_axis, trial.pred_vel[plot_dim], color='magenta', alpha = alpha, linewidth=0.5)\n",
    "        axs[1][i].plot(active_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "    for _, trial in act_both_vel_df[np.isin(act_both_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[2][i].plot(active_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[2][i].plot(active_x_axis, trial.pred_vel[plot_dim], color='brown', alpha = alpha, linewidth=0.5)    \n",
    "        axs[2][i].spines[['right', 'top']].set_visible(False) \n",
    "\n",
    "    for _, trial in pas_eff_vel_df[np.isin(pas_eff_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[3][i].plot(passive_x_axis, trial.pred_vel[plot_dim], color='green', alpha = alpha, linewidth=0.5)\n",
    "        axs[3][i].plot(passive_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "    for _, trial in pas_aff_vel_df[np.isin(pas_aff_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[4][i].plot(passive_x_axis, trial.pred_vel[plot_dim], color='magenta', alpha = alpha, linewidth=0.5)\n",
    "        axs[4][i].plot(passive_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "    for _, trial in pas_both_vel_df[np.isin(pas_both_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[5][i].plot(passive_x_axis, trial.pred_vel[plot_dim], color='brown', alpha = alpha, linewidth=0.5)\n",
    "        axs[5][i].plot(passive_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[5][i].spines[['right', 'top']].set_visible(False)\n",
    "    i+=2\n",
    "\n",
    "positive_lag = 40\n",
    "negative_lag = -60\n",
    "\n",
    "y_field ='hand_vel'\n",
    "train_range = (-100,1000)\n",
    "train_pos_lag_range = (train_range[0]+positive_lag, train_range[1]+positive_lag)\n",
    "train_neg_lag_range = (train_range[0]+negative_lag, train_range[1]+negative_lag)\n",
    "train_mask = active_mask\n",
    "\n",
    "_, aff_weights, aff_offset, act_aff_vel_df,_,_ = fit_and_predict(dataset, train_mask, 'move_onset_time', train_range, positive_lag, 'FB_proj', y_field)\n",
    "_, eff_weights, eff_offset, act_eff_vel_df,_,_ = fit_and_predict(dataset, train_mask, 'move_onset_time', train_range, negative_lag,'CD_proj',y_field)\n",
    "_, both_weights, both_offset, act_both_vel_df,_,_ = fit_and_predict(dataset, train_mask, 'move_onset_time', train_range, 0,'CD_FB_proj',y_field)\n",
    "\n",
    "#pred active\n",
    "pred_range = (-100, 1000)\n",
    "active_x_axis = np.arange(train_range[0], train_range[1], dataset.bin_width)\n",
    "_, _, _,_,act_aff_vel_df = pred_with_new_weights(dataset, active_mask, 'move_onset_time',pred_range, 0,'FB_proj',\n",
    "                                                 y_field, aff_weights, aff_offset, train_range, train_pos_lag_range, train_mask)\n",
    "_, _, _,_,act_eff_vel_df = pred_with_new_weights(dataset, active_mask, 'move_onset_time',pred_range, 0,'CD_proj',\n",
    "                                                 y_field, eff_weights, eff_offset, train_range, train_neg_lag_range, train_mask)\n",
    "_, _, _,_,act_both_vel_df = pred_with_new_weights(dataset, active_mask, 'move_onset_time',pred_range, 0,'CD_FB_proj',\n",
    "                                                 y_field, both_weights, both_offset, train_range, train_neg_lag_range, train_mask)\n",
    "# #pred passive\n",
    "# pred_range = (-100, 500)\n",
    "# passive_x_axis = np.arange(pred_range[0], pred_range[1], dataset.bin_width)\n",
    "# _, _, _,_,pas_aff_vel_df = pred_with_new_weights(dataset, passive_mask, 'move_onset_time',pred_range, 0,'FB_proj',\n",
    "#                                                  y_field, aff_weights, aff_offset, train_range, train_pos_lag_range, train_mask)\n",
    "# _, _, _,_,pas_eff_vel_df = pred_with_new_weights(dataset, passive_mask, 'move_onset_time',pred_range, 0,'CD_proj',\n",
    "#                                                  y_field, eff_weights, eff_offset, train_range, train_neg_lag_range, train_mask)\n",
    "# _, _, _,_,pas_both_vel_df = pred_with_new_weights(dataset, passive_mask, 'move_onset_time',pred_range, 0,'CD_FB_proj',\n",
    "#                                                  y_field, both_weights, both_offset, train_range, train_neg_lag_range, train_mask)\n",
    "\n",
    "#pred nan\n",
    "pred_range = (-100, 1000)\n",
    "passive_x_axis = np.arange(pred_range[0], pred_range[1], dataset.bin_width)\n",
    "_, _, _,_,pas_aff_vel_df = pred_with_new_weights(dataset, nan_mask, 'move_onset_time',pred_range, 0,'FB_proj',\n",
    "                                                 y_field, aff_weights, aff_offset, train_range, train_pos_lag_range, train_mask)\n",
    "_, _, _,_,pas_eff_vel_df = pred_with_new_weights(dataset, nan_mask, 'move_onset_time',pred_range, 0,'CD_proj',\n",
    "                                                 y_field, eff_weights, eff_offset, train_range, train_neg_lag_range, train_mask)\n",
    "_, _, _,_,pas_both_vel_df = pred_with_new_weights(dataset, nan_mask, 'move_onset_time',pred_range, 0,'CD_FB_proj',\n",
    "                                                 y_field, both_weights, both_offset, train_range, train_neg_lag_range, train_mask)\n",
    "\n",
    "\n",
    "plot_dir = [90.0, 270.0] # limit plot directions to reduce cluttering\n",
    "colors = ['gray', 'gray']\n",
    "plot_dim = 'y'\n",
    "i = 1\n",
    "alpha = 0.5\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset.trial_info[dataset.trial_info.cond_dir%360 == trial_dir].trial_id\n",
    "    for _, trial in act_eff_vel_df[np.isin(act_eff_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[0][i].plot(active_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[0][i].plot(active_x_axis, trial.pred_vel[plot_dim], color='green', alpha = alpha, linewidth=0.5)\n",
    "    for _, trial in act_aff_vel_df[np.isin(act_aff_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[1][i].plot(active_x_axis, trial.pred_vel[plot_dim], color='magenta', alpha = alpha, linewidth=0.5)\n",
    "        axs[1][i].plot(active_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "    for _, trial in act_both_vel_df[np.isin(act_both_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[2][i].plot(active_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[2][i].plot(active_x_axis, trial.pred_vel[plot_dim], color='brown', alpha = alpha, linewidth=0.5)    \n",
    "        axs[2][i].spines[['right', 'top']].set_visible(False) \n",
    "\n",
    "    for _, trial in pas_eff_vel_df[np.isin(pas_eff_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[3][i].plot(passive_x_axis, trial.pred_vel[plot_dim], color='green', alpha = alpha, linewidth=0.5)\n",
    "        axs[3][i].plot(passive_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "    for _, trial in pas_aff_vel_df[np.isin(pas_aff_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[4][i].plot(passive_x_axis, trial.pred_vel[plot_dim], color='magenta', alpha = alpha, linewidth=0.5)\n",
    "        axs[4][i].plot(passive_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "    for _, trial in pas_both_vel_df[np.isin(pas_both_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[5][i].plot(passive_x_axis, trial.pred_vel[plot_dim], color='brown', alpha = alpha, linewidth=0.5)\n",
    "        axs[5][i].plot(passive_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[5][i].spines[['right', 'top']].set_visible(False)\n",
    "    i+=2\n",
    "\n",
    "fig.supxlabel('Time after movement onset (ms)')\n",
    "# axs[0][0].set_ylabel('Prediction',fontsize=14)\n",
    "# axs[1][0].set_ylabel('Prediction',fontsize=14)\n",
    "# axs[0][0].set_ylabel('Hand acceleration \\n (cm/s^2)',fontsize=14)\n",
    "# axs[1][0].set_ylabel('Hand acceleration \\n (cm/s^2)',fontsize=14)\n",
    "axs[0][0].set_ylabel('Hand velocity \\n (cm/s)',fontsize=14)\n",
    "axs[1][0].set_ylabel('Hand velocity \\n (cm/s)',fontsize=14)\n",
    "\n",
    "\n",
    "axs[0][0].set_title('0 deg')\n",
    "axs[0][1].set_title('90 deg')\n",
    "axs[0][2].set_title('180 deg')\n",
    "axs[0][3].set_title('270 deg')\n",
    "\n",
    "\n",
    "# legend_elements = [Patch(facecolor='magenta', label='Afferent prediction'),\n",
    "#                     Patch(facecolor='k', label='Efferent prediction')]\n",
    "# legend_elements = [Patch(facecolor='magenta', label='Afferent prediction')]\n",
    "# plt.legend(handles=legend_elements)\n",
    "plt.tight_layout()\n",
    "# figDir = '/Users/sherryan/area2_population_analysis/'\n",
    "# plt.savefig(figDir + monkey + '_cross_vel_both_early_aligned.pdf', dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # 2D plot\n",
    "\n",
    "# dataset = dataset_5ms\n",
    "# x_field = 'PCA_40'\n",
    "# y_field ='hand_acc'\n",
    "\n",
    "# plot_dir = 0.0\n",
    "# plot_dim = 'x'\n",
    "# putative_aff_lag = 80\n",
    "# putative_eff_lag = -60\n",
    "# fit_range = (-100,500)\n",
    "# dim = n_dims\n",
    "# all_mask = dataset_5ms.trial_info.split != 'none'\n",
    "\n",
    "# aff_fit_mask = active_mask\n",
    "# eff_fit_mask = active_mask\n",
    "\n",
    "# # _, aff_axis, _ = fit_and_predict(dataset, aff_fit_mask, 'move_onset_time', fit_range, putative_aff_lag, x_field, y_field)\n",
    "# # _, eff_axis,_ = sub_and_predict(dataset, eff_fit_mask, 'move_onset_time', fit_range, putative_eff_lag,x_field,y_field,aff_axis)\n",
    "# # _, eff_axis,_ = fit_and_predict(dataset, active_mask, 'move_onset_time', fit_range, putative_eff_lag,x_field,y_field, cond_dict = cond_dict)\n",
    "\n",
    "# _, eff_axis, _ = fit_and_predict(dataset, eff_fit_mask, 'move_onset_time', fit_range, putative_eff_lag, x_field, y_field)\n",
    "# _, aff_axis,_ = sub_and_predict(dataset, aff_fit_mask, 'move_onset_time', fit_range, putative_aff_lag,x_field,y_field,eff_axis)\n",
    "\n",
    "# print(math.degrees(angle_between(aff_axis[0,:],eff_axis[0,:])))\n",
    "\n",
    "# pred_range =(-1000,700)\n",
    "# x_axis = np.arange(pred_range[0], pred_range[1], dataset.bin_width)\n",
    "\n",
    "# if plot_dim == 'x':\n",
    "#     aff_axis_x = aff_axis[0,:]\n",
    "#     eff_axis_x = eff_axis[0,:]\n",
    "# if plot_dim == 'y':\n",
    "#     aff_axis_x = aff_axis[1,:]\n",
    "#     eff_axis_x = eff_axis[1,:]\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# # fig.set_figheight(4)\n",
    "# plt.xlabel('Aff axis')\n",
    "# plt.ylabel('Eff axis')\n",
    "# plt.title('')\n",
    "# ax.spines['left'].set_position(('data', 0.0))\n",
    "# ax.spines['bottom'].set_position(('data', 0.0))\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# ax.set_aspect('equal')\n",
    "# ax.set_xticks([]); ax.set_yticks([])\n",
    "# ax.yaxis.set_label_coords(-.1, .9)\n",
    "# ax.xaxis.set_label_coords(.9, -.1)\n",
    "\n",
    "# # # Define Passive\n",
    "# # trial_mask = (dataset_5ms.trial_info.cond_dir == plot_dir) & (dataset_5ms.trial_info.ctr_hold_bump) & (dataset_5ms.trial_info.split != 'none')\n",
    "# # df = dataset.make_trial_data(align_field= 'move_onset_time', align_range=pred_range, ignored_trials=~trial_mask)\n",
    "# # n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "# # n_timepoints = int((pred_range[1] - pred_range[0])/dataset.bin_width)\n",
    "# # pas_aff_proj = np.mean((df[x_field].to_numpy()@aff_axis_x.T).reshape(n_trials, n_timepoints),axis=0)\n",
    "# # pas_eff_proj = np.mean((df[x_field].to_numpy()@eff_axis_x.T).reshape(n_trials, n_timepoints),axis=0)\n",
    "\n",
    "# # ## Plot Passive (1)\n",
    "# # # plt.plot(pas_aff_proj, pas_eff_proj, color = 'k', label = 'Passive proj')\n",
    "# # plt.scatter(pas_aff_proj,pas_eff_proj,s = 10,c=x_axis, cmap='Greys')\n",
    "# # plt.scatter(pas_aff_proj[np.argwhere(x_axis==0)],pas_eff_proj[np.argwhere(x_axis==0)],color = 'green',zorder=10)\n",
    "# # plt.scatter(pas_aff_proj[np.argwhere(x_axis==120)],pas_eff_proj[np.argwhere(x_axis==120)],color = 'red',zorder=10)\n",
    "# # plt.scatter(pas_aff_proj[np.argwhere(x_axis==500)],pas_eff_proj[np.argwhere(x_axis==500)],color = 'orange',zorder=10)\n",
    "\n",
    "\n",
    "# ## Define Active\n",
    "# trial_mask = (dataset_5ms.trial_info.cond_dir == plot_dir) & (~dataset_5ms.trial_info.ctr_hold_bump) & (dataset_5ms.trial_info.split != 'none')\n",
    "# df = dataset.make_trial_data(align_field= 'move_onset_time', align_range=pred_range, ignored_trials=~trial_mask)\n",
    "# n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "# n_timepoints = int((pred_range[1] - pred_range[0])/dataset.bin_width)\n",
    "# act_aff_proj = np.mean((df[x_field].to_numpy() @ aff_axis_x.T).reshape(n_trials, n_timepoints),axis=0)\n",
    "# act_eff_proj = np.mean((df[x_field].to_numpy() @ eff_axis_x.T).reshape(n_trials, n_timepoints),axis=0)\n",
    "\n",
    "# ## Plot Active (1)\n",
    "# # plt.plot(act_aff_proj, act_eff_proj, color = 'blue', label = 'Active proj')\n",
    "# plt.scatter(act_aff_proj,act_eff_proj,s = 10,c=x_axis, cmap='Blues')\n",
    "# plt.scatter(act_aff_proj[np.argwhere(x_axis==0)],act_eff_proj[np.argwhere(x_axis==0)],color = 'green',zorder=10)\n",
    "# plt.scatter(act_aff_proj[np.argwhere(x_axis==120)],act_eff_proj[np.argwhere(x_axis==120)],color = 'red',zorder=10)\n",
    "# plt.scatter(act_aff_proj[np.argwhere(x_axis==500)],act_eff_proj[np.argwhere(x_axis==500)],color = 'orange',zorder=10)\n",
    "# plt.scatter(act_aff_proj[np.argwhere(x_axis==1000)],act_eff_proj[np.argwhere(x_axis==1000)],color = 'orange',zorder=10)\n",
    "\n",
    "\n",
    "# legend_elements = [Patch(facecolor='#1f77b4', label='Active'),\n",
    "#                     Patch(facecolor='#7f7f7f', label='Passive')]\n",
    "# # plt.legend(handles=legend_elements)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # 1D plot\n",
    "# dataset = dataset_5ms\n",
    "# x_field = 'PCA_40'\n",
    "# y_field ='hand_acc'\n",
    "\n",
    "# plot_dir = 0.0\n",
    "# plot_dim = 'x'\n",
    "# proj_axis = 'Efferent'\n",
    "\n",
    "# pred_range =(-1000,1000)\n",
    "# putative_aff_lag = 80\n",
    "# putative_eff_lag = -60\n",
    "# aff_fit_mask = active_mask \n",
    "# eff_fit_mask = active_mask \n",
    "# aff_fit_range = (-100, 500)\n",
    "# eff_fit_range = (-100, 500)\n",
    "\n",
    "# if proj_axis == 'Efferent':\n",
    "#     _, eff_axis, _ = fit_and_predict(dataset, eff_fit_mask, 'move_onset_time', eff_fit_range, putative_eff_lag, x_field, y_field)\n",
    "#     if plot_dim == 'x':\n",
    "#         axis = eff_axis[0,:]    \n",
    "#     if plot_dim == 'y':\n",
    "#         axis = eff_axis[1,:]\n",
    "# if proj_axis == 'Afferent':\n",
    "#     _, eff_axis, _ = fit_and_predict(dataset, eff_fit_mask, 'move_onset_time', eff_fit_range, putative_eff_lag, x_field, y_field)\n",
    "#     _, aff_axis,_ = sub_and_predict(dataset, aff_fit_mask, 'move_onset_time', aff_fit_range, putative_aff_lag,x_field,y_field,eff_axis)\n",
    "#     if plot_dim == 'x':\n",
    "#         axis = aff_axis[0,:]    \n",
    "#     if plot_dim == 'y':\n",
    "#         axis = aff_axis[1,:]\n",
    "\n",
    "# x_axis = np.arange(pred_range[0], pred_range[1], dataset.bin_width)\n",
    "\n",
    "# trial_mask = (dataset_5ms.trial_info.cond_dir == plot_dir) & (~dataset_5ms.trial_info.ctr_hold_bump) & (dataset_5ms.trial_info.split != 'none')\n",
    "# df = dataset.make_trial_data(align_field= 'move_onset_time', align_range=pred_range, ignored_trials=~trial_mask)\n",
    "# proj = (df[x_field].to_numpy()@ axis.T)\n",
    "# n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "# n_timepoints = int((pred_range[1] - pred_range[0])/dataset.bin_width)\n",
    "# proj_reshaped = proj.reshape(n_trials, n_timepoints)\n",
    "# mean_proj = np.mean(proj_reshaped,axis = 0)\n",
    "# fig, ax = plt.subplots()\n",
    "# fig.set_figheight(4)\n",
    "# plt.plot(mean_proj,x_axis,label = 'Active')\n",
    "# acc = (df[y_field][plot_dim].to_numpy()).reshape(n_trials,n_timepoints)\n",
    "# mean_acc = np.mean(acc/np.std(acc)-np.mean(acc),axis=0)\n",
    "\n",
    "# plt.plot(mean_acc,x_axis, color = '#1f77b4',alpha = 0.3)\n",
    "# plt.xlabel(f'{proj_axis} axis')\n",
    "# plt.title('')\n",
    "# plt.scatter(mean_proj,x_axis,s = 10)\n",
    "# plt.scatter(mean_proj[np.argwhere(x_axis==0)],0,color = 'green',zorder=10)\n",
    "# plt.scatter(mean_proj[np.argwhere(x_axis==120)],120,color = 'red',zorder=10)\n",
    "\n",
    "# trial_mask = (dataset_5ms.trial_info.cond_dir == plot_dir) & (dataset_5ms.trial_info.ctr_hold_bump) & (dataset_5ms.trial_info.split != 'none')\n",
    "# df = dataset.make_trial_data(align_field= 'move_onset_time', align_range=pred_range, ignored_trials=~trial_mask)\n",
    "# proj = (df[x_field].to_numpy()@ axis.T)\n",
    "# n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "# n_timepoints = int((pred_range[1] - pred_range[0])/dataset.bin_width)\n",
    "# proj_reshaped = proj.reshape(n_trials, n_timepoints)\n",
    "# mean_proj = np.mean(proj_reshaped,axis = 0)\n",
    "# plt.plot(mean_proj,x_axis,color = 'k',label = 'Passive')\n",
    "# acc = (df[y_field][plot_dim].to_numpy()).reshape(n_trials,n_timepoints)\n",
    "# mean_acc = np.mean(acc/np.std(acc)-np.mean(acc),axis=0)\n",
    "\n",
    "# plt.plot(mean_acc,x_axis, color = 'k',alpha = 0.3)\n",
    "# plt.xlabel(f'{proj_axis} axis')\n",
    "# plt.yticks([])\n",
    "# plt.scatter(mean_proj,x_axis,s = 10,color = 'k')\n",
    "# plt.scatter(mean_proj[np.argwhere(x_axis==0)],0,color = 'green',zorder=10)\n",
    "# plt.scatter(mean_proj[np.argwhere(x_axis==120)],120,color = 'red',zorder=10)\n",
    "\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# ax.spines['left'].set_visible(False)\n",
    "\n",
    "# plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
