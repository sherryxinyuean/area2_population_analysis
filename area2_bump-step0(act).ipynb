{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d2edb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n"
     ]
    }
   ],
   "source": [
    "from nlb_tools.nwb_interface import NWBDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "\n",
    "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966 (90 deg)\n",
    "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0 (0 deg)\n",
    "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793 (180 deg)\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "\n",
    "#Import standard packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import io\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "# If you would prefer to load the '.h5' example file rather than the '.pickle' example file. You need the deepdish package\n",
    "# import deepdish as dd \n",
    "\n",
    "#Import function to get the covariate matrix that includes spike history from previous bins\n",
    "from Neural_Decoding.preprocessing_funcs import get_spikes_with_history\n",
    "\n",
    "#Import metrics\n",
    "from Neural_Decoding.metrics import get_R2\n",
    "from Neural_Decoding.metrics import get_rho\n",
    "\n",
    "#Import decoder functions\n",
    "from Neural_Decoding.decoders import WienerCascadeDecoder\n",
    "from Neural_Decoding.decoders import WienerFilterDecoder\n",
    "from Neural_Decoding.decoders import DenseNNDecoder\n",
    "from Neural_Decoding.decoders import SimpleRNNDecoder\n",
    "from Neural_Decoding.decoders import GRUDecoder\n",
    "from Neural_Decoding.decoders import LSTMDecoder\n",
    "from Neural_Decoding.decoders import XGBoostDecoder\n",
    "from Neural_Decoding.decoders import SVRDecoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def get_sses_pred(y_test,y_test_pred):\n",
    "    sse=np.sum((y_test_pred-y_test)**2,axis=0)\n",
    "    return sse\n",
    "\n",
    "def get_sses_mean(y_test):\n",
    "    y_mean=np.mean(y_test,axis=0)\n",
    "    sse_mean=np.sum((y_test-y_mean)**2,axis=0)\n",
    "    return sse_mean\n",
    "\n",
    "def nans(shape, dtype=float):\n",
    "    a = np.empty(shape, dtype)\n",
    "    a.fill(np.nan)\n",
    "    return a\n",
    "\n",
    "def vector_reject(u,v):\n",
    "    #project u on v, subtract u1 from u\n",
    "    P = np.outer(v,(v.T))/(v@(v.T))\n",
    "    u_sub = u - P@u\n",
    "#     another calculation, to double-check\n",
    "#     v_norm = np.sqrt(sum(v**2))    \n",
    "#     proj_u_on_v = (np.dot(u, v)/v_norm**2)*v\n",
    "#     u_sub = u - proj_u_on_v\n",
    "    return u_sub\n",
    "\n",
    "def calc_proj_matrix(A):\n",
    "    return A@np.linalg.inv(A.T@A)@A.T\n",
    "def calc_proj(b, A):\n",
    "    P = calc_proj_matrix(A)\n",
    "    return P@b.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dca024",
   "metadata": {},
   "source": [
    "# Single Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dc8cc31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "foldername = \"~/area2_population_analysis/s1-kinematics/actpas_NWB/\"\n",
    "monkey = \"Lando_20170731\"\n",
    "filename = foldername + monkey + \"_COactpas_TD.nwb\"\n",
    "\n",
    "dataset_5ms = NWBDataset(filename, split_heldout=False)\n",
    "dataset_5ms.resample(5)\n",
    "dataset_5ms.smooth_spk(40, name='smth_40')\n",
    "bin_width = dataset_5ms.bin_width\n",
    "print(bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34b3102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371 trials\n",
      "87 neurons\n",
      "(538986, 87)\n",
      "(538986, 87)\n",
      "(538986, 20)\n",
      "PCA total var explained: 0.4726979696371898\n",
      "[0. 6. 6. 4. 6. 2. 0. 4. 6. 4. 6. 0. 4. 4. 4. 4. 4. 6. 4. 0. 6. 6. 0. 6.\n",
      " 6. 2. 4. 6. 0. 2. 6. 4. 4. 0. 6. 6. 6. 0. 0. 2. 2. 6. 4. 4. 0. 6. 6. 6.\n",
      " 6. 6. 2. 6. 6. 0. 2. 2. 2. 4. 6. 0. 2. 0. 0. 2. 0. 6. 2. 0. 0. 4. 6. 2.\n",
      " 6. 6. 2. 0. 0. 6. 0. 6. 0. 4. 0. 4. 0. 4. 6. 6. 6. 0. 0. 6. 2. 0. 4. 0.\n",
      " 4. 0. 2. 2. 2. 2. 4. 2. 0. 0. 0. 0. 6. 6. 0. 0. 4. 2. 6. 4. 0. 6. 2. 6.\n",
      " 4. 0. 2. 4. 4. 4. 6. 4. 4. 0. 2. 4. 2. 2. 0. 0. 2. 4. 2. 2. 4. 0. 6. 2.\n",
      " 4. 6. 6. 6. 4. 4. 6. 2. 6. 4. 6. 2. 4. 6. 2. 4. 6. 2. 0. 2. 6. 6. 2. 4.\n",
      " 6. 6. 2. 6. 4. 6. 4. 2. 6. 0. 0. 0. 2. 0. 4. 0. 4. 0. 2. 4. 4. 2. 4. 2.\n",
      " 4. 4. 6. 6. 4. 0. 4. 4. 4. 0. 0. 4. 0. 6. 4. 0. 2. 0. 0. 2. 0. 4. 0. 4.\n",
      " 2. 2. 2. 2. 4. 0. 4. 4. 6. 4. 0. 4. 4. 0. 0. 6. 4. 2. 0. 4. 6. 6. 4. 0.\n",
      " 6. 4. 4. 6. 2. 0. 2. 0. 2. 6. 2. 6. 2. 2. 0. 0. 4. 2. 4. 2. 2. 6. 0. 0.\n",
      " 6. 6. 0. 0. 0. 0. 2. 2. 0. 0. 6. 0. 6. 4. 6. 6. 0. 6. 4. 2. 4. 2. 6. 2.\n",
      " 6. 6. 0. 4. 6. 0. 0. 2. 0. 0. 4. 0. 4. 6. 4. 6. 2. 4. 6. 6. 6. 2. 6. 2.\n",
      " 0. 4. 0. 2. 2. 2. 2. 4. 6. 6. 4. 4. 2. 2. 2. 0. 0. 0. 2. 2. 2. 0. 6. 4.\n",
      " 2. 2. 2. 2. 6. 6. 6. 0. 4. 4. 6. 2. 4. 6. 6. 2. 6. 0. 2. 4. 0. 4. 6. 6.\n",
      " 4. 0. 6. 0. 6. 0. 0. 6. 2. 4. 0.]\n"
     ]
    }
   ],
   "source": [
    "n_dims = 20 # for PCA\n",
    "\n",
    "active_mask = (~dataset_5ms.trial_info.ctr_hold_bump) & (dataset_5ms.trial_info.split != 'none')\n",
    "passive_mask = (dataset_5ms.trial_info.ctr_hold_bump) & (dataset_5ms.trial_info.split != 'none')\n",
    "\n",
    "\n",
    "trial_mask = active_mask\n",
    "n_trials = dataset_5ms.trial_info.loc[trial_mask].shape[0]\n",
    "print(n_trials,'trials')\n",
    "n_neurons = dataset_5ms.data.spikes.shape[1]\n",
    "print(n_neurons,'neurons')\n",
    "\n",
    "all_data = np.array(dataset_5ms.data.spikes_smth_40)\n",
    "print(all_data.shape)\n",
    "data_for_pca = all_data[~np.isnan(all_data).any(axis=1)]\n",
    "print(data_for_pca.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data_for_pca)\n",
    "pca = PCA(n_components=n_dims)\n",
    "X = pca.fit(X)\n",
    "\n",
    "PCA_data = nans([all_data.shape[0],n_dims])\n",
    "idx = 0\n",
    "for dp in all_data:\n",
    "    dp = dp.reshape((1, -1))\n",
    "    if np.isnan(dp).any():\n",
    "        dp_pca = nans([1,n_dims])\n",
    "    else:\n",
    "        dp_pca = pca.transform(scaler.transform(dp))\n",
    "    PCA_data[idx,:] = dp_pca\n",
    "    idx+=1\n",
    "print(PCA_data.shape)\n",
    "dataset_5ms.add_continuous_data(PCA_data,'PCA')\n",
    "print('PCA total var explained:',sum(pca.explained_variance_ratio_))\n",
    "\n",
    "#make dictionary for trial condition (reaching directions) for Stratified CV\n",
    "active_trials_idx = np.array(dataset_5ms.trial_info.loc[trial_mask]['trial_id'])\n",
    "cond_dir_idx = []\n",
    "cond_dict = nans([n_trials])\n",
    "for direction in [0,45,90,135,180,225,270,315]:\n",
    "    cond_dir_idx.append(np.where((dataset_5ms.trial_info['cond_dir'] == direction) & (dataset_5ms.trial_info['ctr_hold_bump'] == False) & \\\n",
    "           (dataset_5ms.trial_info['split'] != 'none'))[0])\n",
    "i = 0\n",
    "for idx in active_trials_idx:\n",
    "    for cond in range(0,len(cond_dir_idx)):\n",
    "        if idx in cond_dir_idx[cond]:\n",
    "            cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(cond_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf18adf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare for plotting\n",
    "\n",
    "# active_data = dataset_5ms.make_trial_data(align_field='move_onset_time', align_range=(-100, 500), ignored_trials=~trial_mask)\n",
    "# active_trials_pca = nans([n_trials,n_timepoints,n_dims])\n",
    "# i = 0\n",
    "# for idx, trial in active_data.groupby('trial_id'):\n",
    "#     active_trials_pca[i,:,:]=trial.PCA.to_numpy()\n",
    "#     i+=1\n",
    "# print(active_trials_pca.shape)\n",
    "\n",
    "# plot_dir = np.array([0,45,90,135,180,225,270,315]) # limit plot directions to reduce cluttering\n",
    "# directions = np.array([0,45,90,135,180,225,270,315])\n",
    "# pred_range = (-100, 500)\n",
    "# x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "\n",
    "# # define some useful time points\n",
    "# move_idx=0\n",
    "# ret_idx = 200\n",
    "\n",
    "# import matplotlib as mpl\n",
    "# cmap = plt.get_cmap('coolwarm',len(plot_dir))\n",
    "# custom_palette = [mpl.colors.rgb2hex(cmap(i)) for i in range(len(plot_dir))]\n",
    "\n",
    "# plot_dims = 10\n",
    "\n",
    "# fig,ax=plt.subplots(plot_dims,1,figsize=(10,20))\n",
    "# for i in range(plot_dims):\n",
    "#     for j in range(len(plot_dir)):\n",
    "#         color = custom_palette[j]\n",
    "#         dir_idx = np.argwhere(directions == plot_dir[j])[0]\n",
    "#         cond_mean_proj = np.mean(active_trials_pca[np.argwhere(cond_dict==dir_idx).flatten(),:,:], axis = 0)[:,i] \n",
    "#         pca_mean = np.mean(active_data.PCA.to_numpy(),axis = 0)[i]\n",
    "#         ax[i].plot(x_axis,cond_mean_proj - pca_mean,linewidth=2.25,color = color,label = plot_dir[j])\n",
    "        \n",
    "#         ax[i].axvline(move_idx, color='k',linewidth = .5)\n",
    "#         ax[i].axvline(ret_idx, color='k',linewidth = .5)\n",
    "# #         ax[i].set_xlim([0,T])\n",
    "#         ax[i].set_ylim([-6, 6])\n",
    "#         ax[i].axhline(0,color ='k',ls = '--')\n",
    "#         if i<plot_dims-1:\n",
    "#             ax[i].set_xticks([])\n",
    "#         else:\n",
    "#             ax[i].set_xlabel('Time (ms)')\n",
    "            \n",
    "#         ax[i].set_yticks([])\n",
    "#         ax[i].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "#     ax[0].set_title('PCA Projections')\n",
    "    \n",
    "# plt.legend(bbox_to_anchor = (1, 1), loc = 'upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fb1fa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_test(X,y,training_set,test_set):\n",
    "    X_train = X[training_set,:,:]\n",
    "    X_test = X[test_set,:,:]\n",
    "    y_train = y[training_set,:,:]\n",
    "    y_test = y[test_set,:,:]\n",
    "\n",
    "    #flat by trials\n",
    "    X_flat_train = X_train.reshape((X_train.shape[0]*X_train.shape[1]),X_train.shape[2])\n",
    "    X_flat_test = X_test.reshape((X_test.shape[0]*X_test.shape[1]),X_test.shape[2])\n",
    "    y_train=y_train.reshape((y_train.shape[0]*y_train.shape[1]),y_train.shape[2])\n",
    "    y_test=y_test.reshape((y_test.shape[0]*y_test.shape[1]),y_test.shape[2])\n",
    "    \n",
    "    X_flat_train_mean=np.nanmean(X_flat_train,axis=0)\n",
    "    X_flat_train_std=np.nanstd(X_flat_train,axis=0)   \n",
    "    #array with only 0 will have 0 std and cause errors\n",
    "    X_flat_train_std[X_flat_train_std==0] = 1\n",
    "    \n",
    "    X_flat_train=(X_flat_train-X_flat_train_mean)/X_flat_train_std\n",
    "    X_flat_test=(X_flat_test-X_flat_train_mean)/X_flat_train_std\n",
    "    y_train_mean=np.mean(y_train,axis=0)\n",
    "    y_train=y_train-y_train_mean\n",
    "    y_test=y_test-y_train_mean    \n",
    "    \n",
    "    return X_flat_train,X_flat_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f0762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(dataset, trial_mask, align_field, align_range, lag, x_field, y_field):\n",
    "    \"\"\"Extracts spiking and kinematic data from selected trials and fits linear decoder\"\"\"\n",
    "    # Extract rate data from selected trials\n",
    "    vel_df = dataset.make_trial_data(align_field=align_field, align_range=align_range, ignored_trials=~trial_mask)\n",
    "    # Lag alignment for kinematics and extract kinematics data from selected trials\n",
    "    lag_align_range = (align_range[0] + lag, align_range[1] + lag)\n",
    "    rates_df = dataset.make_trial_data(align_field=align_field, align_range=lag_align_range, ignored_trials=~trial_mask)\n",
    "    \n",
    "    n_trials = rates_df['trial_id'].nunique()\n",
    "    n_timepoints = int((align_range[1] - align_range[0])/dataset.bin_width)\n",
    "    n_neurons = rates_df[x_field].shape[1]\n",
    "    \n",
    "    lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)})\n",
    "    rates_array = rates_df[x_field].to_numpy()\n",
    "    vel_array = vel_df[y_field].to_numpy()\n",
    "    lr_all.fit(rates_array, vel_array)\n",
    "    pred_vel = lr_all.predict(rates_array)\n",
    "    vel_df = pd.concat([vel_df, pd.DataFrame(pred_vel, columns=dataset._make_midx('pred_vel', ['x', 'y'], 2))], axis=1)\n",
    "#     print(lr_all.best_params_['alpha'])\n",
    "    \n",
    "    rates_array = rates_array.reshape(n_trials, n_timepoints, n_neurons)\n",
    "    vel_array = vel_array.reshape(n_trials, n_timepoints, 2)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "    true_concat = nans([n_trials*n_timepoints,2])\n",
    "    pred_concat = nans([n_trials*n_timepoints,2])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test, y_train, y_test = process_train_test(rates_array,vel_array,training_set,test_set)\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)}) \n",
    "        lr.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "        \n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "        trial_save_idx += n\n",
    "    \n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    print('R2:',R2) \n",
    "    return R2, lr_all.best_estimator_.coef_, vel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb0e7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_and_predict(dataset, trial_mask, align_field, align_range, lag, x_field, y_field, weights):\n",
    "    \"\"\"Extracts spiking and kinematic data from selected trials and fits linear decoder\"\"\"\n",
    "    # Extract rate data from selected trials\n",
    "    vel_df = dataset.make_trial_data(align_field=align_field, align_range=align_range, ignored_trials=~trial_mask)\n",
    "    # Lag alignment for kinematics and extract kinematics data from selected trials\n",
    "    lag_align_range = (align_range[0] + lag, align_range[1] + lag)\n",
    "    rates_df = dataset.make_trial_data(align_field=align_field, align_range=lag_align_range, ignored_trials=~trial_mask)\n",
    "    \n",
    "    n_trials = rates_df['trial_id'].nunique()\n",
    "    n_timepoints = int((align_range[1] - align_range[0])/dataset.bin_width)\n",
    "    n_neurons = rates_df[x_field].shape[1]\n",
    "\n",
    "    rates_array = rates_df[x_field].to_numpy() - calc_proj(rates_df[x_field].to_numpy(),weights.T).T\n",
    "    vel_array = vel_df[y_field].to_numpy()\n",
    "    \n",
    "    lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)})\n",
    "    lr_all.fit(rates_array, vel_array)\n",
    "    pred_vel = lr_all.predict(rates_array)\n",
    "    vel_df = pd.concat([vel_df, pd.DataFrame(pred_vel, columns=dataset._make_midx('pred_vel', ['x', 'y'], 2))], axis=1)\n",
    "#     print(lr_all.best_params_['alpha'])\n",
    "    \n",
    "    rates_array = rates_array.reshape(n_trials, n_timepoints, n_neurons)\n",
    "    vel_array = vel_array.reshape(n_trials, n_timepoints, 2)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "    true_concat = nans([n_trials*n_timepoints,2])\n",
    "    pred_concat = nans([n_trials*n_timepoints,2])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test, y_train, y_test = process_train_test(rates_array,vel_array,training_set,test_set)\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)}) \n",
    "        lr.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "        \n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "        trial_save_idx += n\n",
    "    \n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    print('R2:',R2) \n",
    "    return R2, lr_all.best_estimator_.coef_, vel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257bacfe",
   "metadata": {},
   "source": [
    "## with Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "106dc233",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_axis = np.arange(-300,300,20)\n",
    "x_field = 'spikes_smth_40'\n",
    "y_field ='hand_vel'\n",
    "trial_mask = active_mask\n",
    "\n",
    "# Prepare for plotting\n",
    "plot_dir = [0.0, 90.0, 180.0, 270.0] # limit plot directions to reduce cluttering\n",
    "plot_dim = 'x' # plot x velocity\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/neurons/act/\"\n",
    "\n",
    "dim = n_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21a60097",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.04487391562437748\n",
      "R2: 0.06957057596127358\n",
      "R2: 0.09804973776191162\n",
      "R2: 0.1308959198200862\n",
      "R2: 0.1691114312981591\n",
      "R2: 0.21331173367960976\n",
      "R2: 0.2626127954119539\n",
      "R2: 0.31507136141787573\n",
      "R2: 0.3683185149050926\n",
      "R2: 0.42041304582226857\n",
      "R2: 0.46989235143346164\n",
      "R2: 0.5147226184887073\n",
      "R2: 0.552611615874187\n",
      "R2: 0.58171696310109\n",
      "R2: 0.6015942818640538\n",
      "R2: 0.6128427785002228\n",
      "R2: 0.6160987909721423\n",
      "R2: 0.6120028245611691\n",
      "R2: 0.6017528693457472\n",
      "R2: 0.5870101450328304\n",
      "R2: 0.5697738351216108\n",
      "R2: 0.5521672812537423\n",
      "R2: 0.5361227200877473\n",
      "R2: 0.5230898340263261\n",
      "R2: 0.5133828972598026\n",
      "R2: 0.5059570854972484\n",
      "R2: 0.4991485943549392\n",
      "R2: 0.4916334111249465\n",
      "R2: 0.4827250041457416\n",
      "R2: 0.47232650511179763\n",
      "R2: 0.6160987909721423\n",
      "R2: 0.03926321917679165\n",
      "R2: 0.06080448887424339\n",
      "R2: 0.08475324606850754\n",
      "R2: 0.11152864551054864\n",
      "R2: 0.1419252628608193\n",
      "R2: 0.17621192510889228\n",
      "R2: 0.21297270489330478\n",
      "R2: 0.24919498008020324\n",
      "R2: 0.2819024642061516\n",
      "R2: 0.30988008239002574\n",
      "R2: 0.3338784462739306\n",
      "R2: 0.3556821460436823\n",
      "R2: 0.37682283379888704\n",
      "R2: 0.3954189408780374\n",
      "R2: 0.4079872670244369\n",
      "R2: 0.415140121747431\n",
      "R2: 0.4195067965593562\n",
      "R2: 0.42333611275729544\n",
      "R2: 0.4279866887446513\n",
      "R2: 0.4338920867783419\n",
      "R2: 0.44087206401751033\n",
      "R2: 0.448266575101121\n",
      "R2: 0.455437515646823\n",
      "R2: 0.46209777859210543\n",
      "R2: 0.4678467684078591\n",
      "R2: 0.4718633325949383\n",
      "R2: 0.47320504965298105\n",
      "R2: 0.47133056338550405\n",
      "R2: 0.46619493034695103\n",
      "R2: 0.4581443243852611\n",
      "R2: 0.47320504965298105\n",
      "R2: 0.04180761111599329\n",
      "R2: 0.06326510714991207\n",
      "R2: 0.08697384330341051\n",
      "R2: 0.11344015987473643\n",
      "R2: 0.14356618446862524\n",
      "R2: 0.17760794502402455\n",
      "R2: 0.21427011778889538\n",
      "R2: 0.25111816860303127\n",
      "R2: 0.28566148395050084\n",
      "R2: 0.3161710218009215\n",
      "R2: 0.3417931471392148\n",
      "R2: 0.36225658594657795\n",
      "R2: 0.37769607999754606\n",
      "R2: 0.388347096332744\n",
      "R2: 0.39454146387093925\n",
      "R2: 0.3974699397535141\n",
      "R2: 0.39856544286584494\n",
      "R2: 0.3989015023147078\n",
      "R2: 0.3994473967577187\n",
      "R2: 0.40098741593167375\n",
      "R2: 0.4038192097862544\n",
      "R2: 0.40787163741954924\n",
      "R2: 0.412942399657272\n",
      "R2: 0.4187378025888273\n",
      "R2: 0.4245328281879518\n",
      "R2: 0.4292183075935927\n",
      "R2: 0.43184696730965144\n",
      "R2: 0.4321005091400403\n",
      "R2: 0.430099619146987\n",
      "R2: 0.42604184198861195\n",
      "R2: 0.4321005091400403\n",
      "R2: 0.04191573084693867\n",
      "R2: 0.06230766646067498\n",
      "R2: 0.08478878582294302\n",
      "R2: 0.10979780854795662\n",
      "R2: 0.1382845454948507\n",
      "R2: 0.17074743221728161\n",
      "R2: 0.20614456773607948\n",
      "R2: 0.24206911253190155\n",
      "R2: 0.27578298795149025\n",
      "R2: 0.3052588447010949\n",
      "R2: 0.3294430032101019\n",
      "R2: 0.34785699589771113\n",
      "R2: 0.3605377509659533\n",
      "R2: 0.3680714783470477\n",
      "R2: 0.37118628942746323\n",
      "R2: 0.3709796524016066\n",
      "R2: 0.368868525639264\n",
      "R2: 0.3661316280345077\n",
      "R2: 0.3637811857379806\n",
      "R2: 0.36223725797826023\n",
      "R2: 0.36162288052761815\n",
      "R2: 0.3622110711921692\n",
      "R2: 0.3642178121587889\n",
      "R2: 0.3676354315956928\n",
      "R2: 0.3719300435605525\n",
      "R2: 0.3758534680029695\n",
      "R2: 0.37811020100257386\n",
      "R2: 0.37814228062624067\n",
      "R2: 0.37590208496015776\n",
      "R2: 0.37160485698497037\n",
      "R2: 0.37814228062624067\n",
      "R2: 0.04314416446320557\n",
      "R2: 0.06390617048317049\n",
      "R2: 0.08681491638834715\n",
      "R2: 0.11222220198413968\n",
      "R2: 0.1408837295981924\n",
      "R2: 0.1731223027557801\n",
      "R2: 0.20797492071021162\n",
      "R2: 0.24336993785424865\n",
      "R2: 0.2769551884726097\n",
      "R2: 0.3066500943782493\n",
      "R2: 0.3307705565126179\n",
      "R2: 0.34819135981375293\n",
      "R2: 0.3586603093777815\n",
      "R2: 0.3630213765630358\n",
      "R2: 0.3627969882778245\n",
      "R2: 0.3595814866501238\n",
      "R2: 0.3546891371686369\n",
      "R2: 0.34903427824601874\n",
      "R2: 0.3432402307736031\n",
      "R2: 0.3377351657281401\n",
      "R2: 0.33286927345016204\n",
      "R2: 0.32914810023151175\n",
      "R2: 0.326990625953651\n",
      "R2: 0.3265560592607115\n",
      "R2: 0.32760753956565836\n",
      "R2: 0.329204274484758\n",
      "R2: 0.3300475751247782\n",
      "R2: 0.32939627119416637\n",
      "R2: 0.3272319008657747\n",
      "R2: 0.32400783010906087\n",
      "R2: 0.3630213765630358\n",
      "R2: 0.03771663650942725\n",
      "R2: 0.05656289885312282\n",
      "R2: 0.07679720864349626\n",
      "R2: 0.09874511433656197\n",
      "R2: 0.12297885038004541\n",
      "R2: 0.1496181991025931\n",
      "R2: 0.17792259750677664\n",
      "R2: 0.20642321170689826\n",
      "R2: 0.23329660827030374\n",
      "R2: 0.25677920539490584\n",
      "R2: 0.2755054040195739\n",
      "R2: 0.28892317419679026\n",
      "R2: 0.2974505252615829\n",
      "R2: 0.3021910238108535\n",
      "R2: 0.30432499279563485\n",
      "R2: 0.3048800655026349\n",
      "R2: 0.30482643365054296\n",
      "R2: 0.3048924344343392\n",
      "R2: 0.30542680412617185\n",
      "R2: 0.3063842357822134\n",
      "R2: 0.307595175918159\n",
      "R2: 0.30922153614153647\n",
      "R2: 0.3116579280165198\n",
      "R2: 0.3151995760088854\n",
      "R2: 0.31964275916783247\n",
      "R2: 0.3239815171292866\n",
      "R2: 0.3268552964706377\n",
      "R2: 0.3274660183785204\n",
      "R2: 0.3258440852171075\n",
      "R2: 0.3226829525581465\n",
      "R2: 0.3274660183785204\n",
      "R2: 0.03848636285806095\n",
      "R2: 0.0571313755540197\n",
      "R2: 0.07707555046415904\n",
      "R2: 0.09874671245900002\n",
      "R2: 0.12277135925316918\n",
      "R2: 0.14925567675188134\n",
      "R2: 0.17747507978535437\n",
      "R2: 0.2060081009998861\n",
      "R2: 0.23300452750709588\n",
      "R2: 0.256625478762457\n",
      "R2: 0.27545727282294064\n",
      "R2: 0.2889178408397064\n",
      "R2: 0.2973530666109786\n",
      "R2: 0.30174189194524004\n",
      "R2: 0.3031526971506763\n",
      "R2: 0.30253892684646644\n",
      "R2: 0.3007692828448677\n",
      "R2: 0.2983532136744902\n",
      "R2: 0.2954407412173137\n",
      "R2: 0.2920913181039605\n",
      "R2: 0.28841980474187\n",
      "R2: 0.28475738416653174\n",
      "R2: 0.2816064443455921\n",
      "R2: 0.27943922307674507\n",
      "R2: 0.27834201445122375\n",
      "R2: 0.27784073862411174\n",
      "R2: 0.2771093078893597\n",
      "R2: 0.2754154749385678\n",
      "R2: 0.27263143863650974\n",
      "R2: 0.2693441099605044\n",
      "R2: 0.3031526971506763\n",
      "R2: 0.03014220584878402\n",
      "R2: 0.04651338543579264\n",
      "R2: 0.06334343608103876\n",
      "R2: 0.08093247144841786\n",
      "R2: 0.09966688960494463\n",
      "R2: 0.11928700895566724\n",
      "R2: 0.13876713929113482\n",
      "R2: 0.15680213745460125\n",
      "R2: 0.17203831461083352\n",
      "R2: 0.1831476510169764\n",
      "R2: 0.189386788689896\n",
      "R2: 0.19127927346708873\n",
      "R2: 0.19044329590451603\n",
      "R2: 0.18889215978177487\n",
      "R2: 0.18841151154750124\n",
      "R2: 0.1901760805555408\n",
      "R2: 0.1946277016214215\n",
      "R2: 0.2013777866531009\n",
      "R2: 0.20943897832881797\n",
      "R2: 0.21770017233416117\n",
      "R2: 0.22537349230399362\n",
      "R2: 0.23213088548826533\n",
      "R2: 0.2378173324297551\n",
      "R2: 0.24236759793686113\n",
      "R2: 0.24584590123222205\n",
      "R2: 0.24825565346553113\n",
      "R2: 0.24933649191147822\n",
      "R2: 0.24869703517178676\n",
      "R2: 0.24645287774898017\n",
      "R2: 0.2435824104193488\n",
      "R2: 0.24933649191147822\n"
     ]
    }
   ],
   "source": [
    "pred_range = (-100, 500)\n",
    "label = '_whole_'\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "\n",
    "curr_r2_array = nans([len(lag_axis)])\n",
    "curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "    curr_r2_array[i] = r2\n",
    "    curr_coef_array[i,:,:] = coef\n",
    "\n",
    "idx_max = np.argmax(curr_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "_, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.hand_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + 'true.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(lag_axis, curr_r2_array)\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.title('R2 score predicting hand velocity [-100,500]')\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "# ang_dist_to_max = nans([len(lag_axis)])\n",
    "# for i in range(0, len(curr_coef_array)):\n",
    "#     ang_dist_to_max[i] = math.degrees(angle_between(curr_coef_array[i,0,:],curr_coef_array[idx_max,0,:]))\n",
    "# plt.scatter(lag_axis, ang_dist_to_max)\n",
    "# plt.title('Angular distance to X-vel decoding dim at t_max')\n",
    "# plt.xlabel('Time lag (ms)')\n",
    "# plt.ylabel('Angular distance (degrees)')\n",
    "# plt.show()\n",
    "\n",
    "weights = curr_coef_array[idx_max,:,:]\n",
    "for iter in range(0,7):  \n",
    "    #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "    sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "    sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "        sub_r2_array[i] = r2\n",
    "        sub_coef_array[i,:,:] = coef\n",
    "\n",
    "    plt.plot(lag_axis,sub_r2_array)\n",
    "    plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "    idx_max = np.argmax(sub_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('x-vel')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "#     plt.plot(lag_axis,np.subtract(sub_r2_array,curr_r2_array))\n",
    "#     plt.axhline(0,color = 'k',linestyle='--')\n",
    "#     plt.title('R2 difference after projecting out t_max dim')\n",
    "#     plt.xlabel('Time lag (ms)')\n",
    "#     plt.ylabel('R2 difference')\n",
    "#     plt.show()\n",
    "#     curr_r2_array = sub_r2_array\n",
    "\n",
    "    #stack the decoding dimensions to be projected out\n",
    "    weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad8771f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.17144769637932256\n",
      "R2: -0.18960197011496294\n",
      "R2: -0.23853637136404315\n",
      "R2: -0.30057508443337255\n",
      "R2: -0.32038765265819347\n",
      "R2: -0.2714794605090982\n",
      "R2: -0.23754155734290228\n",
      "R2: -0.20794353090780637\n",
      "R2: -0.11992783329039058\n",
      "R2: 0.0430098873603495\n",
      "R2: 0.2266010901957053\n",
      "R2: 0.38585624269844343\n",
      "R2: 0.4924175203679172\n",
      "R2: 0.5561060924519965\n",
      "R2: 0.5892108339427159\n",
      "R2: 0.5955604440279927\n",
      "R2: 0.5893925703277675\n",
      "R2: 0.5849634701395976\n",
      "R2: 0.5789492247957497\n",
      "R2: 0.568057965889406\n",
      "R2: 0.5687450947291666\n",
      "R2: 0.5674674788466568\n",
      "R2: 0.5599339334533522\n",
      "R2: 0.5460269616607429\n",
      "R2: 0.5254830062941698\n",
      "R2: 0.5068300094067473\n",
      "R2: 0.4938975192816373\n",
      "R2: 0.4888143978869912\n",
      "R2: 0.3819459469337636\n",
      "R2: 0.40291896115888914\n",
      "R2: 0.5955604440279927\n",
      "R2: -0.1668270924685018\n",
      "R2: -0.18380863725126573\n",
      "R2: -0.22443543209737427\n",
      "R2: -0.2689755659854016\n",
      "R2: -0.2813595839021412\n",
      "R2: -0.2312747319590125\n",
      "R2: -0.19291200327099878\n",
      "R2: -0.18574629449112434\n",
      "R2: -0.13060564337845637\n",
      "R2: 0.012044650516197741\n",
      "R2: 0.17048006477313538\n",
      "R2: 0.2890656115410447\n",
      "R2: 0.35041204556924965\n",
      "R2: 0.35255267599268614\n",
      "R2: 0.35458156251567574\n",
      "R2: 0.3884076100139754\n",
      "R2: 0.42058649713540985\n",
      "R2: 0.4428016382136958\n",
      "R2: 0.435547455367165\n",
      "R2: 0.3964232130374157\n",
      "R2: 0.49372385111419903\n",
      "R2: 0.527768066963756\n",
      "R2: 0.5384274233959191\n",
      "R2: 0.5324093695622063\n",
      "R2: 0.5149564649722398\n",
      "R2: 0.4983323762648444\n",
      "R2: 0.4883792187517978\n",
      "R2: 0.4838353444799488\n",
      "R2: 0.480490171353838\n",
      "R2: 0.4740592613267407\n",
      "R2: 0.5384274233959191\n",
      "R2: -0.1573477053350314\n",
      "R2: -0.17471020624321\n",
      "R2: -0.2120198378890361\n",
      "R2: -0.25281260682716566\n",
      "R2: -0.2700732052329926\n",
      "R2: -0.23469908141232598\n",
      "R2: -0.19305184089531147\n",
      "R2: -0.16709165172971407\n",
      "R2: -0.11345322277126368\n",
      "R2: -0.0025026412992767977\n",
      "R2: 0.1294226994090929\n",
      "R2: 0.23894771207998222\n",
      "R2: 0.29894151911435884\n",
      "R2: 0.3063230480756616\n",
      "R2: 0.3056024900950305\n",
      "R2: 0.3225077715196353\n",
      "R2: 0.34320479066520104\n",
      "R2: 0.36108416408318333\n",
      "R2: 0.35232066879983903\n",
      "R2: 0.3302394279203257\n",
      "R2: 0.31593973660160846\n",
      "R2: 0.2868507729717127\n",
      "R2: 0.2666602213173166\n",
      "R2: 0.2697750943905901\n",
      "R2: 0.29091541197011284\n",
      "R2: 0.3221585951140846\n",
      "R2: 0.359079502698751\n",
      "R2: 0.39705030253211926\n",
      "R2: 0.4320857188803813\n",
      "R2: 0.4571434289703227\n",
      "R2: 0.4571434289703227\n",
      "R2: -0.15224348933978993\n",
      "R2: -0.17026311775421799\n",
      "R2: -0.20089842738554742\n",
      "R2: -0.23661869086727783\n",
      "R2: -0.25365263204351285\n",
      "R2: -0.23064833098447712\n",
      "R2: -0.19386180554318866\n",
      "R2: -0.1624949817723167\n",
      "R2: -0.1026985513429679\n",
      "R2: 0.005665281311673209\n",
      "R2: 0.13527686051568544\n",
      "R2: 0.2482440035716128\n",
      "R2: 0.3109433416925309\n",
      "R2: 0.31729738946483776\n",
      "R2: 0.3106012954710813\n",
      "R2: 0.3206327756275684\n",
      "R2: 0.3384019412138741\n",
      "R2: 0.36055508514855594\n",
      "R2: 0.37702658305493697\n",
      "R2: 0.36523757495881226\n",
      "R2: 0.3222581843010628\n",
      "R2: 0.27630939820499034\n",
      "R2: 0.2535465194892149\n",
      "R2: 0.25095286622824375\n",
      "R2: 0.2566701170138611\n",
      "R2: 0.26183213261591043\n",
      "R2: 0.25622797891470495\n",
      "R2: 0.23488932987034206\n",
      "R2: 0.216064456329501\n",
      "R2: 0.2237836086856958\n",
      "R2: 0.37702658305493697\n"
     ]
    }
   ],
   "source": [
    "pred_range = (0, 120)\n",
    "label = '_early_'\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "\n",
    "curr_r2_array = nans([len(lag_axis)])\n",
    "curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "    curr_r2_array[i] = r2\n",
    "    curr_coef_array[i,:,:] = coef\n",
    "\n",
    "idx_max = np.argmax(curr_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "_, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.hand_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + 'true.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(lag_axis, curr_r2_array)\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.title('R2 score predicting hand velocity [0,120]')\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "weights = curr_coef_array[idx_max,:,:]\n",
    "for iter in range(0,3):  \n",
    "    #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "    sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "    sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "        sub_r2_array[i] = r2\n",
    "        sub_coef_array[i,:,:] = coef\n",
    "\n",
    "    plt.plot(lag_axis,sub_r2_array)\n",
    "    plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "    idx_max = np.argmax(sub_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('x-vel')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    #stack the decoding dimensions to be projected out\n",
    "    weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca42adc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.38525820554664825\n",
      "R2: 0.38707635252648176\n",
      "R2: 0.3773383281831364\n",
      "R2: 0.37799470134855195\n",
      "R2: 0.39339459463002147\n",
      "R2: 0.4149754764297644\n",
      "R2: 0.44001422323045036\n",
      "R2: 0.46868852038927256\n",
      "R2: 0.49721458469882573\n",
      "R2: 0.4749919393654032\n",
      "R2: 0.46082424125104116\n",
      "R2: 0.5031003362197723\n",
      "R2: 0.5428885898690555\n",
      "R2: 0.5923360707010129\n",
      "R2: 0.6097290537907152\n",
      "R2: 0.6191041802286824\n",
      "R2: 0.6166095401935408\n",
      "R2: 0.606164189337595\n",
      "R2: 0.5977415386302625\n",
      "R2: 0.5916230506025818\n",
      "R2: 0.5803987418668325\n",
      "R2: 0.5614601360418886\n",
      "R2: 0.5321161559970004\n",
      "R2: 0.49676397389687377\n",
      "R2: 0.463046741407105\n",
      "R2: 0.4296449160305177\n",
      "R2: 0.3994392260130196\n",
      "R2: 0.37714947222273265\n",
      "R2: 0.3542175224163765\n",
      "R2: 0.3262207783886649\n",
      "R2: 0.6191041802286824\n",
      "R2: 0.38928971124597245\n",
      "R2: 0.38323731071795897\n",
      "R2: 0.3617770932330153\n",
      "R2: 0.3565074118103265\n",
      "R2: 0.37877604224304173\n",
      "R2: 0.40927886900665134\n",
      "R2: 0.437337170263263\n",
      "R2: 0.4574568744173221\n",
      "R2: 0.4485005496556732\n",
      "R2: 0.38722296986579907\n",
      "R2: 0.2935024448063456\n",
      "R2: 0.24372751077920785\n",
      "R2: 0.24717941406248878\n",
      "R2: 0.4448829333689295\n",
      "R2: 0.48798512947437744\n",
      "R2: 0.5047521291784534\n",
      "R2: 0.5164707358602334\n",
      "R2: 0.5228696289821704\n",
      "R2: 0.5346247597070994\n",
      "R2: 0.541557006553044\n",
      "R2: 0.5381740630798395\n",
      "R2: 0.525032129501598\n",
      "R2: 0.502918706687393\n",
      "R2: 0.4773158283548802\n",
      "R2: 0.45359551432952805\n",
      "R2: 0.4295568310695854\n",
      "R2: 0.40444213660843154\n",
      "R2: 0.37978290759938527\n",
      "R2: 0.35138881210605877\n",
      "R2: 0.33139162245354714\n",
      "R2: 0.541557006553044\n",
      "R2: 0.38267679679906963\n",
      "R2: 0.3817945442950853\n",
      "R2: 0.37328804893827094\n",
      "R2: 0.37151606493359435\n",
      "R2: 0.3840811445972955\n",
      "R2: 0.40375685909461745\n",
      "R2: 0.4208129884810129\n",
      "R2: 0.4304196431227062\n",
      "R2: 0.43669268927968896\n",
      "R2: 0.44265883228300307\n",
      "R2: 0.44593370225996465\n",
      "R2: 0.4246543132224667\n",
      "R2: 0.3917241703412855\n",
      "R2: 0.4163431319008678\n",
      "R2: 0.458775574878841\n",
      "R2: 0.45849955917236784\n",
      "R2: 0.4370532640069601\n",
      "R2: 0.40180352362241334\n",
      "R2: 0.36323205802625047\n",
      "R2: 0.34008077792930913\n",
      "R2: 0.3384695986127122\n",
      "R2: 0.34990595117634293\n",
      "R2: 0.36618268400634046\n",
      "R2: 0.3811318395999779\n",
      "R2: 0.38972667652675674\n",
      "R2: 0.3870588060171206\n",
      "R2: 0.371105225549324\n",
      "R2: 0.35016184138205975\n",
      "R2: 0.33058774623098663\n",
      "R2: 0.31076808607049056\n",
      "R2: 0.458775574878841\n",
      "R2: 0.3680977739783462\n",
      "R2: 0.3562556980274544\n",
      "R2: 0.3294420308895556\n",
      "R2: 0.310924825754051\n",
      "R2: 0.31573281185434476\n",
      "R2: 0.33311315657242413\n",
      "R2: 0.3481858764698751\n",
      "R2: 0.3504978624127072\n",
      "R2: 0.33987807926623426\n",
      "R2: 0.3198545293468401\n",
      "R2: 0.2973270458552657\n",
      "R2: 0.28005761738511026\n",
      "R2: 0.2733779159746289\n",
      "R2: 0.27547386105959826\n",
      "R2: 0.28840012209812815\n",
      "R2: 0.30455937904304997\n",
      "R2: 0.3091474692359317\n",
      "R2: 0.3042022517968852\n",
      "R2: 0.3016583421595459\n",
      "R2: 0.3060458696102498\n",
      "R2: 0.318326405065682\n",
      "R2: 0.3349592261020333\n",
      "R2: 0.3503639632571558\n",
      "R2: 0.3589321570829619\n",
      "R2: 0.35832910137605445\n",
      "R2: 0.3509916631958707\n",
      "R2: 0.33834578089901046\n",
      "R2: 0.3214787654087192\n",
      "R2: 0.3059728782747133\n",
      "R2: 0.2876496328257172\n",
      "R2: 0.3680977739783462\n"
     ]
    }
   ],
   "source": [
    "pred_range = (380, 500)\n",
    "label = '_late_'\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "\n",
    "curr_r2_array = nans([len(lag_axis)])\n",
    "curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "    curr_r2_array[i] = r2\n",
    "    curr_coef_array[i,:,:] = coef\n",
    "\n",
    "idx_max = np.argmax(curr_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "_, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.hand_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + 'true.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(lag_axis, curr_r2_array)\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.title('R2 score predicting hand velocity [380,500]')\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "weights = curr_coef_array[idx_max,:,:]\n",
    "for iter in range(0,3):  \n",
    "    #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "    sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "    sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "        sub_r2_array[i] = r2\n",
    "        sub_coef_array[i,:,:] = coef\n",
    "\n",
    "    plt.plot(lag_axis,sub_r2_array)\n",
    "    plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "    idx_max = np.argmax(sub_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('x-vel')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    #stack the decoding dimensions to be projected out\n",
    "    weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f030f4",
   "metadata": {},
   "source": [
    "## with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56d6d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_field = 'PCA'\n",
    "y_field ='hand_vel'\n",
    "lag_axis = np.arange(-300,300,20)\n",
    "\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/PCA/act/\"\n",
    "\n",
    "dim = n_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8e9b431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.049721302436977144\n",
      "R2: 0.06710173035639588\n",
      "R2: 0.08830056259344021\n",
      "R2: 0.11395545256097306\n",
      "R2: 0.14448320279799942\n",
      "R2: 0.17992094896974964\n",
      "R2: 0.21991979701224562\n",
      "R2: 0.26379106171180267\n",
      "R2: 0.31034673900508014\n",
      "R2: 0.3578054020478617\n",
      "R2: 0.4039630156554378\n",
      "R2: 0.44644547482717867\n",
      "R2: 0.4831955200862339\n",
      "R2: 0.5129089866623612\n",
      "R2: 0.5350828266490762\n",
      "R2: 0.5498056811917367\n",
      "R2: 0.5574449267245716\n",
      "R2: 0.5585921894959761\n",
      "R2: 0.5541636658276785\n",
      "R2: 0.545274160075264\n",
      "R2: 0.5332659911994232\n",
      "R2: 0.5198761580733626\n",
      "R2: 0.5069546196501644\n",
      "R2: 0.4957508646578034\n",
      "R2: 0.4863644741928337\n",
      "R2: 0.4778790836030775\n",
      "R2: 0.4690996234219509\n",
      "R2: 0.45925105242814324\n",
      "R2: 0.44817206999663284\n",
      "R2: 0.4361442082298802\n",
      "R2: 0.5585921894959761\n",
      "R2: 0.039826988015280174\n",
      "R2: 0.051375449704841425\n",
      "R2: 0.06412382994320776\n",
      "R2: 0.07815637267468634\n",
      "R2: 0.09345634070606024\n",
      "R2: 0.10980094149035935\n",
      "R2: 0.1266884042217068\n",
      "R2: 0.14334528818976566\n",
      "R2: 0.15874183073820458\n",
      "R2: 0.17173587356369657\n",
      "R2: 0.18129007199864378\n",
      "R2: 0.1866496911094625\n",
      "R2: 0.1876068501089\n",
      "R2: 0.18482751687263899\n",
      "R2: 0.17986044688629232\n",
      "R2: 0.1747352312037871\n",
      "R2: 0.1713695694284436\n",
      "R2: 0.1712466391629064\n",
      "R2: 0.17517445406636523\n",
      "R2: 0.18316287026935418\n",
      "R2: 0.19475158798427983\n",
      "R2: 0.20944262425032267\n",
      "R2: 0.22651872027925435\n",
      "R2: 0.24459245865302726\n",
      "R2: 0.2616668321245367\n",
      "R2: 0.2756973992554318\n",
      "R2: 0.28528404547816777\n",
      "R2: 0.29003895917103983\n",
      "R2: 0.2903647388136027\n",
      "R2: 0.2870215673551476\n",
      "R2: 0.2903647388136027\n",
      "R2: 0.03873208771319969\n",
      "R2: 0.050115835736602055\n",
      "R2: 0.06255522625724297\n",
      "R2: 0.07594190714894555\n",
      "R2: 0.09013324466020678\n",
      "R2: 0.10486263275740015\n",
      "R2: 0.11965362823679226\n",
      "R2: 0.13380005446990095\n",
      "R2: 0.14631443961146984\n",
      "R2: 0.15601125153523332\n",
      "R2: 0.16181335158927368\n",
      "R2: 0.1630511617559175\n",
      "R2: 0.1595884255723241\n",
      "R2: 0.1519970279280881\n",
      "R2: 0.14166783540461503\n",
      "R2: 0.13045755188298014\n",
      "R2: 0.11992597395641014\n",
      "R2: 0.1109797840225466\n",
      "R2: 0.10390233254187675\n",
      "R2: 0.0982812634909046\n",
      "R2: 0.09334526394959419\n",
      "R2: 0.08856971217060117\n",
      "R2: 0.08373584748569751\n",
      "R2: 0.07859319757209848\n",
      "R2: 0.07294874267287044\n",
      "R2: 0.06677755353344816\n",
      "R2: 0.06008184868277355\n",
      "R2: 0.05294615425777416\n",
      "R2: 0.045676758785245575\n",
      "R2: 0.03880419032500737\n",
      "R2: 0.1630511617559175\n",
      "R2: 0.0053104305082487535\n",
      "R2: 0.007677912459851721\n",
      "R2: 0.009994816502322368\n",
      "R2: 0.012094293795653077\n",
      "R2: 0.01396282917170133\n",
      "R2: 0.015692561673045113\n",
      "R2: 0.017342259651478065\n",
      "R2: 0.018880917391648433\n",
      "R2: 0.020250016544451133\n",
      "R2: 0.021437294297774745\n",
      "R2: 0.02251700620866881\n",
      "R2: 0.023741468915703612\n",
      "R2: 0.02559125351196534\n",
      "R2: 0.02861564867651034\n",
      "R2: 0.03316494333184483\n",
      "R2: 0.039157452526534686\n",
      "R2: 0.04595700602845909\n",
      "R2: 0.05255496954144079\n",
      "R2: 0.05798584332286583\n",
      "R2: 0.06155673801556183\n",
      "R2: 0.06292269126522476\n",
      "R2: 0.06212886549377339\n",
      "R2: 0.05950733017532328\n",
      "R2: 0.05547767196551534\n",
      "R2: 0.05049952898235499\n",
      "R2: 0.045019374182017846\n",
      "R2: 0.03941336792050876\n",
      "R2: 0.03406773690268239\n",
      "R2: 0.029401433294211188\n",
      "R2: 0.025820991249892455\n",
      "R2: 0.06292269126522476\n"
     ]
    }
   ],
   "source": [
    "pred_range = (-100, 500)\n",
    "label = '_whole_'\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "\n",
    "curr_r2_array = nans([len(lag_axis)])\n",
    "curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "    curr_r2_array[i] = r2\n",
    "    curr_coef_array[i,:,:] = coef\n",
    "\n",
    "idx_max = np.argmax(curr_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "_, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(lag_axis, curr_r2_array)\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.title('R2 score predicting hand velocity [-100,500]')\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "weights = curr_coef_array[idx_max,:,:]\n",
    "for iter in range(0,3):  \n",
    "    #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "    sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "    sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "        sub_r2_array[i] = r2\n",
    "        sub_coef_array[i,:,:] = coef\n",
    "\n",
    "    plt.plot(lag_axis,sub_r2_array)\n",
    "    plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "    idx_max = np.argmax(sub_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('x-vel')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    #stack the decoding dimensions to be projected out\n",
    "    weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bad9fe30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.0447749909065811\n",
      "R2: -0.049479313498691946\n",
      "R2: -0.04894865493423439\n",
      "R2: -0.04267213277405024\n",
      "R2: -0.03558467071344551\n",
      "R2: -0.032099802798039034\n",
      "R2: -0.029954067556268393\n",
      "R2: -0.020272993314270016\n",
      "R2: 0.01666658081516481\n",
      "R2: 0.09959913236834372\n",
      "R2: 0.2183903688070863\n",
      "R2: 0.3407067306166158\n",
      "R2: 0.43623037137125753\n",
      "R2: 0.49326341795241513\n",
      "R2: 0.5166885422345626\n",
      "R2: 0.5186901830962132\n",
      "R2: 0.5167876850692164\n",
      "R2: 0.5216712853647987\n",
      "R2: 0.5314529745214682\n",
      "R2: 0.5400841494630995\n",
      "R2: 0.5462790984699961\n",
      "R2: 0.5506414364632507\n",
      "R2: 0.5510140828776319\n",
      "R2: 0.5436461769241279\n",
      "R2: 0.529930095017792\n",
      "R2: 0.5178149350448992\n",
      "R2: 0.5123670299911232\n",
      "R2: 0.5122172035944931\n",
      "R2: 0.513184808679229\n",
      "R2: 0.5090261134271288\n",
      "R2: 0.5510140828776319\n",
      "R2: -0.03960815673914997\n",
      "R2: -0.046045417268753\n",
      "R2: -0.04531890237824365\n",
      "R2: -0.038688462411687885\n",
      "R2: -0.03201577020247193\n",
      "R2: -0.028779821981347986\n",
      "R2: -0.02673727542759541\n",
      "R2: -0.0208318172365054\n",
      "R2: 0.0014480333938419188\n",
      "R2: 0.060695410449311704\n",
      "R2: 0.16123752546844738\n",
      "R2: 0.27568661440350983\n",
      "R2: 0.3679096850736149\n",
      "R2: 0.4209800708204974\n",
      "R2: 0.437271020095087\n",
      "R2: 0.4286643069590962\n",
      "R2: 0.4124963471195445\n",
      "R2: 0.3969112129252681\n",
      "R2: 0.37641533312435427\n",
      "R2: 0.3400160808409679\n",
      "R2: 0.283469751947108\n",
      "R2: 0.21500751920560812\n",
      "R2: 0.15882461785921276\n",
      "R2: 0.13752087723256312\n",
      "R2: 0.15194403991964134\n",
      "R2: 0.18614458787856747\n",
      "R2: 0.22851803169729312\n",
      "R2: 0.27589044776375393\n",
      "R2: 0.30754682026449764\n",
      "R2: 0.32309309487879334\n",
      "R2: 0.437271020095087\n",
      "R2: -0.03524050381755761\n",
      "R2: -0.04212773615644405\n",
      "R2: -0.041686437609877114\n",
      "R2: -0.036011465089470285\n",
      "R2: -0.03203183593164538\n",
      "R2: -0.03266289648476972\n",
      "R2: -0.03404808330588183\n",
      "R2: -0.030811682270617036\n",
      "R2: -0.018223637831603634\n",
      "R2: 0.005583703966324904\n",
      "R2: 0.03485792219929529\n",
      "R2: 0.05762719947742245\n",
      "R2: 0.05750712163761584\n",
      "R2: 0.03192040470527069\n",
      "R2: 0.019722562221297535\n",
      "R2: 0.03528387364010066\n",
      "R2: 0.06463732658634769\n",
      "R2: 0.10475757051013823\n",
      "R2: 0.14456186588755848\n",
      "R2: 0.1658666461845698\n",
      "R2: 0.15805474098915584\n",
      "R2: 0.1291188917766931\n",
      "R2: 0.10104481663313747\n",
      "R2: 0.09108846525563385\n",
      "R2: 0.10256440549963897\n",
      "R2: 0.1254708858282213\n",
      "R2: 0.15819442825942842\n",
      "R2: 0.20687281584873918\n",
      "R2: 0.2205169646627031\n",
      "R2: 0.17534893851394828\n",
      "R2: 0.2205169646627031\n",
      "R2: -0.04213755715199241\n",
      "R2: -0.04525592066995521\n",
      "R2: -0.04287181303842558\n",
      "R2: -0.036652425306695546\n",
      "R2: -0.03182132350926348\n",
      "R2: -0.030490376642568817\n",
      "R2: -0.029902622065773876\n",
      "R2: -0.025831924477918156\n",
      "R2: -0.01349815567243473\n",
      "R2: 0.00830717989244667\n",
      "R2: 0.03386891441563167\n",
      "R2: 0.05465493170902991\n",
      "R2: 0.062275227497087804\n",
      "R2: 0.0550416688127322\n",
      "R2: 0.044261623637794845\n",
      "R2: 0.04920597297117002\n",
      "R2: 0.07889516133828633\n",
      "R2: 0.1258892976338173\n",
      "R2: 0.17170999903754947\n",
      "R2: 0.19523845807142515\n",
      "R2: 0.18767373209236626\n",
      "R2: 0.15760579514718154\n",
      "R2: 0.12318305409892505\n",
      "R2: 0.09565585881108352\n",
      "R2: 0.07457872965768175\n",
      "R2: 0.06000912010503845\n",
      "R2: 0.05338627996274381\n",
      "R2: 0.051616319118945486\n",
      "R2: 0.04216667285831177\n",
      "R2: 0.02130126714663494\n",
      "R2: 0.19523845807142515\n"
     ]
    }
   ],
   "source": [
    "pred_range = (0, 120)\n",
    "label = '_early_'\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "\n",
    "curr_r2_array = nans([len(lag_axis)])\n",
    "curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "    curr_r2_array[i] = r2\n",
    "    curr_coef_array[i,:,:] = coef\n",
    "\n",
    "idx_max = np.argmax(curr_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "_, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(lag_axis, curr_r2_array)\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.title('R2 score predicting hand velocity [0,120]')\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "weights = curr_coef_array[idx_max,:,:]\n",
    "for iter in range(0,3):  \n",
    "    #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "    sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "    sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "        sub_r2_array[i] = r2\n",
    "        sub_coef_array[i,:,:] = coef\n",
    "\n",
    "    plt.plot(lag_axis,sub_r2_array)\n",
    "    plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "    idx_max = np.argmax(sub_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('x-vel')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    #stack the decoding dimensions to be projected out\n",
    "    weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3648371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.3743074247389314\n",
      "R2: 0.39065077153077876\n",
      "R2: 0.3992724695041473\n",
      "R2: 0.40527641212731536\n",
      "R2: 0.4142007914070239\n",
      "R2: 0.4276085669299772\n",
      "R2: 0.4465612145654553\n",
      "R2: 0.47120323608011194\n",
      "R2: 0.4978381976733761\n",
      "R2: 0.5253977099700073\n",
      "R2: 0.5536517488075579\n",
      "R2: 0.5781165878512429\n",
      "R2: 0.5974002308627047\n",
      "R2: 0.6154846163322143\n",
      "R2: 0.626778504844836\n",
      "R2: 0.6318249520376016\n",
      "R2: 0.631156063276104\n",
      "R2: 0.6249032537917194\n",
      "R2: 0.6136048286660658\n",
      "R2: 0.5984721127934545\n",
      "R2: 0.5811012203835997\n",
      "R2: 0.5620762535726369\n",
      "R2: 0.5416276788702836\n",
      "R2: 0.5200697547950628\n",
      "R2: 0.4969627895163815\n",
      "R2: 0.4711089257679689\n",
      "R2: 0.44373629521704705\n",
      "R2: 0.4185226956308735\n",
      "R2: 0.3967669806480605\n",
      "R2: 0.3788567863931591\n",
      "R2: 0.6318249520376016\n",
      "R2: 0.34029470616957436\n",
      "R2: 0.33601491493336033\n",
      "R2: 0.3192483785990856\n",
      "R2: 0.2938375922375239\n",
      "R2: 0.26926391540053796\n",
      "R2: 0.2541986515122463\n",
      "R2: 0.24447383581949722\n",
      "R2: 0.2414792440639365\n",
      "R2: 0.2379746128359772\n",
      "R2: 0.19229314200650383\n",
      "R2: 0.09864975222452144\n",
      "R2: 0.026835442846740776\n",
      "R2: 0.03932197171463947\n",
      "R2: 0.12374588223598237\n",
      "R2: 0.22725469959523725\n",
      "R2: 0.2674845409459784\n",
      "R2: 0.2620380271438779\n",
      "R2: 0.2618198455716585\n",
      "R2: 0.2655503862470662\n",
      "R2: 0.2656398011382458\n",
      "R2: 0.260496129234853\n",
      "R2: 0.2511929485077401\n",
      "R2: 0.24137674457946146\n",
      "R2: 0.2347007251709845\n",
      "R2: 0.23154965526158\n",
      "R2: 0.22927693860580656\n",
      "R2: 0.22459144874798953\n",
      "R2: 0.2169499573815682\n",
      "R2: 0.2091326134116258\n",
      "R2: 0.20355779780289285\n",
      "R2: 0.34029470616957436\n",
      "R2: 0.11460456020250509\n",
      "R2: 0.09837262178997064\n",
      "R2: 0.09711612438093087\n",
      "R2: 0.10887066125163125\n",
      "R2: 0.12742881158204233\n",
      "R2: 0.14758361199042203\n",
      "R2: 0.16502967947664327\n",
      "R2: 0.18309906570455814\n",
      "R2: 0.20060534238063044\n",
      "R2: 0.20711763965172247\n",
      "R2: 0.20644666728235594\n",
      "R2: 0.21027599598994284\n",
      "R2: 0.2209664160982414\n",
      "R2: 0.23648953220186697\n",
      "R2: 0.25471831048807403\n",
      "R2: 0.26131101369420406\n",
      "R2: 0.2567586789369949\n",
      "R2: 0.25513034526481393\n",
      "R2: 0.25553506427586703\n",
      "R2: 0.25419411288136196\n",
      "R2: 0.249836269994533\n",
      "R2: 0.24277071320484178\n",
      "R2: 0.2352841718677855\n",
      "R2: 0.22986782453350552\n",
      "R2: 0.22694712406746753\n",
      "R2: 0.22474666277103772\n",
      "R2: 0.22095768891801382\n",
      "R2: 0.21443278271733168\n",
      "R2: 0.2066438043231964\n",
      "R2: 0.20003837514991707\n",
      "R2: 0.26131101369420406\n",
      "R2: 0.12752803409381142\n",
      "R2: 0.12064351703164466\n",
      "R2: 0.11769776007449295\n",
      "R2: 0.11828979871291279\n",
      "R2: 0.12271133397768386\n",
      "R2: 0.1293751069879442\n",
      "R2: 0.13563750650881323\n",
      "R2: 0.14043440908116656\n",
      "R2: 0.1426171719546243\n",
      "R2: 0.13990429219670386\n",
      "R2: 0.1317480404213891\n",
      "R2: 0.11906130831166173\n",
      "R2: 0.1013233472182613\n",
      "R2: 0.08008968733145427\n",
      "R2: 0.06307091275328425\n",
      "R2: 0.05688581287474481\n",
      "R2: 0.0595167225241412\n",
      "R2: 0.06607198003685666\n",
      "R2: 0.07510059016667281\n",
      "R2: 0.08604639611359888\n",
      "R2: 0.09772079640124465\n",
      "R2: 0.11007279009701454\n",
      "R2: 0.12374807628376161\n",
      "R2: 0.13823246284222224\n",
      "R2: 0.1512118993463033\n",
      "R2: 0.15929486477064836\n",
      "R2: 0.16029442147063155\n",
      "R2: 0.1549595712827947\n",
      "R2: 0.1457080423682715\n",
      "R2: 0.13537796798846513\n",
      "R2: 0.16029442147063155\n"
     ]
    }
   ],
   "source": [
    "pred_range = (380, 500)\n",
    "label = '_late_'\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "\n",
    "curr_r2_array = nans([len(lag_axis)])\n",
    "curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "    curr_r2_array[i] = r2\n",
    "    curr_coef_array[i,:,:] = coef\n",
    "\n",
    "idx_max = np.argmax(curr_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "_, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(lag_axis, curr_r2_array)\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.title('R2 score predicting hand velocity [380,500]')\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "weights = curr_coef_array[idx_max,:,:]\n",
    "for iter in range(0,3):  \n",
    "    #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "    sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "    sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "        sub_r2_array[i] = r2\n",
    "        sub_coef_array[i,:,:] = coef\n",
    "\n",
    "    plt.plot(lag_axis,sub_r2_array)\n",
    "    plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "    idx_max = np.argmax(sub_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('x-vel')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "    \n",
    "    #stack the decoding dimensions to be projected out\n",
    "    weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c89f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9046b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df8d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa52a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80e66b89",
   "metadata": {},
   "source": [
    "# Multi Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8649848a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "dataset_50ms = NWBDataset(filename, split_heldout=False)\n",
    "dataset_50ms.resample(50)\n",
    "print(dataset_50ms.bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fda3bfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371 trials\n",
      "87 neurons\n",
      "(53899, 87)\n",
      "(53899, 87)\n",
      "(53899, 20)\n",
      "PCA total var explained: 0.432188868413881\n"
     ]
    }
   ],
   "source": [
    "n_dims = 20 # for PCA\n",
    "\n",
    "active_mask = (~dataset_50ms.trial_info.ctr_hold_bump) & (dataset_50ms.trial_info.split != 'none')\n",
    "passive_mask = (dataset_50ms.trial_info.ctr_hold_bump) & (dataset_50ms.trial_info.split != 'none')\n",
    "\n",
    "\n",
    "trial_mask = active_mask\n",
    "n_trials = dataset_50ms.trial_info.loc[trial_mask].shape[0]\n",
    "print(n_trials,'trials')\n",
    "n_neurons = dataset_50ms.data.spikes.shape[1]\n",
    "print(n_neurons,'neurons')\n",
    "\n",
    "all_data = np.array(dataset_50ms.data.spikes)\n",
    "print(all_data.shape)\n",
    "data_for_pca = all_data[~np.isnan(all_data).any(axis=1)]\n",
    "print(data_for_pca.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data_for_pca)\n",
    "pca = PCA(n_components=n_dims)\n",
    "X = pca.fit(X)\n",
    "\n",
    "PCA_data = nans([all_data.shape[0],n_dims])\n",
    "idx = 0\n",
    "for dp in all_data:\n",
    "    dp = dp.reshape((1, -1))\n",
    "    if np.isnan(dp).any():\n",
    "        dp_pca = nans([1,n_dims])\n",
    "    else:\n",
    "        dp_pca = pca.transform(scaler.transform(dp))\n",
    "    PCA_data[idx,:] = dp_pca\n",
    "    idx+=1\n",
    "print(PCA_data.shape)\n",
    "dataset_50ms.add_continuous_data(PCA_data,'PCA')\n",
    "print('PCA total var explained:',sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a348315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 time bins\n",
      "(371, 20, 87)\n",
      "(371, 20, 2)\n",
      "(371, 20, 20)\n",
      "[0. 6. 6. 4. 6. 2. 0. 4. 6. 4. 6. 0. 4. 4. 4. 4. 4. 6. 4. 0. 6. 6. 0. 6.\n",
      " 6. 2. 4. 6. 0. 2. 6. 4. 4. 0. 6. 6. 6. 0. 0. 2. 2. 6. 4. 4. 0. 6. 6. 6.\n",
      " 6. 6. 2. 6. 6. 0. 2. 2. 2. 4. 6. 0. 2. 0. 0. 2. 0. 6. 2. 0. 0. 4. 6. 2.\n",
      " 6. 6. 2. 0. 0. 6. 0. 6. 0. 4. 0. 4. 0. 4. 6. 6. 6. 0. 0. 6. 2. 0. 4. 0.\n",
      " 4. 0. 2. 2. 2. 2. 4. 2. 0. 0. 0. 0. 6. 6. 0. 0. 4. 2. 6. 4. 0. 6. 2. 6.\n",
      " 4. 0. 2. 4. 4. 4. 6. 4. 4. 0. 2. 4. 2. 2. 0. 0. 2. 4. 2. 2. 4. 0. 6. 2.\n",
      " 4. 6. 6. 6. 4. 4. 6. 2. 6. 4. 6. 2. 4. 6. 2. 4. 6. 2. 0. 2. 6. 6. 2. 4.\n",
      " 6. 6. 2. 6. 4. 6. 4. 2. 6. 0. 0. 0. 2. 0. 4. 0. 4. 0. 2. 4. 4. 2. 4. 2.\n",
      " 4. 4. 6. 6. 4. 0. 4. 4. 4. 0. 0. 4. 0. 6. 4. 0. 2. 0. 0. 2. 0. 4. 0. 4.\n",
      " 2. 2. 2. 2. 4. 0. 4. 4. 6. 4. 0. 4. 4. 0. 0. 6. 4. 2. 0. 4. 6. 6. 4. 0.\n",
      " 6. 4. 4. 6. 2. 0. 2. 0. 2. 6. 2. 6. 2. 2. 0. 0. 4. 2. 4. 2. 2. 6. 0. 0.\n",
      " 6. 6. 0. 0. 0. 0. 2. 2. 0. 0. 6. 0. 6. 4. 6. 6. 0. 6. 4. 2. 4. 2. 6. 2.\n",
      " 6. 6. 0. 4. 6. 0. 0. 2. 0. 0. 4. 0. 4. 6. 4. 6. 2. 4. 6. 6. 6. 2. 6. 2.\n",
      " 0. 4. 0. 2. 2. 2. 2. 4. 6. 6. 4. 4. 2. 2. 2. 0. 0. 0. 2. 2. 2. 0. 6. 4.\n",
      " 2. 2. 2. 2. 6. 6. 6. 0. 4. 4. 6. 2. 4. 6. 6. 2. 6. 0. 2. 4. 0. 4. 6. 6.\n",
      " 4. 0. 6. 0. 6. 0. 0. 6. 2. 4. 0.]\n"
     ]
    }
   ],
   "source": [
    "active_data = dataset_50ms.make_trial_data(align_field='move_onset_time', align_range=(-300, 700), ignored_trials=~trial_mask)\n",
    "for idx, trial in active_data.groupby('trial_id'):\n",
    "    n_timepoints = trial.shape[0]\n",
    "    break\n",
    "print(n_timepoints,'time bins')\n",
    "\n",
    "active_trials_neuron = nans([n_trials,n_timepoints,n_neurons])\n",
    "active_trials_vel = nans([n_trials,n_timepoints,2])\n",
    "active_trials_pca = nans([n_trials,n_timepoints,n_dims])\n",
    "i = 0\n",
    "for idx, trial in active_data.groupby('trial_id'):\n",
    "    active_trials_neuron[i,:,:]=trial.spikes.to_numpy()\n",
    "    active_trials_vel[i,:,:]=trial.hand_vel.to_numpy()\n",
    "    active_trials_pca[i,:,:]=trial.PCA.to_numpy()\n",
    "    i+=1\n",
    "print(active_trials_neuron.shape)\n",
    "print(active_trials_vel.shape)\n",
    "print(active_trials_pca.shape)\n",
    "\n",
    "#make dictionary for trial condition (reaching directions) for Stratified CV\n",
    "active_trials_idx = np.array(dataset_50ms.trial_info.loc[trial_mask]['trial_id'])\n",
    "cond_dir_idx = []\n",
    "cond_dict = nans([n_trials])\n",
    "for direction in [0,45,90,135,180,225,270,315]:\n",
    "    cond_dir_idx.append(np.where((dataset_50ms.trial_info['cond_dir'] == direction) & (dataset_50ms.trial_info['ctr_hold_bump'] == False) & \\\n",
    "           (dataset_50ms.trial_info['split'] != 'none'))[0])\n",
    "i = 0\n",
    "for idx in active_trials_idx:\n",
    "    for cond in range(0,len(cond_dir_idx)):\n",
    "        if idx in cond_dir_idx[cond]:\n",
    "            cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(cond_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988e86c8",
   "metadata": {},
   "source": [
    "## Early"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a441427b",
   "metadata": {},
   "source": [
    "### with Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73bd712d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with 0 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.41422941008821457\n",
      "Predicting with 0 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.5128502743183188\n",
      "Predicting with 0 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.5706362975605955\n",
      "Predicting with 0 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.6112927846557585\n",
      "Predicting with 0 to 200 ms neural data\n",
      "100.0\n",
      "R2: 0.6351267659050517\n",
      "Predicting with 0 to 250 ms neural data\n",
      "100.0\n",
      "R2: 0.6508872052660535\n",
      "Predicting with 0 to 300 ms neural data\n",
      "100.0\n",
      "R2: 0.6582177965889632\n",
      "Predicting with 0 to 350 ms neural data\n",
      "100.0\n",
      "R2: 0.6674650542753541\n",
      "Predicting with 0 to 400 ms neural data\n",
      "100.0\n",
      "R2: 0.6768030001971175\n",
      "Predicting with 0 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.6761994776019549\n",
      "Predicting with 0 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.6777298786119517\n",
      "Predicting with -50 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.5152347979845865\n",
      "Predicting with -50 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.5926599942735644\n",
      "Predicting with -50 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.6380333158311494\n",
      "Predicting with -50 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.6695649849446681\n",
      "Predicting with -50 to 200 ms neural data\n",
      "100.0\n",
      "R2: 0.6858017139873132\n",
      "Predicting with -50 to 250 ms neural data\n",
      "100.0\n",
      "R2: 0.6963056936261713\n",
      "Predicting with -50 to 300 ms neural data\n",
      "100.0\n",
      "R2: 0.7020915307002196\n",
      "Predicting with -50 to 350 ms neural data\n",
      "100.0\n",
      "R2: 0.7111089813075606\n",
      "Predicting with -50 to 400 ms neural data\n",
      "100.0\n",
      "R2: 0.7189449955186795\n",
      "Predicting with -50 to 450 ms neural data\n",
      "100.0\n",
      "R2: 0.7184108210437494\n",
      "Predicting with -50 to 500 ms neural data\n",
      "100.0\n",
      "R2: 0.7191559100660609\n",
      "Predicting with -100 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.5571546275232554\n",
      "Predicting with -100 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.6222529729501676\n",
      "Predicting with -100 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.6611823458348672\n",
      "Predicting with -100 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.6882281274911833\n",
      "Predicting with -100 to 200 ms neural data\n",
      "100.0\n",
      "R2: 0.7030500946963893\n",
      "Predicting with -100 to 250 ms neural data\n",
      "100.0\n",
      "R2: 0.7130316718433829\n",
      "Predicting with -100 to 300 ms neural data\n",
      "100.0\n",
      "R2: 0.7184880346912556\n",
      "Predicting with -100 to 350 ms neural data\n",
      "100.0\n",
      "R2: 0.7268138494198455\n",
      "Predicting with -100 to 400 ms neural data\n",
      "100.0\n",
      "R2: 0.7337080700182333\n",
      "Predicting with -100 to 450 ms neural data\n",
      "100.0\n",
      "R2: 0.7333762472300693\n",
      "Predicting with -100 to 500 ms neural data\n",
      "100.0\n",
      "R2: 0.7326684757860397\n",
      "Predicting with -150 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.5517881996511982\n",
      "Predicting with -150 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.6157531402668831\n",
      "Predicting with -150 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.6573722937006187\n",
      "Predicting with -150 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.6839844414647407\n",
      "Predicting with -150 to 200 ms neural data\n",
      "100.0\n",
      "R2: 0.7005362486579756\n",
      "Predicting with -150 to 250 ms neural data\n",
      "100.0\n",
      "R2: 0.7109846422636162\n",
      "Predicting with -150 to 300 ms neural data\n",
      "100.0\n",
      "R2: 0.7175742531486268\n",
      "Predicting with -150 to 350 ms neural data\n",
      "100.0\n",
      "R2: 0.7254378201802565\n",
      "Predicting with -150 to 400 ms neural data\n",
      "100.0\n",
      "R2: 0.732541604365754\n",
      "Predicting with -150 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.731923354726485\n",
      "Predicting with -150 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.731066449393713\n",
      "Predicting with -200 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.5449061119486629\n",
      "Predicting with -200 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.61186839912365\n",
      "Predicting with -200 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.6525195410772712\n",
      "Predicting with -200 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.6806627127269864\n",
      "Predicting with -200 to 200 ms neural data\n",
      "100.0\n",
      "R2: 0.6981545816683876\n",
      "Predicting with -200 to 250 ms neural data\n",
      "100.0\n",
      "R2: 0.7075919623848183\n",
      "Predicting with -200 to 300 ms neural data\n",
      "100.0\n",
      "R2: 0.7139558518834443\n",
      "Predicting with -200 to 350 ms neural data\n",
      "100.0\n",
      "R2: 0.7210270513758783\n",
      "Predicting with -200 to 400 ms neural data\n",
      "100.0\n",
      "R2: 0.7291314453760114\n",
      "Predicting with -200 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.729017151319255\n",
      "Predicting with -200 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.7285373578931225\n",
      "Predicting with -250 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.542858168704849\n",
      "Predicting with -250 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.6087197293580785\n",
      "Predicting with -250 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.649870556027982\n",
      "Predicting with -250 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.6780775271490733\n",
      "Predicting with -250 to 200 ms neural data\n",
      "100.0\n",
      "R2: 0.6940395023788021\n",
      "Predicting with -250 to 250 ms neural data\n",
      "100.0\n",
      "R2: 0.7043636908926687\n",
      "Predicting with -250 to 300 ms neural data\n",
      "100.0\n",
      "R2: 0.711407496415909\n",
      "Predicting with -250 to 350 ms neural data\n",
      "100.0\n",
      "R2: 0.718833158815342\n",
      "Predicting with -250 to 400 ms neural data\n",
      "100.0\n",
      "R2: 0.7279966965495459\n",
      "Predicting with -250 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.7277979429940657\n",
      "Predicting with -250 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.7277070383864442\n",
      "Predicting with -300 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.5403568466182258\n",
      "Predicting with -300 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.6055637725928639\n",
      "Predicting with -300 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.6493260410475116\n",
      "Predicting with -300 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.6783110209016535\n",
      "Predicting with -300 to 200 ms neural data\n",
      "100.0\n",
      "R2: 0.6941214635162402\n",
      "Predicting with -300 to 250 ms neural data\n",
      "100.0\n",
      "R2: 0.7041297292612843\n",
      "Predicting with -300 to 300 ms neural data\n",
      "100.0\n",
      "R2: 0.7102838838169501\n",
      "Predicting with -300 to 350 ms neural data\n",
      "100.0\n",
      "R2: 0.7175256225212927\n",
      "Predicting with -300 to 400 ms neural data\n",
      "100.0\n",
      "R2: 0.7251831327455145\n",
      "Predicting with -300 to 450 ms neural data\n",
      "100.0\n",
      "R2: 0.7248774720199653\n",
      "Predicting with -300 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.7263706981992502\n"
     ]
    }
   ],
   "source": [
    "data_range = [-300,700]\n",
    "pred_start = 0\n",
    "pred_end = 120\n",
    "\n",
    "idx1 = int((pred_start - data_range[0])/dataset_50ms.bin_width)\n",
    "idx2 = int(n_timepoints - (data_range[1]-pred_end)/dataset_50ms.bin_width)\n",
    "\n",
    "t_before_range = range(0,301,50);\n",
    "t_after_range = range(0,501,50);\n",
    "\n",
    "early_multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "early_multi_coefs = []\n",
    "j,k=0,0\n",
    "for time_before in t_before_range:\n",
    "    coef_arr = []\n",
    "    for time_after in t_after_range:\n",
    "        print('Predicting with',-time_before, 'to', time_after,'ms neural data')\n",
    "        \n",
    "        bins_before= int(time_before/dataset_50ms.bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "        bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "        bins_after= int(time_after/dataset_50ms.bin_width) #How many bins of neural data after the output are used for decoding\n",
    "\n",
    "        n_total_bins = bins_before + bins_current + bins_after\n",
    "\n",
    "        X =  nans([n_trials,idx2-idx1,n_total_bins*n_neurons])\n",
    "        i = 0\n",
    "        for trial_data in active_trials_neuron:\n",
    "            trial_hist=get_spikes_with_history(trial_data,bins_before,bins_after,bins_current)\n",
    "            trial_hist = trial_hist[idx1:idx2,:,:]\n",
    "            trial_hist_flat=trial_hist.reshape(trial_hist.shape[0],(trial_hist.shape[1]*trial_hist.shape[2]))\n",
    "            X[i,:,:] = trial_hist_flat\n",
    "            i+=1\n",
    "        \n",
    "        y = active_trials_vel[:,idx1:idx2,:]\n",
    "    \n",
    "        lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)})\n",
    "        X_reshaped = X.reshape((X.shape[0]*X.shape[1]),X.shape[2])\n",
    "        y_reshaped = y.reshape((y.shape[0]*y.shape[1]),y.shape[2])\n",
    "        lr_all.fit(X_reshaped, y_reshaped)\n",
    "        print(lr_all.best_params_['alpha'])\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "        true_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "        pred_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "        trial_save_idx = 0\n",
    "        for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "            #split training and testing by trials\n",
    "            X_train, X_test, y_train, y_test = process_train_test(X,y,training_set,test_set)\n",
    "            lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)}) \n",
    "            lr.fit(X_train, y_train)\n",
    "            y_test_predicted = lr.predict(X_test)\n",
    "            n = y_test_predicted.shape[0]\n",
    "            true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "            pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "            trial_save_idx += n\n",
    "\n",
    "        sses =get_sses_pred(true_concat,pred_concat)\n",
    "        sses_mean=get_sses_mean(true_concat)\n",
    "        early_multi_R2s[j,k] =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "        print('R2:',early_multi_R2s[j,k])\n",
    "        coef_arr.append(lr_all.best_estimator_.coef_)\n",
    "        k += 1\n",
    "    j += 1\n",
    "    k = 0\n",
    "    early_multi_coefs.append(coef_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce60a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(early_multi_R2s)\n",
    "ax.set_xlabel('Length of lagging info')\n",
    "ax.set_ylabel('Length of leading info')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_after_range)))\n",
    "ax.set_yticks(np.arange(len(t_before_range)))\n",
    "ax.set_xticklabels(labels=t_after_range)\n",
    "ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "ax.set_title(\"R2 predicting [0, 120] velocity \\nwith different lagging/leading info\")\n",
    "fig.tight_layout()\n",
    " \n",
    "for i in range(len(t_before_range)):\n",
    "    for j in range(len(t_after_range)):\n",
    "        text = ax.text(j, i, str(int(early_multi_R2s[i, j]*1000)/1000),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "plt.tight_layout()\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/neurons/act/\"\n",
    "plt.savefig(figDir + monkey + '_multi_early.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e187da",
   "metadata": {},
   "source": [
    "### with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcff8207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with 0 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.33376730533028376\n",
      "Predicting with 0 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.43247328959568654\n",
      "Predicting with 0 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.48750461231304376\n",
      "Predicting with 0 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.5316391028617087\n",
      "Predicting with 0 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.5549895374519626\n",
      "Predicting with 0 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.5813314340720162\n",
      "Predicting with 0 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.598130245356703\n",
      "Predicting with 0 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.6191225301639743\n",
      "Predicting with 0 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.6276581509045009\n",
      "Predicting with 0 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.6342110488611694\n",
      "Predicting with 0 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.6368165492745863\n",
      "Predicting with -50 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.4617229349565739\n",
      "Predicting with -50 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.5172985341628616\n",
      "Predicting with -50 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.5556314694904743\n",
      "Predicting with -50 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.5911030621987567\n",
      "Predicting with -50 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.6074851179467444\n",
      "Predicting with -50 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.6264941418578804\n",
      "Predicting with -50 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.6415004107204293\n",
      "Predicting with -50 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.6494402342372978\n",
      "Predicting with -50 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.65817836461566\n",
      "Predicting with -50 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.6680926506096945\n",
      "Predicting with -50 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.670386611249876\n",
      "Predicting with -100 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.49282145671943944\n",
      "Predicting with -100 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.5417281987500964\n",
      "Predicting with -100 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.5748527522594138\n",
      "Predicting with -100 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.6082375153977377\n",
      "Predicting with -100 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.6245410159227389\n",
      "Predicting with -100 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.644769474258696\n",
      "Predicting with -100 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.6567004126287915\n",
      "Predicting with -100 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.6616800775215823\n",
      "Predicting with -100 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.6760222419743327\n",
      "Predicting with -100 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.6822523563205176\n",
      "Predicting with -100 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.6844472403293058\n",
      "Predicting with -150 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.48525591098878584\n",
      "Predicting with -150 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.5284964226686181\n",
      "Predicting with -150 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.5688645613050177\n",
      "Predicting with -150 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.6030936035964568\n",
      "Predicting with -150 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.6212604479886583\n",
      "Predicting with -150 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.640584137442852\n",
      "Predicting with -150 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.6512522478883238\n",
      "Predicting with -150 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.6612931952139833\n",
      "Predicting with -150 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.6772967082410853\n",
      "Predicting with -150 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.68293047236783\n",
      "Predicting with -150 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.6847175579681106\n",
      "Predicting with -200 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.4816571580894997\n",
      "Predicting with -200 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.5213665181992058\n",
      "Predicting with -200 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.5632767818233073\n",
      "Predicting with -200 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.6011148587188364\n",
      "Predicting with -200 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.6169856022278374\n",
      "Predicting with -200 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.6351370582814317\n",
      "Predicting with -200 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.6421501165734484\n",
      "Predicting with -200 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.657494374566769\n",
      "Predicting with -200 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.6770730604997279\n",
      "Predicting with -200 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.6831894054939205\n",
      "Predicting with -200 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.6851296684804697\n",
      "Predicting with -250 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.4734071746114894\n",
      "Predicting with -250 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.5136906455180228\n",
      "Predicting with -250 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.559245258979003\n",
      "Predicting with -250 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.5948883307509056\n",
      "Predicting with -250 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.6089150637234649\n",
      "Predicting with -250 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.621122769226099\n",
      "Predicting with -250 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.635361573066956\n",
      "Predicting with -250 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.6647834053926811\n",
      "Predicting with -250 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.6757154238958005\n",
      "Predicting with -250 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.6823889335039008\n",
      "Predicting with -250 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.6843751485841917\n",
      "Predicting with -300 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.4702358684466198\n",
      "Predicting with -300 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.5123765963037212\n",
      "Predicting with -300 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.5542682093828786\n",
      "Predicting with -300 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.584864366758528\n",
      "Predicting with -300 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.606197284160152\n",
      "Predicting with -300 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.6262397602593655\n",
      "Predicting with -300 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.6470639480828225\n",
      "Predicting with -300 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.6654716801699325\n",
      "Predicting with -300 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.6763086748747449\n",
      "Predicting with -300 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.6830390365134499\n",
      "Predicting with -300 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.6853523144009102\n"
     ]
    }
   ],
   "source": [
    "PCA_early_multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "PCA_early_multi_coefs = []\n",
    "j,k=0,0\n",
    "for time_before in t_before_range:\n",
    "    coef_arr = []\n",
    "    for time_after in t_after_range:\n",
    "        print('Predicting with',-time_before, 'to', time_after,'ms neural data')\n",
    "        \n",
    "        bins_before= int(time_before/dataset_50ms.bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "        bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "        bins_after= int(time_after/dataset_50ms.bin_width) #How many bins of neural data after the output are used for decoding\n",
    "\n",
    "        n_total_bins = bins_before + bins_current + bins_after\n",
    "\n",
    "        X =  nans([n_trials,idx2-idx1,n_total_bins*n_dims])\n",
    "        i = 0\n",
    "        for trial_data in active_trials_pca:\n",
    "            trial_hist=get_spikes_with_history(trial_data,bins_before,bins_after,bins_current)\n",
    "            trial_hist = trial_hist[idx1:idx2,:,:]\n",
    "            trial_hist_flat=trial_hist.reshape(trial_hist.shape[0],(trial_hist.shape[1]*trial_hist.shape[2]))\n",
    "            X[i,:,:] = trial_hist_flat\n",
    "            i+=1\n",
    "        \n",
    "        y = active_trials_vel[:,idx1:idx2,:]\n",
    "    \n",
    "        lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)})\n",
    "        X_reshaped = X.reshape((X.shape[0]*X.shape[1]),X.shape[2])\n",
    "        y_reshaped = y.reshape((y.shape[0]*y.shape[1]),y.shape[2])\n",
    "        lr_all.fit(X_reshaped, y_reshaped)\n",
    "        print(lr_all.best_params_['alpha'])\n",
    "        \n",
    "        skf =StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "        true_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "        pred_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "        trial_save_idx = 0\n",
    "        for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "            #split training and testing by trials\n",
    "            X_train, X_test, y_train, y_test = process_train_test(X,y,training_set,test_set)\n",
    "            lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)}) \n",
    "            lr.fit(X_train, y_train)\n",
    "            y_test_predicted = lr.predict(X_test)\n",
    "            n = y_test_predicted.shape[0]\n",
    "            true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "            pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "            trial_save_idx += n\n",
    "\n",
    "        sses =get_sses_pred(true_concat,pred_concat)\n",
    "        sses_mean=get_sses_mean(true_concat)\n",
    "        PCA_early_multi_R2s[j,k] =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "        print('R2:',PCA_early_multi_R2s[j,k])\n",
    "        coef_arr.append(lr_all.best_estimator_.coef_)\n",
    "        k += 1\n",
    "    j += 1\n",
    "    k = 0\n",
    "    PCA_early_multi_coefs.append(coef_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c9a8339",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(PCA_early_multi_R2s)\n",
    "ax.set_xlabel('Length of lagging info')\n",
    "ax.set_ylabel('Length of leading info')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_after_range)))\n",
    "ax.set_yticks(np.arange(len(t_before_range)))\n",
    "ax.set_xticklabels(labels=t_after_range)\n",
    "ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "ax.set_title(\"R2 predicting [0, 120] velocity \\nwith different lagging/leading info\")\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(t_before_range)):\n",
    "    for j in range(len(t_after_range)):\n",
    "        text = ax.text(j, i, str(int(PCA_early_multi_R2s[i, j]*1000)/1000),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.tight_layout()\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/PCA/act/\"\n",
    "plt.savefig(figDir + monkey + '_multi_early.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa49221",
   "metadata": {},
   "source": [
    "## Whole"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef332cd6",
   "metadata": {},
   "source": [
    "### with Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c8378b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with 0 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.467736481437361\n",
      "Predicting with 0 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.5712959296734621\n",
      "Predicting with 0 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.6161304320153006\n",
      "Predicting with 0 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.6417303565394066\n",
      "Predicting with 0 to 200 ms neural data\n",
      "100.0\n",
      "R2: 0.6604685426737124\n",
      "Predicting with -50 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.5731280728733198\n",
      "Predicting with -50 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.6356185299974026\n",
      "Predicting with -50 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.6652718454871442\n",
      "Predicting with -50 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.6838607919797849\n",
      "Predicting with -50 to 200 ms neural data\n",
      "100.0\n",
      "R2: 0.6981663725911744\n",
      "Predicting with -100 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.6197193518684381\n",
      "Predicting with -100 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.6684559340938048\n",
      "Predicting with -100 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.6927987876851771\n",
      "Predicting with -100 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.7083032612049315\n",
      "Predicting with -100 to 200 ms neural data\n",
      "100.0\n",
      "R2: 0.7191020351156643\n",
      "Predicting with -150 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.6397051838763581\n",
      "Predicting with -150 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.6841627325676665\n",
      "Predicting with -150 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.7063684294184414\n",
      "Predicting with -150 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.7205599186224347\n",
      "Predicting with -150 to 200 ms neural data\n",
      "100.0\n",
      "R2: 0.7298126369185409\n",
      "Predicting with -200 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.647929231379549\n",
      "Predicting with -200 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.6912441684086114\n",
      "Predicting with -200 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.7130582649211654\n",
      "Predicting with -200 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.7264881385632993\n",
      "Predicting with -200 to 200 ms neural data\n",
      "100.0\n",
      "R2: 0.7356670813812227\n"
     ]
    }
   ],
   "source": [
    "data_range = [-300,700]\n",
    "pred_start = -100\n",
    "pred_end = 500\n",
    "\n",
    "idx1 = int((pred_start - data_range[0])/dataset_50ms.bin_width)\n",
    "idx2 = int(n_timepoints - (data_range[1]-pred_end)/dataset_50ms.bin_width)\n",
    "\n",
    "t_before_range = range(0,201,50);\n",
    "t_after_range = range(0,201,50);\n",
    "\n",
    "whole_multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "whole_multi_coefs = []\n",
    "j,k=0,0\n",
    "for time_before in t_before_range:\n",
    "    coef_arr = []\n",
    "    for time_after in t_after_range:\n",
    "        print('Predicting with',-time_before, 'to', time_after,'ms neural data')\n",
    "        \n",
    "        bins_before= int(time_before/dataset_50ms.bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "        bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "        bins_after= int(time_after/dataset_50ms.bin_width) #How many bins of neural data after the output are used for decoding\n",
    "\n",
    "        n_total_bins = bins_before + bins_current + bins_after\n",
    "\n",
    "        X =  nans([n_trials,idx2-idx1,n_total_bins*n_neurons])\n",
    "        i = 0\n",
    "        for trial_data in active_trials_neuron:\n",
    "            trial_hist=get_spikes_with_history(trial_data,bins_before,bins_after,bins_current)\n",
    "            trial_hist = trial_hist[idx1:idx2,:,:]\n",
    "            trial_hist_flat=trial_hist.reshape(trial_hist.shape[0],(trial_hist.shape[1]*trial_hist.shape[2]))\n",
    "            X[i,:,:] = trial_hist_flat\n",
    "            i+=1\n",
    "        \n",
    "        y = active_trials_vel[:,idx1:idx2,:]\n",
    "    \n",
    "        lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)})\n",
    "        X_reshaped = X.reshape((X.shape[0]*X.shape[1]),X.shape[2])\n",
    "        y_reshaped = y.reshape((y.shape[0]*y.shape[1]),y.shape[2])\n",
    "        lr_all.fit(X_reshaped, y_reshaped)\n",
    "        print(lr_all.best_params_['alpha'])\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "        true_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "        pred_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "        trial_save_idx = 0\n",
    "        for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "            #split training and testing by trials\n",
    "            X_train, X_test, y_train, y_test = process_train_test(X,y,training_set,test_set)\n",
    "            lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)}) \n",
    "            lr.fit(X_train, y_train)\n",
    "            y_test_predicted = lr.predict(X_test)\n",
    "            n = y_test_predicted.shape[0]\n",
    "            true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "            pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "            trial_save_idx += n\n",
    "\n",
    "        sses =get_sses_pred(true_concat,pred_concat)\n",
    "        sses_mean=get_sses_mean(true_concat)\n",
    "        whole_multi_R2s[j,k] =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "        print('R2:',whole_multi_R2s[j,k])\n",
    "        coef_arr.append(lr_all.best_estimator_.coef_)\n",
    "        k += 1\n",
    "    j += 1\n",
    "    k = 0\n",
    "    whole_multi_coefs.append(coef_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf34e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(whole_multi_R2s)\n",
    "ax.set_xlabel('Length of lagging info')\n",
    "ax.set_ylabel('Length of leading info')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_after_range)))\n",
    "ax.set_yticks(np.arange(len(t_before_range)))\n",
    "ax.set_xticklabels(labels=t_after_range)\n",
    "ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "ax.set_title(\"R2 predicting [-100, 500] velocity \\nwith different lagging/leading info\")\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(t_before_range)):\n",
    "    for j in range(len(t_after_range)):\n",
    "        text = ax.text(j, i, str(int(whole_multi_R2s[i, j]*1000)/1000),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.tight_layout()\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/neurons/act/\"\n",
    "plt.savefig(figDir + monkey + '_multi_whole.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac2cea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_X = whole_multi_coefs[-1][-1][0] #which entry's weights to use\n",
    "\n",
    "t_label = np.arange(-200,201,50)\n",
    "\n",
    "n_weights = len(t_before_range) + len(t_after_range) - 1\n",
    "coef_X_reshaped = coef_X.reshape(n_weights,n_neurons)\n",
    "angDist_array = nans([n_weights,n_weights])\n",
    "for i in range(n_weights):\n",
    "    for j in range(n_weights):\n",
    "        angDist_array[i,j] = math.degrees(angle_between(coef_X_reshaped[i,:],coef_X_reshaped[j,:]))\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "im = ax.imshow(angDist_array)\n",
    "ax.set_xlabel('Bin time (ms)')\n",
    "ax.set_ylabel('Bin time (ms)')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_label)))\n",
    "ax.set_yticks(np.arange(len(t_label)))\n",
    "ax.set_xticklabels(labels=t_label)\n",
    "ax.set_yticklabels(labels=t_label)\n",
    "\n",
    "ax.set_title(\"Angle between weight vectors at time points\")\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(t_label)):\n",
    "    for j in range(len(t_label)):\n",
    "        text = ax.text(j, i, str(int(angDist_array[i, j])),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.tight_layout()\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/neurons/act/\"\n",
    "plt.savefig(figDir + monkey + '_multi_whole_deg.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8958e911",
   "metadata": {},
   "source": [
    "### with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6de7686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with 0 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.3924697900837686\n",
      "Predicting with 0 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.5028486848661706\n",
      "Predicting with 0 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.5566503525764448\n",
      "Predicting with 0 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.5901526791834324\n",
      "Predicting with 0 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.6125905022879805\n",
      "Predicting with -50 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.48620053961584575\n",
      "Predicting with -50 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.557026892683411\n",
      "Predicting with -50 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.59839707680401\n",
      "Predicting with -50 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.6248358338634898\n",
      "Predicting with -50 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.6444327421856828\n",
      "Predicting with -100 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.5222994275344095\n",
      "Predicting with -100 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.581890966992592\n",
      "Predicting with -100 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.6169814699339284\n",
      "Predicting with -100 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.6421739286416924\n",
      "Predicting with -100 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.6594649499713292\n",
      "Predicting with -150 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.5379059113398543\n",
      "Predicting with -150 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.5917408911868922\n",
      "Predicting with -150 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.625443647276991\n",
      "Predicting with -150 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.6497263513597984\n",
      "Predicting with -150 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.6660535864206343\n",
      "Predicting with -200 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.5455528435012471\n",
      "Predicting with -200 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.5978750414821992\n",
      "Predicting with -200 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.6304012257596933\n",
      "Predicting with -200 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.6543707966466463\n",
      "Predicting with -200 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.6704376432008842\n"
     ]
    }
   ],
   "source": [
    "PCA_whole_multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "PCA_whole_multi_coefs = []\n",
    "j,k=0,0\n",
    "for time_before in t_before_range:\n",
    "    coef_arr = []\n",
    "    for time_after in t_after_range:\n",
    "        print('Predicting with',-time_before, 'to', time_after,'ms neural data')\n",
    "        \n",
    "        bins_before= int(time_before/dataset_50ms.bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "        bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "        bins_after= int(time_after/dataset_50ms.bin_width) #How many bins of neural data after the output are used for decoding\n",
    "\n",
    "        n_total_bins = bins_before + bins_current + bins_after\n",
    "\n",
    "        X =  nans([n_trials,idx2-idx1,n_total_bins*n_dims])\n",
    "        i = 0\n",
    "        for trial_data in active_trials_pca:\n",
    "            trial_hist=get_spikes_with_history(trial_data,bins_before,bins_after,bins_current)\n",
    "            trial_hist = trial_hist[idx1:idx2,:,:]\n",
    "            trial_hist_flat=trial_hist.reshape(trial_hist.shape[0],(trial_hist.shape[1]*trial_hist.shape[2]))\n",
    "            X[i,:,:] = trial_hist_flat\n",
    "            i+=1\n",
    "        \n",
    "        y = active_trials_vel[:,idx1:idx2,:]\n",
    "    \n",
    "        lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)})\n",
    "        X_reshaped = X.reshape((X.shape[0]*X.shape[1]),X.shape[2])\n",
    "        y_reshaped = y.reshape((y.shape[0]*y.shape[1]),y.shape[2])\n",
    "        lr_all.fit(X_reshaped, y_reshaped)\n",
    "        print(lr_all.best_params_['alpha'])\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "        true_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "        pred_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "        trial_save_idx = 0\n",
    "        for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "            #split training and testing by trials\n",
    "            X_train, X_test, y_train, y_test = process_train_test(X,y,training_set,test_set)\n",
    "            lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)}) \n",
    "            lr.fit(X_train, y_train)\n",
    "            y_test_predicted = lr.predict(X_test)\n",
    "            n = y_test_predicted.shape[0]\n",
    "            true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "            pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "            trial_save_idx += n\n",
    "\n",
    "        sses =get_sses_pred(true_concat,pred_concat)\n",
    "        sses_mean=get_sses_mean(true_concat)\n",
    "        PCA_whole_multi_R2s[j,k] =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "        print('R2:',PCA_whole_multi_R2s[j,k])\n",
    "        coef_arr.append(lr_all.best_estimator_.coef_)\n",
    "        k += 1\n",
    "    j += 1\n",
    "    k = 0\n",
    "    PCA_whole_multi_coefs.append(coef_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8f8ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(PCA_whole_multi_R2s)\n",
    "ax.set_xlabel('Length of lagging info')\n",
    "ax.set_ylabel('Length of leading info')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_after_range)))\n",
    "ax.set_yticks(np.arange(len(t_before_range)))\n",
    "ax.set_xticklabels(labels=t_after_range)\n",
    "ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "ax.set_title(\"R2 predicting [-100, 500] velocity \\nwith different lagging/leading info\")\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(t_before_range)):\n",
    "    for j in range(len(t_after_range)):\n",
    "        text = ax.text(j, i, str(int(PCA_whole_multi_R2s[i, j]*1000)/1000),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.tight_layout()\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/PCA/act/\"\n",
    "plt.savefig(figDir + monkey + '_multi_whole.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24c2c54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_X = PCA_whole_multi_coefs[-1][-1][0] #which entry's weights to use\n",
    "\n",
    "t_label = np.arange(-200,201,50)\n",
    "\n",
    "n_weights = len(t_before_range) + len(t_after_range) - 1\n",
    "coef_X_reshaped = coef_X.reshape(n_weights,n_dims)\n",
    "angDist_array = nans([n_weights,n_weights])\n",
    "for i in range(n_weights):\n",
    "    for j in range(n_weights):\n",
    "        angDist_array[i,j] = math.degrees(angle_between(coef_X_reshaped[i,:],coef_X_reshaped[j,:]))\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "im = ax.imshow(angDist_array)\n",
    "ax.set_xlabel('Bin time (ms)')\n",
    "ax.set_ylabel('Bin time (ms)')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_label)))\n",
    "ax.set_yticks(np.arange(len(t_label)))\n",
    "ax.set_xticklabels(labels=t_label)\n",
    "ax.set_yticklabels(labels=t_label)\n",
    "\n",
    "ax.set_title(\"Angle between weight vectors at time points\")\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(t_label)):\n",
    "    for j in range(len(t_label)):\n",
    "        text = ax.text(j, i, str(int(angDist_array[i, j])),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.tight_layout()\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/PCA/act/\"\n",
    "plt.savefig(figDir + monkey + '_multi_whole_deg.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f22933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5384f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
