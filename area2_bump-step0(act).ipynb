{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d2edb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n"
     ]
    }
   ],
   "source": [
    "from nlb_tools.nwb_interface import NWBDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "\n",
    "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966 (90 deg)\n",
    "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0 (0 deg)\n",
    "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793 (180 deg)\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "\n",
    "#Import standard packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import io\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "# If you would prefer to load the '.h5' example file rather than the '.pickle' example file. You need the deepdish package\n",
    "# import deepdish as dd \n",
    "\n",
    "#Import function to get the covariate matrix that includes spike history from previous bins\n",
    "from Neural_Decoding.preprocessing_funcs import get_spikes_with_history\n",
    "\n",
    "#Import metrics\n",
    "from Neural_Decoding.metrics import get_R2\n",
    "from Neural_Decoding.metrics import get_rho\n",
    "\n",
    "#Import decoder functions\n",
    "from Neural_Decoding.decoders import WienerCascadeDecoder\n",
    "from Neural_Decoding.decoders import WienerFilterDecoder\n",
    "from Neural_Decoding.decoders import DenseNNDecoder\n",
    "from Neural_Decoding.decoders import SimpleRNNDecoder\n",
    "from Neural_Decoding.decoders import GRUDecoder\n",
    "from Neural_Decoding.decoders import LSTMDecoder\n",
    "from Neural_Decoding.decoders import XGBoostDecoder\n",
    "from Neural_Decoding.decoders import SVRDecoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def get_sses_pred(y_test,y_test_pred):\n",
    "    sse=np.sum((y_test_pred-y_test)**2,axis=0)\n",
    "    return sse\n",
    "\n",
    "def get_sses_mean(y_test):\n",
    "    y_mean=np.mean(y_test,axis=0)\n",
    "    sse_mean=np.sum((y_test-y_mean)**2,axis=0)\n",
    "    return sse_mean\n",
    "\n",
    "def nans(shape, dtype=float):\n",
    "    a = np.empty(shape, dtype)\n",
    "    a.fill(np.nan)\n",
    "    return a\n",
    "\n",
    "def vector_reject(u,v):\n",
    "    #project u on v, subtract u1 from u\n",
    "    P = np.outer(v,(v.T))/(v@(v.T))\n",
    "    u_sub = u - P@u\n",
    "#     another calculation, to double-check\n",
    "#     v_norm = np.sqrt(sum(v**2))    \n",
    "#     proj_u_on_v = (np.dot(u, v)/v_norm**2)*v\n",
    "#     u_sub = u - proj_u_on_v\n",
    "    return u_sub\n",
    "\n",
    "def calc_proj_matrix(A):\n",
    "    return A@np.linalg.inv(A.T@A)@A.T\n",
    "def calc_proj(b, A):\n",
    "    P = calc_proj_matrix(A)\n",
    "    return P@b.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dca024",
   "metadata": {},
   "source": [
    "# Single Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dc8cc31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "foldername = \"~/area2_population_analysis/s1-kinematics/actpas_NWB/\"\n",
    "monkey = \"Han_20171207\"\n",
    "filename = foldername + monkey + \"_COactpas_TD.nwb\"\n",
    "\n",
    "dataset_5ms = NWBDataset(filename, split_heldout=False)\n",
    "\n",
    "speed = np.sqrt(np.sum(dataset_5ms.data['hand_vel'][:].T**2,axis=0)).to_numpy().reshape((-1,1))\n",
    "dataset_5ms.add_continuous_data(speed,'speed')\n",
    "\n",
    "acceleration = np.diff(speed, axis = 0, prepend=[speed[0]])\n",
    "dataset_5ms.add_continuous_data(acceleration,'acceleration')\n",
    "\n",
    "xy_vel = dataset_5ms.data['hand_vel'].to_numpy()\n",
    "xy_acc = np.diff(xy_vel, axis = 0, prepend=[xy_vel[0]])\n",
    "dataset_5ms.add_continuous_data(xy_acc,'hand_acc',chan_names = ['x','y'])\n",
    "\n",
    "dataset_5ms.resample(5)\n",
    "dataset_5ms.smooth_spk(40, name='smth_40')\n",
    "# dataset_5ms.smooth_spk(20, name='smth_20')\n",
    "bin_width = dataset_5ms.bin_width\n",
    "print(bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3421adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_1ms = NWBDataset(filename, split_heldout=False)\n",
    "# speed = np.sqrt(np.sum(dataset_1ms.data['hand_vel'][:].T**2,axis=0)).to_numpy().reshape((-1,1))\n",
    "# dataset_1ms.add_continuous_data(speed,'speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b3102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245 trials\n",
      "153 neurons\n",
      "(558262, 153)\n",
      "(558262, 153)\n",
      "(558262, 20)\n",
      "PCA total var explained: 0.38767002597161215\n",
      "[6. 4. 5. 4. 0. 2. 0. 5. 4. 1. 6. 5. 6. 3. 7. 5. 2. 0. 0. 5. 0. 6. 4. 2.\n",
      " 2. 7. 0. 4. 4. 7. 5. 2. 6. 3. 2. 5. 5. 1. 1. 5. 5. 1. 6. 3. 7. 0. 4. 2.\n",
      " 1. 5. 1. 1. 1. 1. 1. 6. 2. 0. 5. 4. 7. 6. 3. 1. 5. 3. 0. 4. 6. 6. 0. 1.\n",
      " 3. 0. 6. 3. 1. 4. 3. 4. 5. 2. 2. 3. 3. 3. 4. 4. 2. 1. 2. 2. 4. 6. 1. 5.\n",
      " 0. 2. 0. 4. 6. 5. 6. 3. 0. 0. 6. 7. 2. 0. 0. 5. 7. 5. 1. 4. 2. 0. 0. 5.\n",
      " 4. 6. 3. 6. 3. 6. 3. 1. 7. 3. 3. 7. 5. 5. 3. 1. 5. 0. 7. 4. 7. 5. 5. 1.\n",
      " 6. 3. 3. 2. 1. 7. 5. 5. 0. 1. 6. 2. 7. 1. 0. 0. 3. 4. 1. 2. 0. 3. 0. 2.\n",
      " 5. 1. 3. 0. 7. 2. 3. 1. 2. 2. 0. 4. 2. 1. 3. 5. 5. 2. 1. 4. 1. 1. 6. 4.\n",
      " 1. 4. 7. 0. 2. 5. 6. 2. 1. 1. 5. 7. 1. 1. 2. 2. 5. 0. 6. 0. 0. 0. 3. 7.\n",
      " 7. 0. 7. 0. 3. 0. 7. 7. 5. 3. 0. 7. 3. 0. 6. 4. 3. 0. 0. 4. 3. 3. 6. 1.\n",
      " 0. 2. 0. 0. 3.]\n"
     ]
    }
   ],
   "source": [
    "n_dims = 20 # for PCA\n",
    "\n",
    "active_mask = (~dataset_5ms.trial_info.ctr_hold_bump) & (dataset_5ms.trial_info.split != 'none')\n",
    "passive_mask = (dataset_5ms.trial_info.ctr_hold_bump) & (dataset_5ms.trial_info.split != 'none')\n",
    "\n",
    "\n",
    "trial_mask = active_mask\n",
    "n_trials = dataset_5ms.trial_info.loc[trial_mask].shape[0]\n",
    "print(n_trials,'trials')\n",
    "n_neurons = dataset_5ms.data.spikes.shape[1]\n",
    "print(n_neurons,'neurons')\n",
    "\n",
    "all_data = np.array(dataset_5ms.data.spikes_smth_40)\n",
    "print(all_data.shape)\n",
    "data_for_pca = all_data[~np.isnan(all_data).any(axis=1)]\n",
    "print(data_for_pca.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data_for_pca)\n",
    "pca = PCA(n_components=n_dims)\n",
    "X = pca.fit(X)\n",
    "\n",
    "PCA_data = nans([all_data.shape[0],n_dims])\n",
    "idx = 0\n",
    "for dp in all_data:\n",
    "    dp = dp.reshape((1, -1))\n",
    "    if np.isnan(dp).any():\n",
    "        dp_pca = nans([1,n_dims])\n",
    "    else:\n",
    "        dp_pca = pca.transform(scaler.transform(dp))\n",
    "    PCA_data[idx,:] = dp_pca\n",
    "    idx+=1\n",
    "print(PCA_data.shape)\n",
    "dataset_5ms.add_continuous_data(PCA_data,'PCA')\n",
    "print('PCA total var explained:',sum(pca.explained_variance_ratio_))\n",
    "\n",
    "#make dictionary for trial condition (reaching directions) for Stratified CV\n",
    "active_trials_idx = np.array(dataset_5ms.trial_info.loc[trial_mask]['trial_id'])\n",
    "cond_dir_idx = []\n",
    "cond_dict = nans([n_trials])\n",
    "for direction in [0,45,90,135,180,225,270,315]:\n",
    "    cond_dir_idx.append(np.where((dataset_5ms.trial_info['cond_dir'] == direction) & (dataset_5ms.trial_info['ctr_hold_bump'] == False) & \\\n",
    "           (dataset_5ms.trial_info['split'] != 'none'))[0])\n",
    "i = 0\n",
    "for idx in active_trials_idx:\n",
    "    for cond in range(0,len(cond_dir_idx)):\n",
    "        if idx in cond_dir_idx[cond]:\n",
    "            cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(cond_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf18adf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare for PCA plotting\n",
    "\n",
    "# active_data = dataset_5ms.make_trial_data(align_field='move_onset_time', align_range=(-100, 500), ignored_trials=~trial_mask)\n",
    "# active_trials_pca = nans([n_trials,n_timepoints,n_dims])\n",
    "# i = 0\n",
    "# for idx, trial in active_data.groupby('trial_id'):\n",
    "#     active_trials_pca[i,:,:]=trial.PCA.to_numpy()\n",
    "#     i+=1\n",
    "# print(active_trials_pca.shape)\n",
    "\n",
    "# plot_dir = np.array([0,45,90,135,180,225,270,315]) # limit plot directions to reduce cluttering\n",
    "# directions = np.array([0,45,90,135,180,225,270,315])\n",
    "# pred_range = (-100, 500)\n",
    "# x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "\n",
    "# # define some useful time points\n",
    "# move_idx=0\n",
    "# ret_idx = 200\n",
    "\n",
    "# import matplotlib as mpl\n",
    "# cmap = plt.get_cmap('coolwarm',len(plot_dir))\n",
    "# custom_palette = [mpl.colors.rgb2hex(cmap(i)) for i in range(len(plot_dir))]\n",
    "\n",
    "# plot_dims = 10\n",
    "\n",
    "# fig,ax=plt.subplots(plot_dims,1,figsize=(10,20))\n",
    "# for i in range(plot_dims):\n",
    "#     for j in range(len(plot_dir)):\n",
    "#         color = custom_palette[j]\n",
    "#         dir_idx = np.argwhere(directions == plot_dir[j])[0]\n",
    "#         cond_mean_proj = np.mean(active_trials_pca[np.argwhere(cond_dict==dir_idx).flatten(),:,:], axis = 0)[:,i] \n",
    "#         pca_mean = np.mean(active_data.PCA.to_numpy(),axis = 0)[i]\n",
    "#         ax[i].plot(x_axis,cond_mean_proj - pca_mean,linewidth=2.25,color = color,label = plot_dir[j])\n",
    "        \n",
    "#         ax[i].axvline(move_idx, color='k',linewidth = .5)\n",
    "#         ax[i].axvline(ret_idx, color='k',linewidth = .5)\n",
    "# #         ax[i].set_xlim([0,T])\n",
    "#         ax[i].set_ylim([-6, 6])\n",
    "#         ax[i].axhline(0,color ='k',ls = '--')\n",
    "#         if i<plot_dims-1:\n",
    "#             ax[i].set_xticks([])\n",
    "#         else:\n",
    "#             ax[i].set_xlabel('Time (ms)')\n",
    "            \n",
    "#         ax[i].set_yticks([])\n",
    "#         ax[i].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "#     ax[0].set_title('PCA Projections')\n",
    "    \n",
    "# plt.legend(bbox_to_anchor = (1, 1), loc = 'upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fb1fa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_test(X,y,training_set,test_set):\n",
    "    X_train = X[training_set,:,:]\n",
    "    X_test = X[test_set,:,:]\n",
    "    y_train = y[training_set,:,:]\n",
    "    y_test = y[test_set,:,:]\n",
    "\n",
    "    #flat by trials\n",
    "    X_flat_train = X_train.reshape((X_train.shape[0]*X_train.shape[1]),X_train.shape[2])\n",
    "    X_flat_test = X_test.reshape((X_test.shape[0]*X_test.shape[1]),X_test.shape[2])\n",
    "    y_train=y_train.reshape((y_train.shape[0]*y_train.shape[1]),y_train.shape[2])\n",
    "    y_test=y_test.reshape((y_test.shape[0]*y_test.shape[1]),y_test.shape[2])\n",
    "    \n",
    "    X_flat_train_mean=np.nanmean(X_flat_train,axis=0)\n",
    "    X_flat_train_std=np.nanstd(X_flat_train,axis=0)   \n",
    "    #array with only 0 will have 0 std and cause errors\n",
    "    X_flat_train_std[X_flat_train_std==0] = 1\n",
    "    \n",
    "    X_flat_train=(X_flat_train-X_flat_train_mean)/X_flat_train_std\n",
    "    X_flat_test=(X_flat_test-X_flat_train_mean)/X_flat_train_std\n",
    "    y_train_mean=np.mean(y_train,axis=0)\n",
    "    y_train=y_train-y_train_mean\n",
    "    y_test=y_test-y_train_mean    \n",
    "    \n",
    "    return X_flat_train,X_flat_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a471aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict_weighted(dataset, trial_mask, align_field, align_range, lag, x_field, y_field):\n",
    "    \"\"\"Extracts spiking and kinematic data from selected trials and fits linear decoder\"\"\"\n",
    "    # Extract rate data from selected trials\n",
    "    vel_df = dataset.make_trial_data(align_field=align_field, align_range=align_range, ignored_trials=~trial_mask)\n",
    "    # Lag alignment for kinematics and extract kinematics data from selected trials\n",
    "    lag_align_range = (align_range[0] + lag, align_range[1] + lag)\n",
    "    rates_df = dataset.make_trial_data(align_field=align_field, align_range=lag_align_range, ignored_trials=~trial_mask)\n",
    "    \n",
    "    n_trials = rates_df['trial_id'].nunique()\n",
    "    n_timepoints = int((align_range[1] - align_range[0])/dataset.bin_width)\n",
    "    n_neurons = rates_df[x_field].shape[1]\n",
    "    \n",
    "    lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)})\n",
    "    rates_array = rates_df[x_field].to_numpy()\n",
    "    vel_array = vel_df[y_field].to_numpy()\n",
    "    \n",
    "    vel_array_reshaped = vel_array.reshape(n_trials, n_timepoints, 2)\n",
    "    sw = 1/((np.std(vel_array_reshaped[:,:,0],axis = 0) + np.std(vel_array_reshaped[:,:,1],axis = 0))/2)\n",
    "    \n",
    "    lr_all.fit(rates_array, vel_array,sample_weight = np.tile(sw,n_trials))\n",
    "    pred_vel = lr_all.predict(rates_array)\n",
    "    vel_df = pd.concat([vel_df, pd.DataFrame(pred_vel, columns=dataset._make_midx('pred_vel', ['x', 'y'], 2))], axis=1)\n",
    "#     print(lr_all.best_params_['alpha'])\n",
    "    \n",
    "    rates_array = rates_array.reshape(n_trials, n_timepoints, n_neurons)\n",
    "    vel_array = vel_array_reshaped\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "    true_concat = nans([n_trials*n_timepoints,2])\n",
    "    pred_concat = nans([n_trials*n_timepoints,2])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test, y_train, y_test = process_train_test(rates_array,vel_array,training_set,test_set)\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)}) \n",
    "        lr.fit(X_train, y_train,sample_weight = np.tile(sw,training_set.shape[0]))\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "        \n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "        trial_save_idx += n\n",
    "    \n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    print('R2:',R2) \n",
    "    return R2, lr_all.best_estimator_.coef_, vel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9f0762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(dataset, trial_mask, align_field, align_range, lag, x_field, y_field):\n",
    "    \"\"\"Extracts spiking and kinematic data from selected trials and fits linear decoder\"\"\"\n",
    "    # Extract rate data from selected trials\n",
    "    vel_df = dataset.make_trial_data(align_field=align_field, align_range=align_range, ignored_trials=~trial_mask)\n",
    "    # Lag alignment for kinematics and extract kinematics data from selected trials\n",
    "    lag_align_range = (align_range[0] + lag, align_range[1] + lag)\n",
    "    rates_df = dataset.make_trial_data(align_field=align_field, align_range=lag_align_range, ignored_trials=~trial_mask)\n",
    "    \n",
    "    n_trials = rates_df['trial_id'].nunique()\n",
    "    n_timepoints = int((align_range[1] - align_range[0])/dataset.bin_width)\n",
    "    n_neurons = rates_df[x_field].shape[1]\n",
    "    \n",
    "    lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)})\n",
    "    rates_array = rates_df[x_field].to_numpy()\n",
    "    vel_array = vel_df[y_field].to_numpy()\n",
    "    lr_all.fit(rates_array, vel_array)\n",
    "    pred_vel = lr_all.predict(rates_array)\n",
    "    vel_df = pd.concat([vel_df, pd.DataFrame(pred_vel, columns=dataset._make_midx('pred_vel', ['x', 'y'], 2))], axis=1)\n",
    "#     print(lr_all.best_params_['alpha'])\n",
    "    \n",
    "    rates_array = rates_array.reshape(n_trials, n_timepoints, n_neurons)\n",
    "    vel_array = vel_array.reshape(n_trials, n_timepoints, 2)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "    true_concat = nans([n_trials*n_timepoints,2])\n",
    "    pred_concat = nans([n_trials*n_timepoints,2])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test, y_train, y_test = process_train_test(rates_array,vel_array,training_set,test_set)\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)}) \n",
    "        lr.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "        \n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "        trial_save_idx += n\n",
    "    \n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    print('R2:',R2) \n",
    "    return R2, lr_all.best_estimator_.coef_, vel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb0e7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_and_predict(dataset, trial_mask, align_field, align_range, lag, x_field, y_field, weights):\n",
    "    \"\"\"Extracts spiking and kinematic data from selected trials and fits linear decoder\"\"\"\n",
    "    # Extract rate data from selected trials\n",
    "    vel_df = dataset.make_trial_data(align_field=align_field, align_range=align_range, ignored_trials=~trial_mask)\n",
    "    # Lag alignment for kinematics and extract kinematics data from selected trials\n",
    "    lag_align_range = (align_range[0] + lag, align_range[1] + lag)\n",
    "    rates_df = dataset.make_trial_data(align_field=align_field, align_range=lag_align_range, ignored_trials=~trial_mask)\n",
    "    \n",
    "    n_trials = rates_df['trial_id'].nunique()\n",
    "    n_timepoints = int((align_range[1] - align_range[0])/dataset.bin_width)\n",
    "    n_neurons = rates_df[x_field].shape[1]\n",
    "\n",
    "    rates_array = rates_df[x_field].to_numpy() - calc_proj(rates_df[x_field].to_numpy(),weights.T).T\n",
    "    vel_array = vel_df[y_field].to_numpy()\n",
    "    \n",
    "    lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)})\n",
    "    lr_all.fit(rates_array, vel_array)\n",
    "    pred_vel = lr_all.predict(rates_array)\n",
    "    vel_df = pd.concat([vel_df, pd.DataFrame(pred_vel, columns=dataset._make_midx('pred_vel', ['x', 'y'], 2))], axis=1)\n",
    "#     print(lr_all.best_params_['alpha'])\n",
    "    \n",
    "    rates_array = rates_array.reshape(n_trials, n_timepoints, n_neurons)\n",
    "    vel_array = vel_array.reshape(n_trials, n_timepoints, 2)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "    true_concat = nans([n_trials*n_timepoints,2])\n",
    "    pred_concat = nans([n_trials*n_timepoints,2])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test, y_train, y_test = process_train_test(rates_array,vel_array,training_set,test_set)\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)}) \n",
    "        lr.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "        \n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "        trial_save_idx += n\n",
    "    \n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    print('R2:',R2) \n",
    "    return R2, lr_all.best_estimator_.coef_, vel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b23884",
   "metadata": {},
   "source": [
    "### Timing plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aea2209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153 neurons\n"
     ]
    }
   ],
   "source": [
    "n_neurons = dataset_5ms.data.spikes.shape[1]\n",
    "print(n_neurons,'neurons')\n",
    "\n",
    "active_mask = (~dataset_5ms.trial_info.ctr_hold_bump) & (dataset_5ms.trial_info.split != 'none')\n",
    "passive_mask = (dataset_5ms.trial_info.ctr_hold_bump) & (dataset_5ms.trial_info.split != 'none')\n",
    "\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/timing/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1715590",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_range = (-40, 100)\n",
    "x_axis = np.arange(plot_range[0], plot_range[1], dataset_5ms.bin_width)\n",
    "passive_df = dataset_5ms.make_trial_data(align_field='move_onset_time', align_range=plot_range, ignored_trials=~passive_mask)\n",
    "active_df = dataset_5ms.make_trial_data(align_field='move_onset_time', align_range=plot_range, ignored_trials=~active_mask)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for _, trial in active_df.groupby('trial_id'):\n",
    "    plt.plot(x_axis, trial.force['y'], color='k', linewidth=0.5)\n",
    "for _, trial in passive_df.groupby('trial_id'):\n",
    "    plt.plot(x_axis, trial.force['y'], color='red', linewidth=0.5)\n",
    "plt.xlabel('Time after bump time (ms)')\n",
    "plt.ylabel('Force to manipulandum (N)')\n",
    "plt.axvline(0, color = 'k',linestyle = '--')\n",
    "plt.title('Force aligned to move_onset')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + '_force.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07648a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for _, trial in active_df.groupby('trial_id'):\n",
    "    plt.plot(x_axis,trial.speed, color='k', linewidth=0.5)\n",
    "for _, trial in passive_df.groupby('trial_id'):\n",
    "    plt.plot(x_axis, trial.speed, color='red', linewidth=0.5)\n",
    "plt.xlabel('Time after movement onset (ms)')\n",
    "plt.ylabel('Hand speed (cm/s)')\n",
    "plt.axvline(0, color = 'k',linestyle = '--')\n",
    "plt.title('Speed aligned to move_onset')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + '_speed.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2ed152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for _, trial in active_df.groupby('trial_id'):\n",
    "    plt.plot(x_axis,trial.acceleration, color='k', linewidth=0.5)\n",
    "for _, trial in passive_df.groupby('trial_id'):\n",
    "    plt.plot(x_axis, trial.acceleration, color='red', linewidth=0.5)\n",
    "plt.xlabel('Time after movement onset (ms)')\n",
    "plt.ylabel('Hand acceleration (cm/s^2)')\n",
    "plt.axvline(0, color = 'k',linestyle = '--')\n",
    "plt.title('Acceleration aligned to move_onset')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + '_acc.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc083d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_trials_spikes = []\n",
    "for _, trial in active_df.groupby('trial_id'):\n",
    "    active_trials_spikes.append(np.sum(trial.spikes,axis=1))\n",
    "passive_trials_spikes = []\n",
    "for _, trial in passive_df.groupby('trial_id'):\n",
    "    passive_trials_spikes.append(np.sum(trial.spikes,axis=1))\n",
    "plt.plot(x_axis,np.sum(active_trials_spikes,axis = 0)/dataset_5ms.bin_width*1000/len(active_trials_spikes)/n_neurons,\"-o\",color = 'k',label = 'Active')\n",
    "plt.plot(x_axis,np.sum(passive_trials_spikes,axis = 0)/dataset_5ms.bin_width*1000/len(passive_trials_spikes)/n_neurons,\"-o\",color = 'red',label = 'Passive')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('Peristimulus aligned to move_onset')\n",
    "plt.ylabel('Trial-average, neuron-average, FR (per sec)')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.axvline(0, color = 'k',linestyle = '--')    \n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + '_psth.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aa96979",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_range = (-500, 600)\n",
    "x_axis = np.arange(plot_range[0], plot_range[1], dataset_5ms.bin_width)\n",
    "active_df = dataset_5ms.make_trial_data(align_field='move_onset_time', align_range=plot_range, ignored_trials=~active_mask)\n",
    "passive_df = dataset_5ms.make_trial_data(align_field='move_onset_time', align_range=plot_range, ignored_trials=~passive_mask)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for _, trial in active_df.groupby('trial_id'):\n",
    "    plt.plot(x_axis,trial.speed, color='k', linewidth=0.5)\n",
    "for _, trial in passive_df.groupby('trial_id'):\n",
    "    plt.plot(x_axis, trial.speed, color='red', linewidth=0.5)\n",
    "plt.xlabel('Time after movement onset (ms)')\n",
    "plt.ylabel('Hand speed (cm/s)')\n",
    "plt.axvline(0, color = 'k',linestyle = '--')\n",
    "plt.title('Speed aligned to move_onset')\n",
    "plt.axvline(120, color = 'k',linestyle = '--')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + '_speed_whole.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257bacfe",
   "metadata": {},
   "source": [
    "## with Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106dc233",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_axis = np.arange(-300,300,20)\n",
    "x_field = 'spikes_smth_40'\n",
    "y_field ='hand_acc'\n",
    "trial_mask = active_mask\n",
    "\n",
    "# Prepare for plotting\n",
    "plot_dir = [0.0, 90.0, 180.0, 270.0] # limit plot directions to reduce cluttering\n",
    "plot_dim = 'x' # plot x velocity\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/neurons/act/\"\n",
    "\n",
    "dim = n_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a60097",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ranges = [(-100,500),(0,120),(-100,120),(380,500)]\n",
    "labels = ['_whole_acc_','_early_acc_','_long_acc_','_late_acc_']\n",
    "\n",
    "for pred_range, label in zip(ranges, labels):\n",
    "    x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "    curr_r2_array = nans([len(lag_axis)])\n",
    "    curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "        curr_r2_array[i] = r2\n",
    "        curr_coef_array[i,:,:] = coef\n",
    "\n",
    "    idx_max = np.argmax(curr_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    _, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial[y_field][plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel(plot_dim + '_' + y_field)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + 'true.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel(plot_dim + '_' + y_field)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(lag_axis, curr_r2_array)\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.title('R2 score predicting ' + y_field + ' ' + str(pred_range))\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    # ang_dist_to_max = nans([len(lag_axis)])\n",
    "    # for i in range(0, len(curr_coef_array)):\n",
    "    #     ang_dist_to_max[i] = math.degrees(angle_between(curr_coef_array[i,0,:],curr_coef_array[idx_max,0,:]))\n",
    "    # plt.scatter(lag_axis, ang_dist_to_max)\n",
    "    # plt.title('Angular distance to X-vel decoding dim at t_max')\n",
    "    # plt.xlabel('Time lag (ms)')\n",
    "    # plt.ylabel('Angular distance (degrees)')\n",
    "    # plt.show()\n",
    "\n",
    "    weights = curr_coef_array[idx_max,:,:]\n",
    "    for iter in range(0,3):  \n",
    "        #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "        sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "        sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "        for i in range(len(lag_axis)):\n",
    "            lag = lag_axis[i]\n",
    "            r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "            sub_r2_array[i] = r2\n",
    "            sub_coef_array[i,:,:] = coef\n",
    "\n",
    "        plt.plot(lag_axis,sub_r2_array)\n",
    "        plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "        idx_max = np.argmax(sub_r2_array)\n",
    "        time_max = lag_axis[idx_max]\n",
    "        plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "        plt.legend()\n",
    "        plt.xlabel('Time lag (ms)')\n",
    "        plt.ylabel('R2')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "        plt.close()\n",
    "\n",
    "        _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "        for trial_dir, color in zip(plot_dir, colors):\n",
    "            cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "            for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "                plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "        plt.xlabel('Time (ms)')\n",
    "        plt.ylabel(plot_dim + '_' + y_field)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "        plt.close()\n",
    "    #     plt.plot(lag_axis,np.subtract(sub_r2_array,curr_r2_array))\n",
    "    #     plt.axhline(0,color = 'k',linestyle='--')\n",
    "    #     plt.title('R2 difference after projecting out t_max dim')\n",
    "    #     plt.xlabel('Time lag (ms)')\n",
    "    #     plt.ylabel('R2 difference')\n",
    "    #     plt.show()\n",
    "    #     curr_r2_array = sub_r2_array\n",
    "\n",
    "        #stack the decoding dimensions to be projected out\n",
    "        weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f030f4",
   "metadata": {},
   "source": [
    "## with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56d6d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_field = 'PCA'\n",
    "y_field ='hand_acc'\n",
    "lag_axis = np.arange(-300,300,20)\n",
    "\n",
    "# Prepare for plotting\n",
    "plot_dir = [0.0, 90.0, 180.0, 270.0] # limit plot directions to reduce cluttering\n",
    "plot_dim = 'x' # plot x velocity\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/PCA/act/\"\n",
    "\n",
    "dim = n_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65b70dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.20108665895930988\n",
      "R2: 0.2090813595297727\n",
      "R2: 0.21686707029932228\n",
      "R2: 0.2287397789986162\n",
      "R2: 0.24907191576203402\n",
      "R2: 0.2800789359218361\n",
      "R2: 0.3206308096301407\n",
      "R2: 0.3666682980085152\n",
      "R2: 0.4119342932970589\n",
      "R2: 0.44989643165416193\n",
      "R2: 0.476223915889864\n",
      "R2: 0.49018000003924733\n",
      "R2: 0.49396087916401765\n",
      "R2: 0.49076502931710064\n",
      "R2: 0.4843687079323169\n",
      "R2: 0.4803141628067714\n",
      "R2: 0.48448488830043557\n",
      "R2: 0.49767260675426594\n",
      "R2: 0.5123928757338442\n",
      "R2: 0.5173884986747995\n",
      "R2: 0.5055518819844045\n",
      "R2: 0.4766909403323176\n",
      "R2: 0.43491843507004424\n",
      "R2: 0.38572339710133086\n",
      "R2: 0.3352378821346095\n",
      "R2: 0.2898146244557366\n",
      "R2: 0.25427370049030595\n",
      "R2: 0.23013860114844198\n",
      "R2: 0.2156763430458335\n",
      "R2: 0.20719574109500283\n",
      "R2: 0.5173884986747995\n",
      "R2: 0.17931330338298923\n",
      "R2: 0.18357138503869963\n",
      "R2: 0.18608345762968603\n",
      "R2: 0.19164784713430183\n",
      "R2: 0.20570763615780396\n",
      "R2: 0.23187807479678157\n",
      "R2: 0.27034031874639475\n",
      "R2: 0.31799362098774275\n",
      "R2: 0.3690533580600882\n",
      "R2: 0.41647136084369263\n",
      "R2: 0.4538014939341687\n",
      "R2: 0.47617314996780824\n",
      "R2: 0.47977763752876434\n",
      "R2: 0.46118178518077924\n",
      "R2: 0.41863742491474787\n",
      "R2: 0.35588428647184445\n",
      "R2: 0.28464803196268895\n",
      "R2: 0.2212124088287667\n",
      "R2: 0.1789650693799193\n",
      "R2: 0.16287183427306662\n",
      "R2: 0.16914867278281598\n",
      "R2: 0.18853734757795726\n",
      "R2: 0.21061975346077322\n",
      "R2: 0.2272786219931976\n",
      "R2: 0.2345080551726546\n",
      "R2: 0.23255236092778742\n",
      "R2: 0.2242588283897563\n",
      "R2: 0.21259313688784476\n",
      "R2: 0.19912701513534947\n",
      "R2: 0.18425656605436402\n",
      "R2: 0.47977763752876434\n",
      "R2: 0.1463136880294228\n",
      "R2: 0.15838424762243508\n",
      "R2: 0.16822056860063228\n",
      "R2: 0.17782934696971553\n",
      "R2: 0.18862658916754094\n",
      "R2: 0.19979172110043586\n",
      "R2: 0.2085696920568173\n",
      "R2: 0.21225793431565876\n",
      "R2: 0.20946389226992956\n",
      "R2: 0.2005186183016583\n",
      "R2: 0.18743442192660287\n",
      "R2: 0.17354941942942792\n",
      "R2: 0.16220404239925257\n",
      "R2: 0.15458640737809737\n",
      "R2: 0.14880701153435882\n",
      "R2: 0.14236695348604755\n",
      "R2: 0.1356135485566663\n",
      "R2: 0.1320197246248751\n",
      "R2: 0.13514529246885476\n",
      "R2: 0.14577902363635897\n",
      "R2: 0.16158109571624246\n",
      "R2: 0.17855082133938105\n",
      "R2: 0.19264180210028026\n",
      "R2: 0.20065370936533788\n",
      "R2: 0.20108897491767874\n",
      "R2: 0.1946996631634319\n",
      "R2: 0.1838572238359667\n",
      "R2: 0.1711086361342501\n",
      "R2: 0.15804090550011207\n",
      "R2: 0.1451552648355705\n",
      "R2: 0.21225793431565876\n",
      "R2: 0.1350708554445078\n",
      "R2: 0.14113388481190825\n",
      "R2: 0.14169222932635406\n",
      "R2: 0.13673061793778551\n",
      "R2: 0.12680968835233475\n",
      "R2: 0.11307222784328397\n",
      "R2: 0.09749368572812511\n",
      "R2: 0.08320871436488486\n",
      "R2: 0.07371841923272171\n",
      "R2: 0.07120376869251799\n",
      "R2: 0.07559196031192694\n",
      "R2: 0.08491193621643467\n",
      "R2: 0.09620268077128202\n",
      "R2: 0.10616653169069401\n",
      "R2: 0.11193411012690369\n",
      "R2: 0.1127343742207082\n",
      "R2: 0.11104907773303274\n",
      "R2: 0.11137423788002099\n",
      "R2: 0.1175372943244466\n",
      "R2: 0.1305190242786758\n",
      "R2: 0.14820758653313282\n",
      "R2: 0.16672670505232035\n",
      "R2: 0.18203042463950136\n",
      "R2: 0.1908195436954243\n",
      "R2: 0.19130969236946127\n",
      "R2: 0.18400543939088299\n",
      "R2: 0.17140686471786526\n",
      "R2: 0.1566122469909752\n",
      "R2: 0.14189549621116126\n",
      "R2: 0.1281645494115019\n",
      "R2: 0.19130969236946127\n",
      "R2: -0.07495108096565262\n",
      "R2: -0.0779267059153379\n",
      "R2: -0.0830338481413182\n",
      "R2: -0.08746868319323031\n",
      "R2: -0.08499819215944715\n",
      "R2: -0.0701578379388208\n",
      "R2: -0.03398701873308729\n",
      "R2: 0.0394424515792402\n",
      "R2: 0.15179281986852733\n",
      "R2: 0.2838127308016588\n",
      "R2: 0.4157540945712741\n",
      "R2: 0.5346124433151266\n",
      "R2: 0.6316691906385095\n",
      "R2: 0.7007642921011474\n",
      "R2: 0.743094681074298\n",
      "R2: 0.7653216600302714\n",
      "R2: 0.7734742662175409\n",
      "R2: 0.7727440265269575\n",
      "R2: 0.7678519736314896\n",
      "R2: 0.7625539449367851\n",
      "R2: 0.7582661845313441\n",
      "R2: 0.7542949882886321\n",
      "R2: 0.7498501779195226\n",
      "R2: 0.7446163877995611\n",
      "R2: 0.7384385730130744\n",
      "R2: 0.7313735724979189\n",
      "R2: 0.723359387787947\n",
      "R2: 0.713987231632156\n",
      "R2: 0.7024285683575153\n",
      "R2: 0.6881809017953132\n",
      "R2: 0.7734742662175409\n",
      "R2: -0.06572833768067499\n",
      "R2: -0.07344090161843053\n",
      "R2: -0.08302002841146305\n",
      "R2: -0.08948740290831081\n",
      "R2: -0.08587043257453963\n",
      "R2: -0.0691967953774344\n",
      "R2: -0.03503739980024512\n",
      "R2: 0.028612349354160016\n",
      "R2: 0.12629363508770064\n",
      "R2: 0.24331870482217866\n",
      "R2: 0.3621824847581486\n",
      "R2: 0.4623662898004858\n",
      "R2: 0.5228766128358786\n",
      "R2: 0.5324584526926919\n",
      "R2: 0.49881060920345843\n",
      "R2: 0.4537290280965337\n",
      "R2: 0.4394973784452809\n",
      "R2: 0.4660370590099754\n",
      "R2: 0.5114013001770158\n",
      "R2: 0.5546979527020116\n",
      "R2: 0.5924357276698666\n",
      "R2: 0.628016651833134\n",
      "R2: 0.6603659304810934\n",
      "R2: 0.6874536636993593\n",
      "R2: 0.707151862382396\n",
      "R2: 0.717646406569223\n",
      "R2: 0.7190533397131416\n",
      "R2: 0.712491106589265\n",
      "R2: 0.6997616135783429\n",
      "R2: 0.6825761007425097\n",
      "R2: 0.7190533397131416\n",
      "R2: -0.049908681502086605\n",
      "R2: -0.05768949025717185\n",
      "R2: -0.06756263416693709\n",
      "R2: -0.07450231189963596\n",
      "R2: -0.07232898575807245\n",
      "R2: -0.05908436196816935\n",
      "R2: -0.0313621186286992\n",
      "R2: 0.022845673605931816\n",
      "R2: 0.11226309242733734\n",
      "R2: 0.22851000275473454\n",
      "R2: 0.3511142877507052\n",
      "R2: 0.4538530283657881\n",
      "R2: 0.515457067360457\n",
      "R2: 0.5268586682786269\n",
      "R2: 0.49608788858345565\n",
      "R2: 0.4520765551393138\n",
      "R2: 0.43324271656478\n",
      "R2: 0.44972380122492017\n",
      "R2: 0.48187426897457997\n",
      "R2: 0.5072072792292037\n",
      "R2: 0.5136423745724101\n",
      "R2: 0.5000005867000514\n",
      "R2: 0.4725875016887412\n",
      "R2: 0.4439011080740555\n",
      "R2: 0.42634391415509176\n",
      "R2: 0.4214533354809724\n",
      "R2: 0.4227823522143994\n",
      "R2: 0.42556249158795856\n",
      "R2: 0.43020512506081965\n",
      "R2: 0.4400896925376311\n",
      "R2: 0.5268586682786269\n",
      "R2: -0.05419406417059114\n",
      "R2: -0.059775260029357735\n",
      "R2: -0.06514881382582138\n",
      "R2: -0.06729941681800033\n",
      "R2: -0.06114917954624577\n",
      "R2: -0.046896789069542866\n",
      "R2: -0.027659457291606016\n",
      "R2: -0.0011347811037865085\n",
      "R2: 0.03556537435320728\n",
      "R2: 0.075513932880788\n",
      "R2: 0.108835939155425\n",
      "R2: 0.13094478842110102\n",
      "R2: 0.14191383775472632\n",
      "R2: 0.15049350435707698\n",
      "R2: 0.16973750649201358\n",
      "R2: 0.21101856073358538\n",
      "R2: 0.2795602091077213\n",
      "R2: 0.361782143633373\n",
      "R2: 0.4341418981809355\n",
      "R2: 0.479517867172945\n",
      "R2: 0.4932270773039189\n",
      "R2: 0.4811745269696157\n",
      "R2: 0.4539863613707541\n",
      "R2: 0.42561225975078765\n",
      "R2: 0.40750956998558896\n",
      "R2: 0.4008351013471607\n",
      "R2: 0.4006100163797458\n",
      "R2: 0.4020268662998375\n",
      "R2: 0.40461321319069077\n",
      "R2: 0.4126071506122385\n",
      "R2: 0.4932270773039189\n",
      "R2: -0.0371035365425092\n",
      "R2: -0.040176017658216434\n",
      "R2: -0.043476130281127956\n",
      "R2: -0.04622254156123495\n",
      "R2: -0.04687022147439457\n",
      "R2: -0.04191388781196426\n",
      "R2: -0.023821525112048825\n",
      "R2: 0.021990358128215037\n",
      "R2: 0.10673795841860789\n",
      "R2: 0.22020546140111696\n",
      "R2: 0.3423347935258172\n",
      "R2: 0.45843371904932073\n",
      "R2: 0.5553004373683319\n",
      "R2: 0.6231854705255657\n",
      "R2: 0.6623004118885321\n",
      "R2: 0.6830792291178175\n",
      "R2: 0.6955593484089964\n",
      "R2: 0.7023461213788045\n",
      "R2: 0.7024721723282157\n",
      "R2: 0.6970805359577549\n",
      "R2: 0.6890443997538007\n",
      "R2: 0.6794109418927399\n",
      "R2: 0.6684596661063761\n",
      "R2: 0.6568158272098277\n",
      "R2: 0.6445889587827286\n",
      "R2: 0.630746732056292\n",
      "R2: 0.6138900341181881\n",
      "R2: 0.5936651476294259\n",
      "R2: 0.570487874499441\n",
      "R2: 0.5454846216338254\n",
      "R2: 0.7024721723282157\n",
      "R2: -0.030897550164653342\n",
      "R2: -0.034975691802477504\n",
      "R2: -0.03947829543754855\n",
      "R2: -0.042701540013983186\n",
      "R2: -0.04274558641998083\n",
      "R2: -0.03686104351859365\n",
      "R2: -0.018574475394800283\n",
      "R2: 0.025997153986600297\n",
      "R2: 0.1085427166867956\n",
      "R2: 0.21969301682069975\n",
      "R2: 0.33909738398736167\n",
      "R2: 0.4505743324914636\n",
      "R2: 0.537799116376062\n",
      "R2: 0.5849969539314183\n",
      "R2: 0.584532548690698\n",
      "R2: 0.5431201412522225\n",
      "R2: 0.477763976534074\n",
      "R2: 0.4070647416163088\n",
      "R2: 0.3500258524814561\n",
      "R2: 0.326623251580631\n",
      "R2: 0.3442119037346675\n",
      "R2: 0.38882342795151725\n",
      "R2: 0.4421041829628277\n",
      "R2: 0.49290327278261914\n",
      "R2: 0.535517678066687\n",
      "R2: 0.5658633755806004\n",
      "R2: 0.5808939677288726\n",
      "R2: 0.579936277739149\n",
      "R2: 0.5648655181735133\n",
      "R2: 0.5400713509272856\n",
      "R2: 0.5849969539314183\n",
      "R2: -0.026223235331949812\n",
      "R2: -0.029212246398014452\n",
      "R2: -0.03276283917060718\n",
      "R2: -0.035748448433512436\n",
      "R2: -0.035950408167868764\n",
      "R2: -0.03169906870778472\n",
      "R2: -0.02252219207785755\n",
      "R2: -0.007100128358218827\n",
      "R2: 0.018016801784072056\n",
      "R2: 0.054058941104236036\n",
      "R2: 0.09593253751401043\n",
      "R2: 0.13697773763292265\n",
      "R2: 0.17129289518254576\n",
      "R2: 0.19479856214635316\n",
      "R2: 0.2084401137778249\n",
      "R2: 0.21822096523326895\n",
      "R2: 0.2307937954305722\n",
      "R2: 0.24769860041410074\n",
      "R2: 0.26516346832773674\n",
      "R2: 0.2840210134501212\n",
      "R2: 0.3116949600856155\n",
      "R2: 0.3508738701504214\n",
      "R2: 0.3968183140103817\n",
      "R2: 0.44300737976970406\n",
      "R2: 0.4834704756929681\n",
      "R2: 0.5122489331702503\n",
      "R2: 0.5247474808128427\n",
      "R2: 0.5202588175624113\n",
      "R2: 0.5028059007965774\n",
      "R2: 0.47959697618712605\n",
      "R2: 0.5247474808128427\n",
      "R2: -0.019146889880573115\n",
      "R2: -0.021216229689355437\n",
      "R2: -0.023610883082489487\n",
      "R2: -0.025473695634791627\n",
      "R2: -0.024939201935854305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.02065423633155361\n",
      "R2: -0.012173683642760391\n",
      "R2: 0.002084523543136263\n",
      "R2: 0.025984519032818842\n",
      "R2: 0.06070056979993543\n",
      "R2: 0.09912116579335728\n",
      "R2: 0.1332018477016601\n",
      "R2: 0.15933754175747583\n",
      "R2: 0.1769515500162948\n",
      "R2: 0.189461913626514\n",
      "R2: 0.20301165219641437\n",
      "R2: 0.22095801159338835\n",
      "R2: 0.2416778462678939\n",
      "R2: 0.259642126108214\n",
      "R2: 0.2690842435296523\n",
      "R2: 0.2673540386293056\n",
      "R2: 0.25358404573216853\n",
      "R2: 0.22865814707838972\n",
      "R2: 0.1986796380962247\n",
      "R2: 0.17376752881459456\n",
      "R2: 0.16064785811569515\n",
      "R2: 0.15873871760244307\n",
      "R2: 0.1641561034763348\n",
      "R2: 0.17598077184687066\n",
      "R2: 0.19735830737607984\n",
      "R2: 0.2690842435296523\n",
      "R2: 0.5156874482396526\n",
      "R2: 0.520468058291486\n",
      "R2: 0.5314703709410966\n",
      "R2: 0.5458286133711046\n",
      "R2: 0.5619669553762936\n",
      "R2: 0.5808235664858098\n",
      "R2: 0.6031643854171402\n",
      "R2: 0.6301507343150561\n",
      "R2: 0.6618588260253477\n",
      "R2: 0.6943075299077424\n",
      "R2: 0.720461083209408\n",
      "R2: 0.7343980178236041\n",
      "R2: 0.7329246377175495\n",
      "R2: 0.7153131693959109\n",
      "R2: 0.6848070643737694\n",
      "R2: 0.653428635235352\n",
      "R2: 0.6386586082875076\n",
      "R2: 0.646839213109106\n",
      "R2: 0.6644114927238317\n",
      "R2: 0.6709714279010268\n",
      "R2: 0.6554643058770769\n",
      "R2: 0.619698847640509\n",
      "R2: 0.5739378807671522\n",
      "R2: 0.5289441855710548\n",
      "R2: 0.4916805171829328\n",
      "R2: 0.46254050249678047\n",
      "R2: 0.43740571701667175\n",
      "R2: 0.41158832510609444\n",
      "R2: 0.3820371753676691\n",
      "R2: 0.34929107846533713\n",
      "R2: 0.7343980178236041\n",
      "R2: 0.4751845449219857\n",
      "R2: 0.4902664994662018\n",
      "R2: 0.506797259750422\n",
      "R2: 0.5207892861798508\n",
      "R2: 0.5303126824410453\n",
      "R2: 0.5364023145740873\n",
      "R2: 0.5393251428935077\n",
      "R2: 0.5385955755549916\n",
      "R2: 0.5336353794993257\n",
      "R2: 0.5234597910687111\n",
      "R2: 0.5093408521751057\n",
      "R2: 0.497834893909461\n",
      "R2: 0.49551693396922936\n",
      "R2: 0.5067113478383793\n",
      "R2: 0.5313934090509403\n",
      "R2: 0.5627159436159823\n",
      "R2: 0.5933649821326992\n",
      "R2: 0.6187398607051753\n",
      "R2: 0.632576951106014\n",
      "R2: 0.6291866177382253\n",
      "R2: 0.6089696337603658\n",
      "R2: 0.5770497387804762\n",
      "R2: 0.5407381757921214\n",
      "R2: 0.5066378650598005\n",
      "R2: 0.47887864965132176\n",
      "R2: 0.45610419973605354\n",
      "R2: 0.43328756897513354\n",
      "R2: 0.4070167840714104\n",
      "R2: 0.37676332343858476\n",
      "R2: 0.3439695096131161\n",
      "R2: 0.632576951106014\n",
      "R2: 0.438150094106622\n",
      "R2: 0.45924610862488824\n",
      "R2: 0.4789048135402967\n",
      "R2: 0.49428848237984646\n",
      "R2: 0.5041041808402353\n",
      "R2: 0.5094391281437101\n",
      "R2: 0.5108428147555695\n",
      "R2: 0.5090611938089962\n",
      "R2: 0.5064780775099496\n",
      "R2: 0.5039356172202167\n",
      "R2: 0.4994808424207293\n",
      "R2: 0.49053664667705343\n",
      "R2: 0.4743838486897156\n",
      "R2: 0.4498178344906283\n",
      "R2: 0.4193449297913592\n",
      "R2: 0.387980920666403\n",
      "R2: 0.3603485069999549\n",
      "R2: 0.34104007595596586\n",
      "R2: 0.3333991054966896\n",
      "R2: 0.3340481925523886\n",
      "R2: 0.33390244841385786\n",
      "R2: 0.33074536642186836\n",
      "R2: 0.3324834456440482\n",
      "R2: 0.3430639616245862\n",
      "R2: 0.3557010105151378\n",
      "R2: 0.36253100765925095\n",
      "R2: 0.36090064141814693\n",
      "R2: 0.35123207438503135\n",
      "R2: 0.3342025759957101\n",
      "R2: 0.3118956474460899\n",
      "R2: 0.5108428147555695\n",
      "R2: 0.26742195526938073\n",
      "R2: 0.25400070253197005\n",
      "R2: 0.23863046898505758\n",
      "R2: 0.2194282770749294\n",
      "R2: 0.2023530140232218\n",
      "R2: 0.20198819383610345\n",
      "R2: 0.22458027985546203\n",
      "R2: 0.2604271865196429\n",
      "R2: 0.3008408144913004\n",
      "R2: 0.3438360573562772\n",
      "R2: 0.38495796293169904\n",
      "R2: 0.4158607811708932\n",
      "R2: 0.42831486843206734\n",
      "R2: 0.41937906575632933\n",
      "R2: 0.3936138306065965\n",
      "R2: 0.3582926850582263\n",
      "R2: 0.3203273746156128\n",
      "R2: 0.28794115533870734\n",
      "R2: 0.26706160085437936\n",
      "R2: 0.2556576101842426\n",
      "R2: 0.24772103465842565\n",
      "R2: 0.2427904282030413\n",
      "R2: 0.2466635546846816\n",
      "R2: 0.2619813564168274\n",
      "R2: 0.2836739772569137\n",
      "R2: 0.3047472001601125\n",
      "R2: 0.31934651689171356\n",
      "R2: 0.32378172544357975\n",
      "R2: 0.31683286217943407\n",
      "R2: 0.3004630153726978\n",
      "R2: 0.42831486843206734\n"
     ]
    }
   ],
   "source": [
    "ranges = [(-100,500),(0,120),(-100,120),(380,500)]\n",
    "labels = ['_whole_acc_','_early_acc_','_long_acc_','_late_acc_']\n",
    "\n",
    "for pred_range, label in zip(ranges, labels):\n",
    "    x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "    curr_r2_array = nans([len(lag_axis)])\n",
    "    curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "        curr_r2_array[i] = r2\n",
    "        curr_coef_array[i,:,:] = coef\n",
    "\n",
    "    idx_max = np.argmax(curr_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    _, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial[y_field][plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel(plot_dim + '_' + y_field)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + 'true.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel(plot_dim + '_' + y_field)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(lag_axis, curr_r2_array)\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.title('R2 score predicting ' + y_field + ' ' + str(pred_range))\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    weights = curr_coef_array[idx_max,:,:]\n",
    "    for iter in range(0,3):  \n",
    "        #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "        sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "        sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "        for i in range(len(lag_axis)):\n",
    "            lag = lag_axis[i]\n",
    "            r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "            sub_r2_array[i] = r2\n",
    "            sub_coef_array[i,:,:] = coef\n",
    "\n",
    "        plt.plot(lag_axis,sub_r2_array)\n",
    "        plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "        idx_max = np.argmax(sub_r2_array)\n",
    "        time_max = lag_axis[idx_max]\n",
    "        plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "        plt.legend()\n",
    "        plt.xlabel('Time lag (ms)')\n",
    "        plt.ylabel('R2')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "        plt.close()\n",
    "\n",
    "        _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "        for trial_dir, color in zip(plot_dir, colors):\n",
    "            cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "            for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "                plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "        plt.xlabel('Time (ms)')\n",
    "        plt.ylabel(plot_dim + '_' + y_field)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "        plt.close()\n",
    "\n",
    "        #stack the decoding dimensions to be projected out\n",
    "        weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9046b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80e66b89",
   "metadata": {},
   "source": [
    "# Multi Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8649848a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "dataset_50ms = NWBDataset(filename, split_heldout=False)\n",
    "xy_vel = dataset_50ms.data['hand_vel'].to_numpy()\n",
    "xy_acc = np.diff(xy_vel, axis = 0, prepend=[xy_vel[0]])\n",
    "dataset_50ms.add_continuous_data(xy_acc,'hand_acc',chan_names = ['x','y'])\n",
    "\n",
    "dataset_50ms.resample(50)\n",
    "print(dataset_50ms.bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fda3bfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245 trials\n",
      "153 neurons\n",
      "(55827, 153)\n",
      "(55827, 153)\n",
      "(55827, 20)\n",
      "PCA total var explained: 0.29908653398148444\n"
     ]
    }
   ],
   "source": [
    "n_dims = 20 # for PCA\n",
    "\n",
    "active_mask = (~dataset_50ms.trial_info.ctr_hold_bump) & (dataset_50ms.trial_info.split != 'none')\n",
    "passive_mask = (dataset_50ms.trial_info.ctr_hold_bump) & (dataset_50ms.trial_info.split != 'none')\n",
    "\n",
    "\n",
    "trial_mask = active_mask\n",
    "n_trials = dataset_50ms.trial_info.loc[trial_mask].shape[0]\n",
    "print(n_trials,'trials')\n",
    "n_neurons = dataset_50ms.data.spikes.shape[1]\n",
    "print(n_neurons,'neurons')\n",
    "\n",
    "all_data = np.array(dataset_50ms.data.spikes)\n",
    "print(all_data.shape)\n",
    "data_for_pca = all_data[~np.isnan(all_data).any(axis=1)]\n",
    "print(data_for_pca.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data_for_pca)\n",
    "pca = PCA(n_components=n_dims)\n",
    "X = pca.fit(X)\n",
    "\n",
    "PCA_data = nans([all_data.shape[0],n_dims])\n",
    "idx = 0\n",
    "for dp in all_data:\n",
    "    dp = dp.reshape((1, -1))\n",
    "    if np.isnan(dp).any():\n",
    "        dp_pca = nans([1,n_dims])\n",
    "    else:\n",
    "        dp_pca = pca.transform(scaler.transform(dp))\n",
    "    PCA_data[idx,:] = dp_pca\n",
    "    idx+=1\n",
    "print(PCA_data.shape)\n",
    "dataset_50ms.add_continuous_data(PCA_data,'PCA')\n",
    "print('PCA total var explained:',sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a348315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 time bins\n",
      "(245, 22, 153)\n",
      "(245, 22, 2)\n",
      "(245, 22, 2)\n",
      "(245, 22, 20)\n",
      "[6. 4. 5. 4. 0. 2. 0. 5. 4. 1. 6. 5. 6. 3. 7. 5. 2. 0. 0. 5. 0. 6. 4. 2.\n",
      " 2. 7. 0. 4. 4. 7. 5. 2. 6. 3. 2. 5. 5. 1. 1. 5. 5. 1. 6. 3. 7. 0. 4. 2.\n",
      " 1. 5. 1. 1. 1. 1. 1. 6. 2. 0. 5. 4. 7. 6. 3. 1. 5. 3. 0. 4. 6. 6. 0. 1.\n",
      " 3. 0. 6. 3. 1. 4. 3. 4. 5. 2. 2. 3. 3. 3. 4. 4. 2. 1. 2. 2. 4. 6. 1. 5.\n",
      " 0. 2. 0. 4. 6. 5. 6. 3. 0. 0. 6. 7. 2. 0. 0. 5. 7. 5. 1. 4. 2. 0. 0. 5.\n",
      " 4. 6. 3. 6. 3. 6. 3. 1. 7. 3. 3. 7. 5. 5. 3. 1. 5. 0. 7. 4. 7. 5. 5. 1.\n",
      " 6. 3. 3. 2. 1. 7. 5. 5. 0. 1. 6. 2. 7. 1. 0. 0. 3. 4. 1. 2. 0. 3. 0. 2.\n",
      " 5. 1. 3. 0. 7. 2. 3. 1. 2. 2. 0. 4. 2. 1. 3. 5. 5. 2. 1. 4. 1. 1. 6. 4.\n",
      " 1. 4. 7. 0. 2. 5. 6. 2. 1. 1. 5. 7. 1. 1. 2. 2. 5. 0. 6. 0. 0. 0. 3. 7.\n",
      " 7. 0. 7. 0. 3. 0. 7. 7. 5. 3. 0. 7. 3. 0. 6. 4. 3. 0. 0. 4. 3. 3. 6. 1.\n",
      " 0. 2. 0. 0. 3.]\n"
     ]
    }
   ],
   "source": [
    "active_data = dataset_50ms.make_trial_data(align_field='move_onset_time', align_range=(-400, 700), ignored_trials=~trial_mask)\n",
    "for idx, trial in active_data.groupby('trial_id'):\n",
    "    n_timepoints = trial.shape[0]\n",
    "    break\n",
    "print(n_timepoints,'time bins')\n",
    "\n",
    "active_trials_neuron = nans([n_trials,n_timepoints,n_neurons])\n",
    "active_trials_vel = nans([n_trials,n_timepoints,2])\n",
    "active_trials_acc = nans([n_trials,n_timepoints,2])\n",
    "active_trials_pca = nans([n_trials,n_timepoints,n_dims])\n",
    "i = 0\n",
    "for idx, trial in active_data.groupby('trial_id'):\n",
    "    active_trials_neuron[i,:,:]=trial.spikes.to_numpy()\n",
    "    active_trials_vel[i,:,:]=trial.hand_vel.to_numpy()\n",
    "    active_trials_acc[i,:,:]=trial.hand_acc.to_numpy()\n",
    "    active_trials_pca[i,:,:]=trial.PCA.to_numpy()\n",
    "    i+=1\n",
    "print(active_trials_neuron.shape)\n",
    "print(active_trials_vel.shape)\n",
    "print(active_trials_acc.shape)\n",
    "print(active_trials_pca.shape)\n",
    "\n",
    "#make dictionary for trial condition (reaching directions) for Stratified CV\n",
    "active_trials_idx = np.array(dataset_50ms.trial_info.loc[trial_mask]['trial_id'])\n",
    "cond_dir_idx = []\n",
    "cond_dict = nans([n_trials])\n",
    "for direction in [0,45,90,135,180,225,270,315]:\n",
    "    cond_dir_idx.append(np.where((dataset_50ms.trial_info['cond_dir'] == direction) & (dataset_50ms.trial_info['ctr_hold_bump'] == False) & \\\n",
    "           (dataset_50ms.trial_info['split'] != 'none'))[0])\n",
    "i = 0\n",
    "for idx in active_trials_idx:\n",
    "    for cond in range(0,len(cond_dir_idx)):\n",
    "        if idx in cond_dir_idx[cond]:\n",
    "            cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(cond_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a441427b",
   "metadata": {},
   "source": [
    "### with Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1ac91a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_range = [-400,700]\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/neurons/act/\"\n",
    "active_x = active_trials_neuron\n",
    "active_y = active_trials_acc\n",
    "y_type = 'acceleration'\n",
    "\n",
    "ranges = [(-100,500),(0,120),(-100,120)]\n",
    "labels = ['whole_acc','early_acc','long_acc']\n",
    "\n",
    "dim = n_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73bd712d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with 0 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.5145890864490528\n",
      "Predicting with 0 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.6327963509369792\n",
      "Predicting with 0 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.67911719800766\n",
      "Predicting with 0 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.7020884778770538\n",
      "Predicting with 0 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.7055130378453773\n",
      "Predicting with -50 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.6484463741843767\n",
      "Predicting with -50 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.7175345211020209\n",
      "Predicting with -50 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.7470871011387126\n",
      "Predicting with -50 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.7600613455762663\n",
      "Predicting with -50 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.7611620080754082\n",
      "Predicting with -100 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.6960876342971795\n",
      "Predicting with -100 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.7512553458047537\n",
      "Predicting with -100 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.7734026565864731\n",
      "Predicting with -100 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.7832676088575995\n",
      "Predicting with -100 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.7826468705315486\n",
      "Predicting with -150 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7191133244990263\n",
      "Predicting with -150 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.768524133420334\n",
      "Predicting with -150 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.7869187564616473\n",
      "Predicting with -150 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.7963683036921799\n",
      "Predicting with -150 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.7958923874439727\n",
      "Predicting with -200 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7285242141382509\n",
      "Predicting with -200 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.7769809883565363\n",
      "Predicting with -200 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.7957879042089917\n",
      "Predicting with -200 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8049384814860447\n",
      "Predicting with -200 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8045394245370688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/3p5f6szx247fkf6ftdgp147w0000gn/T/ipykernel_6520/2901737600.py:86: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "/var/folders/c_/3p5f6szx247fkf6ftdgp147w0000gn/T/ipykernel_6520/2901737600.py:118: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with 0 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.7213265993242554\n",
      "Predicting with 0 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.7716100364194546\n",
      "Predicting with 0 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.7969129036794693\n",
      "Predicting with 0 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8102856693595266\n",
      "Predicting with 0 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8201484615247602\n",
      "Predicting with 0 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8296951101698345\n",
      "Predicting with 0 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.832645379163077\n",
      "Predicting with 0 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8378029387481037\n",
      "Predicting with 0 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8409266219188153\n",
      "Predicting with 0 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8439431485270403\n",
      "Predicting with 0 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8426940784686194\n",
      "Predicting with -50 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.7683187129818618\n",
      "Predicting with -50 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.8157935241181382\n",
      "Predicting with -50 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8206683504583127\n",
      "Predicting with -50 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8396841352276461\n",
      "Predicting with -50 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.848383829393851\n",
      "Predicting with -50 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8582505693837015\n",
      "Predicting with -50 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.857802700585128\n",
      "Predicting with -50 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8604822310314321\n",
      "Predicting with -50 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8614289603175023\n",
      "Predicting with -50 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8629770390735462\n",
      "Predicting with -50 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8603932277463611\n",
      "Predicting with -100 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7753212518106473\n",
      "Predicting with -100 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8340158034490006\n",
      "Predicting with -100 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8407194618255344\n",
      "Predicting with -100 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.854072832751681\n",
      "Predicting with -100 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8617477909978708\n",
      "Predicting with -100 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8684166693907369\n",
      "Predicting with -100 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8659255857574595\n",
      "Predicting with -100 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8697863814618656\n",
      "Predicting with -100 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.869899968924774\n",
      "Predicting with -100 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8686036334209246\n",
      "Predicting with -100 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8671953052670719\n",
      "Predicting with -150 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7690341531046964\n",
      "Predicting with -150 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8293974987978481\n",
      "Predicting with -150 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8470843334418091\n",
      "Predicting with -150 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8602515397009657\n",
      "Predicting with -150 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8666347320379598\n",
      "Predicting with -150 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8710678601097372\n",
      "Predicting with -150 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.87001976101029\n",
      "Predicting with -150 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8727925461033984\n",
      "Predicting with -150 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8716601914014117\n",
      "Predicting with -150 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8709263585788238\n",
      "Predicting with -150 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8690553393816086\n",
      "Predicting with -200 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.75091994244983\n",
      "Predicting with -200 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.823022626926414\n",
      "Predicting with -200 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8418405280008343\n",
      "Predicting with -200 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8571069837842724\n",
      "Predicting with -200 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.86329943506067\n",
      "Predicting with -200 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8683791300992194\n",
      "Predicting with -200 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8665434770653504\n",
      "Predicting with -200 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8695826194812164\n",
      "Predicting with -200 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8694341339072108\n",
      "Predicting with -200 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8687363257882506\n",
      "Predicting with -200 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8674400933739573\n",
      "Predicting with -250 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7489677589030894\n",
      "Predicting with -250 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.815726477370544\n",
      "Predicting with -250 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8349035434905341\n",
      "Predicting with -250 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.851884768238197\n",
      "Predicting with -250 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8574326932144483\n",
      "Predicting with -250 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8619104424428199\n",
      "Predicting with -250 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8603308871659066\n",
      "Predicting with -250 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8632145710258727\n",
      "Predicting with -250 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8646980064581047\n",
      "Predicting with -250 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8648564622183019\n",
      "Predicting with -250 to 500 ms neural data\n",
      "100.0\n",
      "R2: 0.8633777823596567\n",
      "Predicting with -300 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7584939213440982\n",
      "Predicting with -300 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.819242553610569\n",
      "Predicting with -300 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.836942349634192\n",
      "Predicting with -300 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8514790806547476\n",
      "Predicting with -300 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8572978632192169\n",
      "Predicting with -300 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8611956827270392\n",
      "Predicting with -300 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8596534797896386\n",
      "Predicting with -300 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8638430673129209\n",
      "Predicting with -300 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8654982169773212\n",
      "Predicting with -300 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8650171810096972\n",
      "Predicting with -300 to 500 ms neural data\n",
      "100.0\n",
      "R2: 0.8632682582577587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/3p5f6szx247fkf6ftdgp147w0000gn/T/ipykernel_6520/2901737600.py:86: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with 0 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.634916809385799\n",
      "Predicting with 0 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.7385455882836808\n",
      "Predicting with 0 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.771011657510292\n",
      "Predicting with 0 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.7911035639114187\n",
      "Predicting with 0 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.801315822652757\n",
      "Predicting with 0 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8077214906590353\n",
      "Predicting with 0 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8065332137242224\n",
      "Predicting with 0 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8111170076132383\n",
      "Predicting with 0 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8112888926328612\n",
      "Predicting with 0 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8117366473672094\n",
      "Predicting with 0 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8113560759783573\n",
      "Predicting with -50 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.7242287869004848\n",
      "Predicting with -50 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.792674558153223\n",
      "Predicting with -50 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8094892378892304\n",
      "Predicting with -50 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8230899677820149\n",
      "Predicting with -50 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8299219416796157\n",
      "Predicting with -50 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8347049871308322\n",
      "Predicting with -50 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8325638933174291\n",
      "Predicting with -50 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8345799800357288\n",
      "Predicting with -50 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8345392278841495\n",
      "Predicting with -50 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8340479342007857\n",
      "Predicting with -50 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8327592764990268\n",
      "Predicting with -100 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7399910439000784\n",
      "Predicting with -100 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8048702557998197\n",
      "Predicting with -100 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8208170131938958\n",
      "Predicting with -100 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8333225928772372\n",
      "Predicting with -100 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.838493945171521\n",
      "Predicting with -100 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8424210887086412\n",
      "Predicting with -100 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.840098123334967\n",
      "Predicting with -100 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8416580161524163\n",
      "Predicting with -100 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8414780605975521\n",
      "Predicting with -100 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8410876649023141\n",
      "Predicting with -100 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8393569834034709\n",
      "Predicting with -150 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7328410598611905\n",
      "Predicting with -150 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.7996864706315809\n",
      "Predicting with -150 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.816401717924178\n",
      "Predicting with -150 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8304112031065335\n",
      "Predicting with -150 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8362635345579663\n",
      "Predicting with -150 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8402292756335049\n",
      "Predicting with -150 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8381432425427878\n",
      "Predicting with -150 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8399790377127604\n",
      "Predicting with -150 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8398347516888286\n",
      "Predicting with -150 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8394729093671371\n",
      "Predicting with -150 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8378465281005334\n",
      "Predicting with -200 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7207122711628791\n",
      "Predicting with -200 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.7916397462388015\n",
      "Predicting with -200 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8097194445589833\n",
      "Predicting with -200 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8248467536329185\n",
      "Predicting with -200 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.831337902151333\n",
      "Predicting with -200 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8358239885520014\n",
      "Predicting with -200 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8337692680506156\n",
      "Predicting with -200 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8359559168171055\n",
      "Predicting with -200 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8364276657125778\n",
      "Predicting with -200 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8362612868715669\n",
      "Predicting with -200 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8347519805644033\n",
      "Predicting with -250 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7131459779219085\n",
      "Predicting with -250 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.785653110843798\n",
      "Predicting with -250 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8049266880980963\n",
      "Predicting with -250 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8198857875324084\n",
      "Predicting with -250 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8270230834557695\n",
      "Predicting with -250 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8313504989159959\n",
      "Predicting with -250 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.828993794038589\n",
      "Predicting with -250 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8312653239655232\n",
      "Predicting with -250 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8318825052615237\n",
      "Predicting with -250 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8284737084367857\n",
      "Predicting with -250 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8273429870243869\n",
      "Predicting with -300 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7082129135253634\n",
      "Predicting with -300 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.7805045017489758\n",
      "Predicting with -300 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8011341571764282\n",
      "Predicting with -300 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8167779759596243\n",
      "Predicting with -300 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8244433605175403\n",
      "Predicting with -300 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8290017110007789\n",
      "Predicting with -300 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8272026536243227\n",
      "Predicting with -300 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.825496369294225\n",
      "Predicting with -300 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8244652109438098\n",
      "Predicting with -300 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8218821993002419\n",
      "Predicting with -300 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8217798190470117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/3p5f6szx247fkf6ftdgp147w0000gn/T/ipykernel_6520/2901737600.py:86: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "for pred_range, label in zip(ranges, labels):\n",
    "\n",
    "    idx1 = int((pred_range[0] - data_range[0])/dataset_50ms.bin_width)\n",
    "    idx2 = int(n_timepoints - (data_range[1]-pred_range[1])/dataset_50ms.bin_width)\n",
    "    \n",
    "    if pred_range == (-100,500):\n",
    "        t_before_range = range(0,201,50);\n",
    "        t_after_range = range(0,201,50);        \n",
    "    else:        \n",
    "        t_before_range = range(0,301,50);\n",
    "        t_after_range = range(0,501,50);\n",
    "\n",
    "    multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "    multi_coefs = []\n",
    "    j,k=0,0\n",
    "    for time_before in t_before_range:\n",
    "        coef_arr = []\n",
    "        for time_after in t_after_range:\n",
    "            print('Predicting with',-time_before, 'to', time_after,'ms neural data')\n",
    "\n",
    "            bins_before= int(time_before/dataset_50ms.bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "            bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "            bins_after= int(time_after/dataset_50ms.bin_width) #How many bins of neural data after the output are used for decoding\n",
    "\n",
    "            n_total_bins = bins_before + bins_current + bins_after\n",
    "\n",
    "            X =  nans([n_trials,idx2-idx1,n_total_bins*dim])\n",
    "            i = 0\n",
    "            for trial_data in active_x:\n",
    "                trial_hist=get_spikes_with_history(trial_data,bins_before,bins_after,bins_current)\n",
    "                trial_hist = trial_hist[idx1:idx2,:,:]\n",
    "                trial_hist_flat=trial_hist.reshape(trial_hist.shape[0],(trial_hist.shape[1]*trial_hist.shape[2]))\n",
    "                X[i,:,:] = trial_hist_flat\n",
    "                i+=1\n",
    "            y = active_y[:,idx1:idx2,:]\n",
    "\n",
    "            lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)})\n",
    "            X_reshaped = X.reshape((X.shape[0]*X.shape[1]),X.shape[2])\n",
    "            y_reshaped = y.reshape((y.shape[0]*y.shape[1]),y.shape[2])\n",
    "            lr_all.fit(X_reshaped, y_reshaped)\n",
    "            print(lr_all.best_params_['alpha'])\n",
    "\n",
    "            skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "            true_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "            pred_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "            trial_save_idx = 0\n",
    "            for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "                #split training and testing by trials\n",
    "                X_train, X_test, y_train, y_test = process_train_test(X,y,training_set,test_set)\n",
    "                lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)}) \n",
    "                lr.fit(X_train, y_train)\n",
    "                y_test_predicted = lr.predict(X_test)\n",
    "                n = y_test_predicted.shape[0]\n",
    "                true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "                pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "                trial_save_idx += n\n",
    "\n",
    "            sses =get_sses_pred(true_concat,pred_concat)\n",
    "            sses_mean=get_sses_mean(true_concat)\n",
    "            multi_R2s[j,k] =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "            print('R2:',multi_R2s[j,k])\n",
    "            coef_arr.append(lr_all.best_estimator_.coef_)\n",
    "            k += 1\n",
    "        j += 1\n",
    "        k = 0\n",
    "        multi_coefs.append(coef_arr)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(multi_R2s)\n",
    "    ax.set_xlabel('Length of lagging info')\n",
    "    ax.set_ylabel('Length of leading info')\n",
    "\n",
    "    ax.set_xticks(np.arange(len(t_after_range)))\n",
    "    ax.set_yticks(np.arange(len(t_before_range)))\n",
    "    ax.set_xticklabels(labels=t_after_range)\n",
    "    ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "    ax.set_title('R2 predicting ' + str(pred_range) + ' ' + y_type +'\\nwith different lagging/leading info')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for i in range(len(t_before_range)):\n",
    "        for j in range(len(t_after_range)):\n",
    "            text = ax.text(j, i, str(int(multi_R2s[i, j]*1000)/1000),\n",
    "                           ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + '_multi_' + label + '.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "    \n",
    "    if pred_range == (-100,500):\n",
    "        coef_X = multi_coefs[-1][-1][0] #which entry's weights to use\n",
    "\n",
    "        t_label = np.arange(-200,201,50)\n",
    "\n",
    "        n_weights = len(t_before_range) + len(t_after_range) - 1\n",
    "        coef_X_reshaped = coef_X.reshape(n_weights,n_neurons)\n",
    "        angDist_array = nans([n_weights,n_weights])\n",
    "        for i in range(n_weights):\n",
    "            for j in range(n_weights):\n",
    "                angDist_array[i,j] = math.degrees(angle_between(coef_X_reshaped[i,:],coef_X_reshaped[j,:]))\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        im = ax.imshow(angDist_array)\n",
    "        ax.set_xlabel('Bin time (ms)')\n",
    "        ax.set_ylabel('Bin time (ms)')\n",
    "\n",
    "        ax.set_xticks(np.arange(len(t_label)))\n",
    "        ax.set_yticks(np.arange(len(t_label)))\n",
    "        ax.set_xticklabels(labels=t_label)\n",
    "        ax.set_yticklabels(labels=t_label)\n",
    "\n",
    "        ax.set_title(\"Angle between weight vectors at time points\")\n",
    "        fig.tight_layout()\n",
    "\n",
    "        for i in range(len(t_label)):\n",
    "            for j in range(len(t_label)):\n",
    "                text = ax.text(j, i, str(int(angDist_array[i, j])),\n",
    "                               ha=\"center\", va=\"center\", color=\"w\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figDir + monkey + '_multi_' + label + '_deg.png', dpi = 'figure')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e187da",
   "metadata": {},
   "source": [
    "### with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1b29958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_range = [-400,700]\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/PCA/act/\"\n",
    "active_x = active_trials_pca\n",
    "active_y = active_trials_acc\n",
    "y_type = 'acceleration'\n",
    "\n",
    "ranges = [(-100,500),(0,120),(-100,120)]\n",
    "labels = ['whole_acc','early_acc','long_acc']\n",
    "\n",
    "dim = n_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcff8207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with 0 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.3958884482843952\n",
      "Predicting with 0 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.5365462117942983\n",
      "Predicting with 0 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.5988363256587734\n",
      "Predicting with 0 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.6190140261692847\n",
      "Predicting with 0 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.6248824331427091\n",
      "Predicting with -50 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.5274648284881696\n",
      "Predicting with -50 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.6345473452486661\n",
      "Predicting with -50 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.6826223033738286\n",
      "Predicting with -50 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.6969004749488928\n",
      "Predicting with -50 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.7002040415713553\n",
      "Predicting with -100 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.5822558844353678\n",
      "Predicting with -100 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.6793911565006001\n",
      "Predicting with -100 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.7175055294300794\n",
      "Predicting with -100 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.7297660119465703\n",
      "Predicting with -100 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.7334087669079279\n",
      "Predicting with -150 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.6214459805053157\n",
      "Predicting with -150 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.70497802142652\n",
      "Predicting with -150 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.7385814190460418\n",
      "Predicting with -150 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.7505993864745166\n",
      "Predicting with -150 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.7537367081529092\n",
      "Predicting with -200 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.6339563757451487\n",
      "Predicting with -200 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.7150129737786453\n",
      "Predicting with -200 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.747758711946547\n",
      "Predicting with -200 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.7598013546339659\n",
      "Predicting with -200 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.7636462918224411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/3p5f6szx247fkf6ftdgp147w0000gn/T/ipykernel_6520/2187432194.py:86: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n",
      "/var/folders/c_/3p5f6szx247fkf6ftdgp147w0000gn/T/ipykernel_6520/2187432194.py:118: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with 0 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.6668253096118432\n",
      "Predicting with 0 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.7651836876885119\n",
      "Predicting with 0 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.8006094581241301\n",
      "Predicting with 0 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.8199979963601481\n",
      "Predicting with 0 to 200 ms neural data\n",
      "100.0\n",
      "R2: 0.8271620117814726\n",
      "Predicting with 0 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8273195508662501\n",
      "Predicting with 0 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8241979391434583\n",
      "Predicting with 0 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8219335979604836\n",
      "Predicting with 0 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8250704338085685\n",
      "Predicting with 0 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8241634767947358\n",
      "Predicting with 0 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8243250127338069\n",
      "Predicting with -50 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.7490391785826123\n",
      "Predicting with -50 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.8218249590095474\n",
      "Predicting with -50 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.83771130299429\n",
      "Predicting with -50 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.8501905464963686\n",
      "Predicting with -50 to 200 ms neural data\n",
      "100.0\n",
      "R2: 0.8493504177822173\n",
      "Predicting with -50 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8502377509712382\n",
      "Predicting with -50 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8487655340159334\n",
      "Predicting with -50 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8480305270903313\n",
      "Predicting with -50 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8475052147251306\n",
      "Predicting with -50 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8471430004817123\n",
      "Predicting with -50 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8455138906166557\n",
      "Predicting with -100 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.7749614053715562\n",
      "Predicting with -100 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.8403999566000022\n",
      "Predicting with -100 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.8537968487960769\n",
      "Predicting with -100 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.8649342734899471\n",
      "Predicting with -100 to 200 ms neural data\n",
      "100.0\n",
      "R2: 0.8648306993822533\n",
      "Predicting with -100 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8648174408734406\n",
      "Predicting with -100 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8633937747474904\n",
      "Predicting with -100 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8632092767834245\n",
      "Predicting with -100 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.862901812787991\n",
      "Predicting with -100 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8614546269279713\n",
      "Predicting with -100 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8590967709630057\n",
      "Predicting with -150 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.7723945015015258\n",
      "Predicting with -150 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.8398364297009492\n",
      "Predicting with -150 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.8542495091452995\n",
      "Predicting with -150 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.8652014792032512\n",
      "Predicting with -150 to 200 ms neural data\n",
      "100.0\n",
      "R2: 0.8659114057722224\n",
      "Predicting with -150 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8670901104292088\n",
      "Predicting with -150 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8661971481253241\n",
      "Predicting with -150 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8662025550055755\n",
      "Predicting with -150 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8658416870206552\n",
      "Predicting with -150 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8651463231343438\n",
      "Predicting with -150 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8631538424938262\n",
      "Predicting with -200 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.7617160438442739\n",
      "Predicting with -200 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.8330475858875899\n",
      "Predicting with -200 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.8495676206335041\n",
      "Predicting with -200 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8599548252643224\n",
      "Predicting with -200 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8619079848457378\n",
      "Predicting with -200 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8627273465662569\n",
      "Predicting with -200 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8622278266365719\n",
      "Predicting with -200 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8628293097656193\n",
      "Predicting with -200 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8625681883236417\n",
      "Predicting with -200 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8610481608053118\n",
      "Predicting with -200 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8598221538500104\n",
      "Predicting with -250 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.7490607272375192\n",
      "Predicting with -250 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.8256776673026653\n",
      "Predicting with -250 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.8405385628872923\n",
      "Predicting with -250 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8516619093472662\n",
      "Predicting with -250 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8544009299118003\n",
      "Predicting with -250 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8553351720249318\n",
      "Predicting with -250 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8549561280126671\n",
      "Predicting with -250 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8555742542014699\n",
      "Predicting with -250 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8539273623482737\n",
      "Predicting with -250 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8531718685366001\n",
      "Predicting with -250 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8524730064414652\n",
      "Predicting with -300 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.734095658658529\n",
      "Predicting with -300 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.8161566796920949\n",
      "Predicting with -300 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.8337019872596014\n",
      "Predicting with -300 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8459406774728908\n",
      "Predicting with -300 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8492238104234926\n",
      "Predicting with -300 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8495946481903291\n",
      "Predicting with -300 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8488352091482481\n",
      "Predicting with -300 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8503296725254401\n",
      "Predicting with -300 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8492766964112548\n",
      "Predicting with -300 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8490971425817245\n",
      "Predicting with -300 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.84702525689713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/3p5f6szx247fkf6ftdgp147w0000gn/T/ipykernel_6520/2187432194.py:86: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with 0 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.5384370177098068\n",
      "Predicting with 0 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.6978155929156001\n",
      "Predicting with 0 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.7447969162204449\n",
      "Predicting with 0 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.7660487542240194\n",
      "Predicting with 0 to 200 ms neural data\n",
      "100.0\n",
      "R2: 0.7743840807322036\n",
      "Predicting with 0 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.7796836721055256\n",
      "Predicting with 0 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.7792971229182712\n",
      "Predicting with 0 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.7779999320172319\n",
      "Predicting with 0 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.7787239332572395\n",
      "Predicting with 0 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.7757627440307958\n",
      "Predicting with 0 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.7735717006819911\n",
      "Predicting with -50 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.6556795555973476\n",
      "Predicting with -50 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.76027197682565\n",
      "Predicting with -50 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.7882696869817984\n",
      "Predicting with -50 to 150 ms neural data\n",
      "100.0\n",
      "R2: 0.8025827524043931\n",
      "Predicting with -50 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8065027693358418\n",
      "Predicting with -50 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8122511182421968\n",
      "Predicting with -50 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8106180454454595\n",
      "Predicting with -50 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8093024091831886\n",
      "Predicting with -50 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8091496278961113\n",
      "Predicting with -50 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8078287807971202\n",
      "Predicting with -50 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8057738754541051\n",
      "Predicting with -100 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.6802962876724119\n",
      "Predicting with -100 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.7784686053756141\n",
      "Predicting with -100 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.8016123217719431\n",
      "Predicting with -100 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.813845967100865\n",
      "Predicting with -100 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8177920753935357\n",
      "Predicting with -100 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8223457062332846\n",
      "Predicting with -100 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8204522898170489\n",
      "Predicting with -100 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.818414432244307\n",
      "Predicting with -100 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8184323247266498\n",
      "Predicting with -100 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8165217728550928\n",
      "Predicting with -100 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8141720947322535\n",
      "Predicting with -150 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.6776047004084396\n",
      "Predicting with -150 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.7778592929916412\n",
      "Predicting with -150 to 100 ms neural data\n",
      "100.0\n",
      "R2: 0.8019150060162598\n",
      "Predicting with -150 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8153329797185944\n",
      "Predicting with -150 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.819470798599748\n",
      "Predicting with -150 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8245485517182661\n",
      "Predicting with -150 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8225093189092705\n",
      "Predicting with -150 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8207448229595996\n",
      "Predicting with -150 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8204852421109334\n",
      "Predicting with -150 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8180743749861559\n",
      "Predicting with -150 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8157298575329408\n",
      "Predicting with -200 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.6711926045330332\n",
      "Predicting with -200 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.775559837986397\n",
      "Predicting with -200 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.7994684961250753\n",
      "Predicting with -200 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8134777379230582\n",
      "Predicting with -200 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8183510014010833\n",
      "Predicting with -200 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8226613264028098\n",
      "Predicting with -200 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8216815970200586\n",
      "Predicting with -200 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.820554539695464\n",
      "Predicting with -200 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8204297709966404\n",
      "Predicting with -200 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8178573973355019\n",
      "Predicting with -200 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.815348420628093\n",
      "Predicting with -250 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.6640088790786387\n",
      "Predicting with -250 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.7698251898584908\n",
      "Predicting with -250 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.7942167611535192\n",
      "Predicting with -250 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8090474635047785\n",
      "Predicting with -250 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8140555582917608\n",
      "Predicting with -250 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8180141686295732\n",
      "Predicting with -250 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8160860383844799\n",
      "Predicting with -250 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8152855778564697\n",
      "Predicting with -250 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8148547321024238\n",
      "Predicting with -250 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8123704257109922\n",
      "Predicting with -250 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8145183329086869\n",
      "Predicting with -300 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.651429064097748\n",
      "Predicting with -300 to 50 ms neural data\n",
      "100.0\n",
      "R2: 0.7607524109107722\n",
      "Predicting with -300 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.7876254077007899\n",
      "Predicting with -300 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8027714559181718\n",
      "Predicting with -300 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8075564904644866\n",
      "Predicting with -300 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8110864442721657\n",
      "Predicting with -300 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8095825565647043\n",
      "Predicting with -300 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8088759201555868\n",
      "Predicting with -300 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8086735607718878\n",
      "Predicting with -300 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8067276164022222\n",
      "Predicting with -300 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8097944885102998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/3p5f6szx247fkf6ftdgp147w0000gn/T/ipykernel_6520/2187432194.py:86: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "for pred_range, label in zip(ranges, labels):\n",
    "\n",
    "    idx1 = int((pred_range[0] - data_range[0])/dataset_50ms.bin_width)\n",
    "    idx2 = int(n_timepoints - (data_range[1]-pred_range[1])/dataset_50ms.bin_width)\n",
    "\n",
    "    if pred_range == (-100,500):\n",
    "        t_before_range = range(0,201,50);\n",
    "        t_after_range = range(0,201,50);        \n",
    "    else:        \n",
    "        t_before_range = range(0,301,50);\n",
    "        t_after_range = range(0,501,50);\n",
    "\n",
    "    multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "    multi_coefs = []\n",
    "    j,k=0,0\n",
    "    for time_before in t_before_range:\n",
    "        coef_arr = []\n",
    "        for time_after in t_after_range:\n",
    "            print('Predicting with',-time_before, 'to', time_after,'ms neural data')\n",
    "\n",
    "            bins_before= int(time_before/dataset_50ms.bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "            bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "            bins_after= int(time_after/dataset_50ms.bin_width) #How many bins of neural data after the output are used for decoding\n",
    "\n",
    "            n_total_bins = bins_before + bins_current + bins_after\n",
    "\n",
    "            X =  nans([n_trials,idx2-idx1,n_total_bins*dim])\n",
    "            i = 0\n",
    "            for trial_data in active_x:\n",
    "                trial_hist=get_spikes_with_history(trial_data,bins_before,bins_after,bins_current)\n",
    "                trial_hist = trial_hist[idx1:idx2,:,:]\n",
    "                trial_hist_flat=trial_hist.reshape(trial_hist.shape[0],(trial_hist.shape[1]*trial_hist.shape[2]))\n",
    "                X[i,:,:] = trial_hist_flat\n",
    "                i+=1\n",
    "            y = active_y[:,idx1:idx2,:]\n",
    "\n",
    "            lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)})\n",
    "            X_reshaped = X.reshape((X.shape[0]*X.shape[1]),X.shape[2])\n",
    "            y_reshaped = y.reshape((y.shape[0]*y.shape[1]),y.shape[2])\n",
    "            lr_all.fit(X_reshaped, y_reshaped)\n",
    "            print(lr_all.best_params_['alpha'])\n",
    "\n",
    "            skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "            true_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "            pred_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "            trial_save_idx = 0\n",
    "            for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "                #split training and testing by trials\n",
    "                X_train, X_test, y_train, y_test = process_train_test(X,y,training_set,test_set)\n",
    "                lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)}) \n",
    "                lr.fit(X_train, y_train)\n",
    "                y_test_predicted = lr.predict(X_test)\n",
    "                n = y_test_predicted.shape[0]\n",
    "                true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "                pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "                trial_save_idx += n\n",
    "\n",
    "            sses =get_sses_pred(true_concat,pred_concat)\n",
    "            sses_mean=get_sses_mean(true_concat)\n",
    "            multi_R2s[j,k] =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "            print('R2:',multi_R2s[j,k])\n",
    "            coef_arr.append(lr_all.best_estimator_.coef_)\n",
    "            k += 1\n",
    "        j += 1\n",
    "        k = 0\n",
    "        multi_coefs.append(coef_arr)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(multi_R2s)\n",
    "    ax.set_xlabel('Length of lagging info')\n",
    "    ax.set_ylabel('Length of leading info')\n",
    "\n",
    "    ax.set_xticks(np.arange(len(t_after_range)))\n",
    "    ax.set_yticks(np.arange(len(t_before_range)))\n",
    "    ax.set_xticklabels(labels=t_after_range)\n",
    "    ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "    ax.set_title('R2 predicting ' + str(pred_range) + ' ' + y_type +'\\nwith different lagging/leading info')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for i in range(len(t_before_range)):\n",
    "        for j in range(len(t_after_range)):\n",
    "            text = ax.text(j, i, str(int(multi_R2s[i, j]*1000)/1000),\n",
    "                           ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + '_multi_' + label + '.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "    \n",
    "    if pred_range == (-100,500):\n",
    "        coef_X = multi_coefs[-1][-1][0] #which entry's weights to use\n",
    "\n",
    "        t_label = np.arange(-200,201,50)\n",
    "\n",
    "        n_weights = len(t_before_range) + len(t_after_range) - 1\n",
    "        coef_X_reshaped = coef_X.reshape(n_weights,dim)\n",
    "        angDist_array = nans([n_weights,n_weights])\n",
    "        for i in range(n_weights):\n",
    "            for j in range(n_weights):\n",
    "                angDist_array[i,j] = math.degrees(angle_between(coef_X_reshaped[i,:],coef_X_reshaped[j,:]))\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        im = ax.imshow(angDist_array)\n",
    "        ax.set_xlabel('Bin time (ms)')\n",
    "        ax.set_ylabel('Bin time (ms)')\n",
    "\n",
    "        ax.set_xticks(np.arange(len(t_label)))\n",
    "        ax.set_yticks(np.arange(len(t_label)))\n",
    "        ax.set_xticklabels(labels=t_label)\n",
    "        ax.set_yticklabels(labels=t_label)\n",
    "\n",
    "        ax.set_title(\"Angle between weight vectors at time points\")\n",
    "        fig.tight_layout()\n",
    "\n",
    "        for i in range(len(t_label)):\n",
    "            for j in range(len(t_label)):\n",
    "                text = ax.text(j, i, str(int(angDist_array[i, j])),\n",
    "                               ha=\"center\", va=\"center\", color=\"w\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figDir + monkey + '_multi_' + label + '_deg.png', dpi = 'figure')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f22933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5384f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
