{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlb_tools.nwb_interface import NWBDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "\n",
    "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966 (90 deg)\n",
    "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0 (0 deg)\n",
    "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793 (180 deg)\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "\n",
    "#Import standard packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import io\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "# If you would prefer to load the '.h5' example file rather than the '.pickle' example file. You need the deepdish package\n",
    "# import deepdish as dd \n",
    "\n",
    "#Import function to get the covariate matrix that includes spike history from previous bins\n",
    "from Neural_Decoding.preprocessing_funcs import get_spikes_with_history\n",
    "\n",
    "#Import metrics\n",
    "from Neural_Decoding.metrics import get_R2\n",
    "from Neural_Decoding.metrics import get_rho\n",
    "\n",
    "#Import decoder functions\n",
    "from Neural_Decoding.decoders import WienerCascadeDecoder\n",
    "from Neural_Decoding.decoders import WienerFilterDecoder\n",
    "from Neural_Decoding.decoders import DenseNNDecoder\n",
    "from Neural_Decoding.decoders import SimpleRNNDecoder\n",
    "from Neural_Decoding.decoders import GRUDecoder\n",
    "from Neural_Decoding.decoders import LSTMDecoder\n",
    "from Neural_Decoding.decoders import XGBoostDecoder\n",
    "from Neural_Decoding.decoders import SVRDecoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def get_sses_pred(y_test,y_test_pred):\n",
    "    sse=np.sum((y_test_pred-y_test)**2,axis=0)\n",
    "    return sse\n",
    "\n",
    "def get_sses_mean(y_test):\n",
    "    y_mean=np.mean(y_test,axis=0)\n",
    "    sse_mean=np.sum((y_test-y_mean)**2,axis=0)\n",
    "    return sse_mean\n",
    "\n",
    "def nans(shape, dtype=float):\n",
    "    a = np.empty(shape, dtype)\n",
    "    a.fill(np.nan)\n",
    "    return a\n",
    "\n",
    "def vector_reject(u,v):\n",
    "    #project u on v, subtract u1 from u\n",
    "    P = np.outer(v,(v.T))/(v@(v.T))\n",
    "    u_sub = u - P@u\n",
    "#     another calculation, to double-check\n",
    "#     v_norm = np.sqrt(sum(v**2))    \n",
    "#     proj_u_on_v = (np.dot(u, v)/v_norm**2)*v\n",
    "#     u_sub = u - proj_u_on_v\n",
    "    return u_sub\n",
    "\n",
    "def calc_proj_matrix(A):\n",
    "    return A@np.linalg.inv(A.T@A)@A.T\n",
    "def calc_proj(b, A):\n",
    "    P = calc_proj_matrix(A)\n",
    "    return P@b.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dca024",
   "metadata": {},
   "source": [
    "# Single Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc8cc31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "foldername = \"~/area2_population_analysis/s1-kinematics/actpas_NWB/\"\n",
    "monkey = \"Han_20171207\"\n",
    "filename = foldername + monkey + \"_COactpas_TD.nwb\"\n",
    "\n",
    "dataset_5ms = NWBDataset(filename, split_heldout=False)\n",
    "dataset_5ms.resample(5)\n",
    "dataset_5ms.smooth_spk(40, name='smth_40')\n",
    "# dataset_5ms.smooth_spk(20, name='smth_20')\n",
    "bin_width = dataset_5ms.bin_width\n",
    "print(bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8cd4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = np.sqrt(np.sum(dataset_5ms.data['hand_vel'][:].T**2,axis=0)).to_numpy().reshape((-1,1))\n",
    "dataset_5ms.add_continuous_data(speed,'speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b3102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dims = 20 # for PCA\n",
    "\n",
    "active_mask = (~dataset_5ms.trial_info.ctr_hold_bump) & (dataset_5ms.trial_info.split != 'none')\n",
    "passive_mask = (dataset_5ms.trial_info.ctr_hold_bump) & (dataset_5ms.trial_info.split != 'none')\n",
    "\n",
    "\n",
    "trial_mask = active_mask\n",
    "n_trials = dataset_5ms.trial_info.loc[trial_mask].shape[0]\n",
    "print(n_trials,'trials')\n",
    "n_neurons = dataset_5ms.data.spikes.shape[1]\n",
    "print(n_neurons,'neurons')\n",
    "\n",
    "all_data = np.array(dataset_5ms.data.spikes_smth_40)\n",
    "print(all_data.shape)\n",
    "data_for_pca = all_data[~np.isnan(all_data).any(axis=1)]\n",
    "print(data_for_pca.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data_for_pca)\n",
    "pca = PCA(n_components=n_dims)\n",
    "X = pca.fit(X)\n",
    "\n",
    "PCA_data = nans([all_data.shape[0],n_dims])\n",
    "idx = 0\n",
    "for dp in all_data:\n",
    "    dp = dp.reshape((1, -1))\n",
    "    if np.isnan(dp).any():\n",
    "        dp_pca = nans([1,n_dims])\n",
    "    else:\n",
    "        dp_pca = pca.transform(scaler.transform(dp))\n",
    "    PCA_data[idx,:] = dp_pca\n",
    "    idx+=1\n",
    "print(PCA_data.shape)\n",
    "dataset_5ms.add_continuous_data(PCA_data,'PCA')\n",
    "print('PCA total var explained:',sum(pca.explained_variance_ratio_))\n",
    "\n",
    "#make dictionary for trial condition (reaching directions) for Stratified CV\n",
    "active_trials_idx = np.array(dataset_5ms.trial_info.loc[trial_mask]['trial_id'])\n",
    "cond_dir_idx = []\n",
    "cond_dict = nans([n_trials])\n",
    "for direction in [0,45,90,135,180,225,270,315]:\n",
    "    cond_dir_idx.append(np.where((dataset_5ms.trial_info['cond_dir'] == direction) & (dataset_5ms.trial_info['ctr_hold_bump'] == False) & \\\n",
    "           (dataset_5ms.trial_info['split'] != 'none'))[0])\n",
    "i = 0\n",
    "for idx in active_trials_idx:\n",
    "    for cond in range(0,len(cond_dir_idx)):\n",
    "        if idx in cond_dir_idx[cond]:\n",
    "            cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(cond_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf18adf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare for PCA plotting\n",
    "\n",
    "# active_data = dataset_5ms.make_trial_data(align_field='move_onset_time', align_range=(-100, 500), ignored_trials=~trial_mask)\n",
    "# active_trials_pca = nans([n_trials,n_timepoints,n_dims])\n",
    "# i = 0\n",
    "# for idx, trial in active_data.groupby('trial_id'):\n",
    "#     active_trials_pca[i,:,:]=trial.PCA.to_numpy()\n",
    "#     i+=1\n",
    "# print(active_trials_pca.shape)\n",
    "\n",
    "# plot_dir = np.array([0,45,90,135,180,225,270,315]) # limit plot directions to reduce cluttering\n",
    "# directions = np.array([0,45,90,135,180,225,270,315])\n",
    "# pred_range = (-100, 500)\n",
    "# x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "\n",
    "# # define some useful time points\n",
    "# move_idx=0\n",
    "# ret_idx = 200\n",
    "\n",
    "# import matplotlib as mpl\n",
    "# cmap = plt.get_cmap('coolwarm',len(plot_dir))\n",
    "# custom_palette = [mpl.colors.rgb2hex(cmap(i)) for i in range(len(plot_dir))]\n",
    "\n",
    "# plot_dims = 10\n",
    "\n",
    "# fig,ax=plt.subplots(plot_dims,1,figsize=(10,20))\n",
    "# for i in range(plot_dims):\n",
    "#     for j in range(len(plot_dir)):\n",
    "#         color = custom_palette[j]\n",
    "#         dir_idx = np.argwhere(directions == plot_dir[j])[0]\n",
    "#         cond_mean_proj = np.mean(active_trials_pca[np.argwhere(cond_dict==dir_idx).flatten(),:,:], axis = 0)[:,i] \n",
    "#         pca_mean = np.mean(active_data.PCA.to_numpy(),axis = 0)[i]\n",
    "#         ax[i].plot(x_axis,cond_mean_proj - pca_mean,linewidth=2.25,color = color,label = plot_dir[j])\n",
    "        \n",
    "#         ax[i].axvline(move_idx, color='k',linewidth = .5)\n",
    "#         ax[i].axvline(ret_idx, color='k',linewidth = .5)\n",
    "# #         ax[i].set_xlim([0,T])\n",
    "#         ax[i].set_ylim([-6, 6])\n",
    "#         ax[i].axhline(0,color ='k',ls = '--')\n",
    "#         if i<plot_dims-1:\n",
    "#             ax[i].set_xticks([])\n",
    "#         else:\n",
    "#             ax[i].set_xlabel('Time (ms)')\n",
    "            \n",
    "#         ax[i].set_yticks([])\n",
    "#         ax[i].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "#     ax[0].set_title('PCA Projections')\n",
    "    \n",
    "# plt.legend(bbox_to_anchor = (1, 1), loc = 'upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb1fa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_test(X,y,training_set,test_set):\n",
    "    X_train = X[training_set,:,:]\n",
    "    X_test = X[test_set,:,:]\n",
    "    y_train = y[training_set,:,:]\n",
    "    y_test = y[test_set,:,:]\n",
    "\n",
    "    #flat by trials\n",
    "    X_flat_train = X_train.reshape((X_train.shape[0]*X_train.shape[1]),X_train.shape[2])\n",
    "    X_flat_test = X_test.reshape((X_test.shape[0]*X_test.shape[1]),X_test.shape[2])\n",
    "    y_train=y_train.reshape((y_train.shape[0]*y_train.shape[1]),y_train.shape[2])\n",
    "    y_test=y_test.reshape((y_test.shape[0]*y_test.shape[1]),y_test.shape[2])\n",
    "    \n",
    "    X_flat_train_mean=np.nanmean(X_flat_train,axis=0)\n",
    "    X_flat_train_std=np.nanstd(X_flat_train,axis=0)   \n",
    "    #array with only 0 will have 0 std and cause errors\n",
    "    X_flat_train_std[X_flat_train_std==0] = 1\n",
    "    \n",
    "    X_flat_train=(X_flat_train-X_flat_train_mean)/X_flat_train_std\n",
    "    X_flat_test=(X_flat_test-X_flat_train_mean)/X_flat_train_std\n",
    "    y_train_mean=np.mean(y_train,axis=0)\n",
    "    y_train=y_train-y_train_mean\n",
    "    y_test=y_test-y_train_mean    \n",
    "    \n",
    "    return X_flat_train,X_flat_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f0762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(dataset, trial_mask, align_field, align_range, lag, x_field, y_field):\n",
    "    \"\"\"Extracts spiking and kinematic data from selected trials and fits linear decoder\"\"\"\n",
    "    # Extract rate data from selected trials\n",
    "    vel_df = dataset.make_trial_data(align_field=align_field, align_range=align_range, ignored_trials=~trial_mask)\n",
    "    # Lag alignment for kinematics and extract kinematics data from selected trials\n",
    "    lag_align_range = (align_range[0] + lag, align_range[1] + lag)\n",
    "    rates_df = dataset.make_trial_data(align_field=align_field, align_range=lag_align_range, ignored_trials=~trial_mask)\n",
    "    \n",
    "    n_trials = rates_df['trial_id'].nunique()\n",
    "    n_timepoints = int((align_range[1] - align_range[0])/dataset.bin_width)\n",
    "    n_neurons = rates_df[x_field].shape[1]\n",
    "    \n",
    "    lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)})\n",
    "    rates_array = rates_df[x_field].to_numpy()\n",
    "    vel_array = vel_df[y_field].to_numpy()\n",
    "    lr_all.fit(rates_array, vel_array)\n",
    "    pred_vel = lr_all.predict(rates_array)\n",
    "    vel_df = pd.concat([vel_df, pd.DataFrame(pred_vel, columns=dataset._make_midx('pred_vel', ['x', 'y'], 2))], axis=1)\n",
    "#     print(lr_all.best_params_['alpha'])\n",
    "    \n",
    "    rates_array = rates_array.reshape(n_trials, n_timepoints, n_neurons)\n",
    "    vel_array = vel_array.reshape(n_trials, n_timepoints, 2)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "    true_concat = nans([n_trials*n_timepoints,2])\n",
    "    pred_concat = nans([n_trials*n_timepoints,2])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test, y_train, y_test = process_train_test(rates_array,vel_array,training_set,test_set)\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)}) \n",
    "        lr.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "        \n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "        trial_save_idx += n\n",
    "    \n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    print('R2:',R2) \n",
    "    return R2, lr_all.best_estimator_.coef_, vel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0e7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_and_predict(dataset, trial_mask, align_field, align_range, lag, x_field, y_field, weights):\n",
    "    \"\"\"Extracts spiking and kinematic data from selected trials and fits linear decoder\"\"\"\n",
    "    # Extract rate data from selected trials\n",
    "    vel_df = dataset.make_trial_data(align_field=align_field, align_range=align_range, ignored_trials=~trial_mask)\n",
    "    # Lag alignment for kinematics and extract kinematics data from selected trials\n",
    "    lag_align_range = (align_range[0] + lag, align_range[1] + lag)\n",
    "    rates_df = dataset.make_trial_data(align_field=align_field, align_range=lag_align_range, ignored_trials=~trial_mask)\n",
    "    \n",
    "    n_trials = rates_df['trial_id'].nunique()\n",
    "    n_timepoints = int((align_range[1] - align_range[0])/dataset.bin_width)\n",
    "    n_neurons = rates_df[x_field].shape[1]\n",
    "\n",
    "    rates_array = rates_df[x_field].to_numpy() - calc_proj(rates_df[x_field].to_numpy(),weights.T).T\n",
    "    vel_array = vel_df[y_field].to_numpy()\n",
    "    \n",
    "    lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)})\n",
    "    lr_all.fit(rates_array, vel_array)\n",
    "    pred_vel = lr_all.predict(rates_array)\n",
    "    vel_df = pd.concat([vel_df, pd.DataFrame(pred_vel, columns=dataset._make_midx('pred_vel', ['x', 'y'], 2))], axis=1)\n",
    "#     print(lr_all.best_params_['alpha'])\n",
    "    \n",
    "    rates_array = rates_array.reshape(n_trials, n_timepoints, n_neurons)\n",
    "    vel_array = vel_array.reshape(n_trials, n_timepoints, 2)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "    true_concat = nans([n_trials*n_timepoints,2])\n",
    "    pred_concat = nans([n_trials*n_timepoints,2])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test, y_train, y_test = process_train_test(rates_array,vel_array,training_set,test_set)\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)}) \n",
    "        lr.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "        \n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "        trial_save_idx += n\n",
    "    \n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    print('R2:',R2) \n",
    "    return R2, lr_all.best_estimator_.coef_, vel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b23884",
   "metadata": {},
   "source": [
    "### Timing plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea2209d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons = dataset_5ms.data.spikes.shape[1]\n",
    "print(n_neurons,'neurons')\n",
    "\n",
    "active_mask = (~dataset_5ms.trial_info.ctr_hold_bump) & (dataset_5ms.trial_info.split != 'none')\n",
    "passive_mask = (dataset_5ms.trial_info.ctr_hold_bump) & (dataset_5ms.trial_info.split != 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1715590",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_range = (-40, 100)\n",
    "x_axis = np.arange(plot_range[0], plot_range[1], dataset_5ms.bin_width)\n",
    "passive_df = dataset_5ms.make_trial_data(align_field='bump_time', align_range=plot_range, ignored_trials=~passive_mask)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for _, trial in passive_df.groupby('trial_id'):\n",
    "    plt.plot(x_axis, trial.force['y'], color='red', linewidth=0.5)\n",
    "plt.xlabel('Time after bump time (ms)')\n",
    "plt.ylabel('Force to manipulandum (N)')\n",
    "plt.axvline(0, color = 'k',linestyle = '--')\n",
    "plt.title('Force aligned to bump_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cdd410",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_range = (-40, 100)\n",
    "x_axis = np.arange(plot_range[0], plot_range[1], dataset_5ms.bin_width)\n",
    "active_df = dataset_5ms.make_trial_data(align_field='move_onset_time', align_range=plot_range, ignored_trials=~active_mask)\n",
    "passive_df = dataset_5ms.make_trial_data(align_field='move_onset_time', align_range=plot_range, ignored_trials=~passive_mask)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for _, trial in active_df.groupby('trial_id'):\n",
    "    plt.plot(x_axis,trial.speed, color='k', linewidth=0.5)\n",
    "for _, trial in passive_df.groupby('trial_id'):\n",
    "    plt.plot(x_axis, trial.speed, color='red', linewidth=0.5)\n",
    "plt.xlabel('Time after movement onset (ms)')\n",
    "plt.ylabel('Hand speed (cm/s)')\n",
    "plt.axvline(0, color = 'k',linestyle = '--')\n",
    "plt.title('Speed aligned to bump_time')\n",
    "# plt.axvline(120, color = 'k',linestyle = '--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc083d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_range = (-40, 100)\n",
    "x_axis = np.arange(plot_range[0], plot_range[1], dataset_5ms.bin_width)\n",
    "active_df = dataset_5ms.make_trial_data(align_field='move_onset_time', align_range=plot_range, ignored_trials=~active_mask)\n",
    "passive_df = dataset_5ms.make_trial_data(align_field='move_onset_time', align_range=plot_range, ignored_trials=~passive_mask)\n",
    "\n",
    "active_trials_spikes = []\n",
    "for _, trial in active_df.groupby('trial_id'):\n",
    "    active_trials_spikes.append(np.sum(trial.spikes,axis=1))\n",
    "passive_trials_spikes = []\n",
    "for _, trial in passive_df.groupby('trial_id'):\n",
    "    passive_trials_spikes.append(np.sum(trial.spikes,axis=1))\n",
    "\n",
    "plt.plot(x_axis,np.sum(active_trials_spikes,axis = 0)/dataset_5ms.bin_width*1000/len(active_trials_spikes)/n_neurons,\"-o\",color = 'k',label = 'Active')\n",
    "plt.plot(x_axis,np.sum(passive_trials_spikes,axis = 0)/dataset_5ms.bin_width*1000/len(passive_trials_spikes)/n_neurons,\"-o\",color = 'red',label = 'Passive')\n",
    "plt.legend()\n",
    "plt.title('Peristimulus')\n",
    "plt.ylabel('Trial-average, neuron-average, FR (per sec)')\n",
    "plt.xlabel('Time after movement onset (ms)')\n",
    "plt.axvline(0, color = 'k',linestyle = '--')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257bacfe",
   "metadata": {},
   "source": [
    "## with Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106dc233",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_axis = np.arange(-300,300,20)\n",
    "x_field = 'spikes_smth_40'\n",
    "y_field ='hand_vel'\n",
    "trial_mask = active_mask\n",
    "\n",
    "# Prepare for plotting\n",
    "plot_dir = [0.0, 90.0, 180.0, 270.0] # limit plot directions to reduce cluttering\n",
    "plot_dim = 'x' # plot x velocity\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/neurons/act/\"\n",
    "\n",
    "dim = n_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a60097",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_range = (-100, 500)\n",
    "label = '_whole_'\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "\n",
    "curr_r2_array = nans([len(lag_axis)])\n",
    "curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "    curr_r2_array[i] = r2\n",
    "    curr_coef_array[i,:,:] = coef\n",
    "\n",
    "idx_max = np.argmax(curr_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "_, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.hand_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + 'true.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(lag_axis, curr_r2_array)\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.title('R2 score predicting hand velocity [-100,500]')\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "# ang_dist_to_max = nans([len(lag_axis)])\n",
    "# for i in range(0, len(curr_coef_array)):\n",
    "#     ang_dist_to_max[i] = math.degrees(angle_between(curr_coef_array[i,0,:],curr_coef_array[idx_max,0,:]))\n",
    "# plt.scatter(lag_axis, ang_dist_to_max)\n",
    "# plt.title('Angular distance to X-vel decoding dim at t_max')\n",
    "# plt.xlabel('Time lag (ms)')\n",
    "# plt.ylabel('Angular distance (degrees)')\n",
    "# plt.show()\n",
    "\n",
    "weights = curr_coef_array[idx_max,:,:]\n",
    "for iter in range(0,7):  \n",
    "    #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "    sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "    sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "        sub_r2_array[i] = r2\n",
    "        sub_coef_array[i,:,:] = coef\n",
    "\n",
    "    plt.plot(lag_axis,sub_r2_array)\n",
    "    plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "    idx_max = np.argmax(sub_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('x-vel')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "#     plt.plot(lag_axis,np.subtract(sub_r2_array,curr_r2_array))\n",
    "#     plt.axhline(0,color = 'k',linestyle='--')\n",
    "#     plt.title('R2 difference after projecting out t_max dim')\n",
    "#     plt.xlabel('Time lag (ms)')\n",
    "#     plt.ylabel('R2 difference')\n",
    "#     plt.show()\n",
    "#     curr_r2_array = sub_r2_array\n",
    "\n",
    "    #stack the decoding dimensions to be projected out\n",
    "    weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8771f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_range = (-100, 120)\n",
    "label = '_long_'\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "\n",
    "curr_r2_array = nans([len(lag_axis)])\n",
    "curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "    curr_r2_array[i] = r2\n",
    "    curr_coef_array[i,:,:] = coef\n",
    "\n",
    "idx_max = np.argmax(curr_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "_, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.hand_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + 'true.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(lag_axis, curr_r2_array)\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.title('R2 score predicting hand velocity [0,120]')\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "weights = curr_coef_array[idx_max,:,:]\n",
    "for iter in range(0,3):  \n",
    "    #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "    sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "    sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "        sub_r2_array[i] = r2\n",
    "        sub_coef_array[i,:,:] = coef\n",
    "\n",
    "    plt.plot(lag_axis,sub_r2_array)\n",
    "    plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "    idx_max = np.argmax(sub_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('x-vel')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    #stack the decoding dimensions to be projected out\n",
    "    weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca42adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_range = (380, 500)\n",
    "label = '_late_'\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "\n",
    "curr_r2_array = nans([len(lag_axis)])\n",
    "curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "    curr_r2_array[i] = r2\n",
    "    curr_coef_array[i,:,:] = coef\n",
    "\n",
    "idx_max = np.argmax(curr_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "_, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.hand_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + 'true.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(lag_axis, curr_r2_array)\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.title('R2 score predicting hand velocity [380,500]')\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "weights = curr_coef_array[idx_max,:,:]\n",
    "for iter in range(0,3):  \n",
    "    #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "    sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "    sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "        sub_r2_array[i] = r2\n",
    "        sub_coef_array[i,:,:] = coef\n",
    "\n",
    "    plt.plot(lag_axis,sub_r2_array)\n",
    "    plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "    idx_max = np.argmax(sub_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('x-vel')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    #stack the decoding dimensions to be projected out\n",
    "    weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f030f4",
   "metadata": {},
   "source": [
    "## with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d6d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_field = 'PCA'\n",
    "y_field ='hand_vel'\n",
    "lag_axis = np.arange(-300,300,20)\n",
    "\n",
    "# Prepare for plotting\n",
    "plot_dir = [0.0, 90.0, 180.0, 270.0] # limit plot directions to reduce cluttering\n",
    "plot_dim = 'x' # plot x velocity\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/PCA/act/\"\n",
    "\n",
    "dim = n_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e9b431",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_range = (-100, 500)\n",
    "label = '_whole_'\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "\n",
    "curr_r2_array = nans([len(lag_axis)])\n",
    "curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "    curr_r2_array[i] = r2\n",
    "    curr_coef_array[i,:,:] = coef\n",
    "\n",
    "idx_max = np.argmax(curr_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "_, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(lag_axis, curr_r2_array)\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.title('R2 score predicting hand velocity [-100,500]')\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "weights = curr_coef_array[idx_max,:,:]\n",
    "for iter in range(0,3):  \n",
    "    #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "    sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "    sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "        sub_r2_array[i] = r2\n",
    "        sub_coef_array[i,:,:] = coef\n",
    "\n",
    "    plt.plot(lag_axis,sub_r2_array)\n",
    "    plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "    idx_max = np.argmax(sub_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('x-vel')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    #stack the decoding dimensions to be projected out\n",
    "    weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad9fe30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_range = (-100, 120)\n",
    "label = '_long_'\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "\n",
    "curr_r2_array = nans([len(lag_axis)])\n",
    "curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "    curr_r2_array[i] = r2\n",
    "    curr_coef_array[i,:,:] = coef\n",
    "\n",
    "idx_max = np.argmax(curr_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "_, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(lag_axis, curr_r2_array)\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.title('R2 score predicting hand velocity [0,120]')\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "weights = curr_coef_array[idx_max,:,:]\n",
    "for iter in range(0,3):  \n",
    "    #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "    sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "    sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "        sub_r2_array[i] = r2\n",
    "        sub_coef_array[i,:,:] = coef\n",
    "\n",
    "    plt.plot(lag_axis,sub_r2_array)\n",
    "    plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "    idx_max = np.argmax(sub_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('x-vel')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    #stack the decoding dimensions to be projected out\n",
    "    weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3648371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_range = (380, 500)\n",
    "label = '_late_'\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "\n",
    "curr_r2_array = nans([len(lag_axis)])\n",
    "curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "    curr_r2_array[i] = r2\n",
    "    curr_coef_array[i,:,:] = coef\n",
    "\n",
    "idx_max = np.argmax(curr_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "_, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('x-vel')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(lag_axis, curr_r2_array)\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.title('R2 score predicting hand velocity [380,500]')\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "weights = curr_coef_array[idx_max,:,:]\n",
    "for iter in range(0,3):  \n",
    "    #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "    sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "    sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "        sub_r2_array[i] = r2\n",
    "        sub_coef_array[i,:,:] = coef\n",
    "\n",
    "    plt.plot(lag_axis,sub_r2_array)\n",
    "    plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "    idx_max = np.argmax(sub_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel('x-vel')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "    \n",
    "    #stack the decoding dimensions to be projected out\n",
    "    weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7c89f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9046b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df8d00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffa52a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80e66b89",
   "metadata": {},
   "source": [
    "# Multi Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8649848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_50ms = NWBDataset(filename, split_heldout=False)\n",
    "dataset_50ms.resample(50)\n",
    "print(dataset_50ms.bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dims = 20 # for PCA\n",
    "\n",
    "active_mask = (~dataset_50ms.trial_info.ctr_hold_bump) & (dataset_50ms.trial_info.split != 'none')\n",
    "passive_mask = (dataset_50ms.trial_info.ctr_hold_bump) & (dataset_50ms.trial_info.split != 'none')\n",
    "\n",
    "\n",
    "trial_mask = active_mask\n",
    "n_trials = dataset_50ms.trial_info.loc[trial_mask].shape[0]\n",
    "print(n_trials,'trials')\n",
    "n_neurons = dataset_50ms.data.spikes.shape[1]\n",
    "print(n_neurons,'neurons')\n",
    "\n",
    "all_data = np.array(dataset_50ms.data.spikes)\n",
    "print(all_data.shape)\n",
    "data_for_pca = all_data[~np.isnan(all_data).any(axis=1)]\n",
    "print(data_for_pca.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data_for_pca)\n",
    "pca = PCA(n_components=n_dims)\n",
    "X = pca.fit(X)\n",
    "\n",
    "PCA_data = nans([all_data.shape[0],n_dims])\n",
    "idx = 0\n",
    "for dp in all_data:\n",
    "    dp = dp.reshape((1, -1))\n",
    "    if np.isnan(dp).any():\n",
    "        dp_pca = nans([1,n_dims])\n",
    "    else:\n",
    "        dp_pca = pca.transform(scaler.transform(dp))\n",
    "    PCA_data[idx,:] = dp_pca\n",
    "    idx+=1\n",
    "print(PCA_data.shape)\n",
    "dataset_50ms.add_continuous_data(PCA_data,'PCA')\n",
    "print('PCA total var explained:',sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a348315",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_data = dataset_50ms.make_trial_data(align_field='move_onset_time', align_range=(-300, 700), ignored_trials=~trial_mask)\n",
    "for idx, trial in active_data.groupby('trial_id'):\n",
    "    n_timepoints = trial.shape[0]\n",
    "    break\n",
    "print(n_timepoints,'time bins')\n",
    "\n",
    "active_trials_neuron = nans([n_trials,n_timepoints,n_neurons])\n",
    "active_trials_vel = nans([n_trials,n_timepoints,2])\n",
    "active_trials_pca = nans([n_trials,n_timepoints,n_dims])\n",
    "i = 0\n",
    "for idx, trial in active_data.groupby('trial_id'):\n",
    "    active_trials_neuron[i,:,:]=trial.spikes.to_numpy()\n",
    "    active_trials_vel[i,:,:]=trial.hand_vel.to_numpy()\n",
    "    active_trials_pca[i,:,:]=trial.PCA.to_numpy()\n",
    "    i+=1\n",
    "print(active_trials_neuron.shape)\n",
    "print(active_trials_vel.shape)\n",
    "print(active_trials_pca.shape)\n",
    "\n",
    "#make dictionary for trial condition (reaching directions) for Stratified CV\n",
    "active_trials_idx = np.array(dataset_50ms.trial_info.loc[trial_mask]['trial_id'])\n",
    "cond_dir_idx = []\n",
    "cond_dict = nans([n_trials])\n",
    "for direction in [0,45,90,135,180,225,270,315]:\n",
    "    cond_dir_idx.append(np.where((dataset_50ms.trial_info['cond_dir'] == direction) & (dataset_50ms.trial_info['ctr_hold_bump'] == False) & \\\n",
    "           (dataset_50ms.trial_info['split'] != 'none'))[0])\n",
    "i = 0\n",
    "for idx in active_trials_idx:\n",
    "    for cond in range(0,len(cond_dir_idx)):\n",
    "        if idx in cond_dir_idx[cond]:\n",
    "            cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(cond_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988e86c8",
   "metadata": {},
   "source": [
    "## Early"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a441427b",
   "metadata": {},
   "source": [
    "### with Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bd712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_range = [-300,700]\n",
    "pred_start = -100\n",
    "pred_end = 120\n",
    "\n",
    "idx1 = int((pred_start - data_range[0])/dataset_50ms.bin_width)\n",
    "idx2 = int(n_timepoints - (data_range[1]-pred_end)/dataset_50ms.bin_width)\n",
    "\n",
    "t_before_range = range(0,301,50);\n",
    "t_after_range = range(0,501,50);\n",
    "\n",
    "early_multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "early_multi_coefs = []\n",
    "j,k=0,0\n",
    "for time_before in t_before_range:\n",
    "    coef_arr = []\n",
    "    for time_after in t_after_range:\n",
    "        print('Predicting with',-time_before, 'to', time_after,'ms neural data')\n",
    "        \n",
    "        bins_before= int(time_before/dataset_50ms.bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "        bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "        bins_after= int(time_after/dataset_50ms.bin_width) #How many bins of neural data after the output are used for decoding\n",
    "\n",
    "        n_total_bins = bins_before + bins_current + bins_after\n",
    "\n",
    "        X =  nans([n_trials,idx2-idx1,n_total_bins*n_neurons])\n",
    "        i = 0\n",
    "        for trial_data in active_trials_neuron:\n",
    "            trial_hist=get_spikes_with_history(trial_data,bins_before,bins_after,bins_current)\n",
    "            trial_hist = trial_hist[idx1:idx2,:,:]\n",
    "            trial_hist_flat=trial_hist.reshape(trial_hist.shape[0],(trial_hist.shape[1]*trial_hist.shape[2]))\n",
    "            X[i,:,:] = trial_hist_flat\n",
    "            i+=1\n",
    "        \n",
    "        y = active_trials_vel[:,idx1:idx2,:]\n",
    "    \n",
    "        lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)})\n",
    "        X_reshaped = X.reshape((X.shape[0]*X.shape[1]),X.shape[2])\n",
    "        y_reshaped = y.reshape((y.shape[0]*y.shape[1]),y.shape[2])\n",
    "        lr_all.fit(X_reshaped, y_reshaped)\n",
    "        print(lr_all.best_params_['alpha'])\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "        true_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "        pred_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "        trial_save_idx = 0\n",
    "        for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "            #split training and testing by trials\n",
    "            X_train, X_test, y_train, y_test = process_train_test(X,y,training_set,test_set)\n",
    "            lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)}) \n",
    "            lr.fit(X_train, y_train)\n",
    "            y_test_predicted = lr.predict(X_test)\n",
    "            n = y_test_predicted.shape[0]\n",
    "            true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "            pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "            trial_save_idx += n\n",
    "\n",
    "        sses =get_sses_pred(true_concat,pred_concat)\n",
    "        sses_mean=get_sses_mean(true_concat)\n",
    "        early_multi_R2s[j,k] =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "        print('R2:',early_multi_R2s[j,k])\n",
    "        coef_arr.append(lr_all.best_estimator_.coef_)\n",
    "        k += 1\n",
    "    j += 1\n",
    "    k = 0\n",
    "    early_multi_coefs.append(coef_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce60a4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(early_multi_R2s)\n",
    "ax.set_xlabel('Length of lagging info')\n",
    "ax.set_ylabel('Length of leading info')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_after_range)))\n",
    "ax.set_yticks(np.arange(len(t_before_range)))\n",
    "ax.set_xticklabels(labels=t_after_range)\n",
    "ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "ax.set_title(\"R2 predicting [-100, 120] velocity \\nwith different lagging/leading info\")\n",
    "fig.tight_layout()\n",
    " \n",
    "for i in range(len(t_before_range)):\n",
    "    for j in range(len(t_after_range)):\n",
    "        text = ax.text(j, i, str(int(early_multi_R2s[i, j]*1000)/1000),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "plt.tight_layout()\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/neurons/act/\"\n",
    "plt.savefig(figDir + monkey + '_multi_early.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e187da",
   "metadata": {},
   "source": [
    "### with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff8207",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_early_multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "PCA_early_multi_coefs = []\n",
    "j,k=0,0\n",
    "for time_before in t_before_range:\n",
    "    coef_arr = []\n",
    "    for time_after in t_after_range:\n",
    "        print('Predicting with',-time_before, 'to', time_after,'ms neural data')\n",
    "        \n",
    "        bins_before= int(time_before/dataset_50ms.bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "        bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "        bins_after= int(time_after/dataset_50ms.bin_width) #How many bins of neural data after the output are used for decoding\n",
    "\n",
    "        n_total_bins = bins_before + bins_current + bins_after\n",
    "\n",
    "        X =  nans([n_trials,idx2-idx1,n_total_bins*n_dims])\n",
    "        i = 0\n",
    "        for trial_data in active_trials_pca:\n",
    "            trial_hist=get_spikes_with_history(trial_data,bins_before,bins_after,bins_current)\n",
    "            trial_hist = trial_hist[idx1:idx2,:,:]\n",
    "            trial_hist_flat=trial_hist.reshape(trial_hist.shape[0],(trial_hist.shape[1]*trial_hist.shape[2]))\n",
    "            X[i,:,:] = trial_hist_flat\n",
    "            i+=1\n",
    "        \n",
    "        y = active_trials_vel[:,idx1:idx2,:]\n",
    "    \n",
    "        lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)})\n",
    "        X_reshaped = X.reshape((X.shape[0]*X.shape[1]),X.shape[2])\n",
    "        y_reshaped = y.reshape((y.shape[0]*y.shape[1]),y.shape[2])\n",
    "        lr_all.fit(X_reshaped, y_reshaped)\n",
    "        print(lr_all.best_params_['alpha'])\n",
    "        \n",
    "        skf =StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "        true_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "        pred_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "        trial_save_idx = 0\n",
    "        for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "            #split training and testing by trials\n",
    "            X_train, X_test, y_train, y_test = process_train_test(X,y,training_set,test_set)\n",
    "            lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)}) \n",
    "            lr.fit(X_train, y_train)\n",
    "            y_test_predicted = lr.predict(X_test)\n",
    "            n = y_test_predicted.shape[0]\n",
    "            true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "            pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "            trial_save_idx += n\n",
    "\n",
    "        sses =get_sses_pred(true_concat,pred_concat)\n",
    "        sses_mean=get_sses_mean(true_concat)\n",
    "        PCA_early_multi_R2s[j,k] =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "        print('R2:',PCA_early_multi_R2s[j,k])\n",
    "        coef_arr.append(lr_all.best_estimator_.coef_)\n",
    "        k += 1\n",
    "    j += 1\n",
    "    k = 0\n",
    "    PCA_early_multi_coefs.append(coef_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9a8339",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(PCA_early_multi_R2s)\n",
    "ax.set_xlabel('Length of lagging info')\n",
    "ax.set_ylabel('Length of leading info')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_after_range)))\n",
    "ax.set_yticks(np.arange(len(t_before_range)))\n",
    "ax.set_xticklabels(labels=t_after_range)\n",
    "ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "ax.set_title(\"R2 predicting [0, 120] velocity \\nwith different lagging/leading info\")\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(t_before_range)):\n",
    "    for j in range(len(t_after_range)):\n",
    "        text = ax.text(j, i, str(int(PCA_early_multi_R2s[i, j]*1000)/1000),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.tight_layout()\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/PCA/act/\"\n",
    "plt.savefig(figDir + monkey + '_multi_early.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa49221",
   "metadata": {},
   "source": [
    "## Whole"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef332cd6",
   "metadata": {},
   "source": [
    "### with Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8378b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_range = [-300,700]\n",
    "pred_start = -100\n",
    "pred_end = 500\n",
    "\n",
    "idx1 = int((pred_start - data_range[0])/dataset_50ms.bin_width)\n",
    "idx2 = int(n_timepoints - (data_range[1]-pred_end)/dataset_50ms.bin_width)\n",
    "\n",
    "t_before_range = range(0,201,50);\n",
    "t_after_range = range(0,201,50);\n",
    "\n",
    "whole_multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "whole_multi_coefs = []\n",
    "j,k=0,0\n",
    "for time_before in t_before_range:\n",
    "    coef_arr = []\n",
    "    for time_after in t_after_range:\n",
    "        print('Predicting with',-time_before, 'to', time_after,'ms neural data')\n",
    "        \n",
    "        bins_before= int(time_before/dataset_50ms.bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "        bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "        bins_after= int(time_after/dataset_50ms.bin_width) #How many bins of neural data after the output are used for decoding\n",
    "\n",
    "        n_total_bins = bins_before + bins_current + bins_after\n",
    "\n",
    "        X =  nans([n_trials,idx2-idx1,n_total_bins*n_neurons])\n",
    "        i = 0\n",
    "        for trial_data in active_trials_neuron:\n",
    "            trial_hist=get_spikes_with_history(trial_data,bins_before,bins_after,bins_current)\n",
    "            trial_hist = trial_hist[idx1:idx2,:,:]\n",
    "            trial_hist_flat=trial_hist.reshape(trial_hist.shape[0],(trial_hist.shape[1]*trial_hist.shape[2]))\n",
    "            X[i,:,:] = trial_hist_flat\n",
    "            i+=1\n",
    "        \n",
    "        y = active_trials_vel[:,idx1:idx2,:]\n",
    "    \n",
    "        lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)})\n",
    "        X_reshaped = X.reshape((X.shape[0]*X.shape[1]),X.shape[2])\n",
    "        y_reshaped = y.reshape((y.shape[0]*y.shape[1]),y.shape[2])\n",
    "        lr_all.fit(X_reshaped, y_reshaped)\n",
    "        print(lr_all.best_params_['alpha'])\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "        true_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "        pred_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "        trial_save_idx = 0\n",
    "        for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "            #split training and testing by trials\n",
    "            X_train, X_test, y_train, y_test = process_train_test(X,y,training_set,test_set)\n",
    "            lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)}) \n",
    "            lr.fit(X_train, y_train)\n",
    "            y_test_predicted = lr.predict(X_test)\n",
    "            n = y_test_predicted.shape[0]\n",
    "            true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "            pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "            trial_save_idx += n\n",
    "\n",
    "        sses =get_sses_pred(true_concat,pred_concat)\n",
    "        sses_mean=get_sses_mean(true_concat)\n",
    "        whole_multi_R2s[j,k] =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "        print('R2:',whole_multi_R2s[j,k])\n",
    "        coef_arr.append(lr_all.best_estimator_.coef_)\n",
    "        k += 1\n",
    "    j += 1\n",
    "    k = 0\n",
    "    whole_multi_coefs.append(coef_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf34e627",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(whole_multi_R2s)\n",
    "ax.set_xlabel('Length of lagging info')\n",
    "ax.set_ylabel('Length of leading info')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_after_range)))\n",
    "ax.set_yticks(np.arange(len(t_before_range)))\n",
    "ax.set_xticklabels(labels=t_after_range)\n",
    "ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "ax.set_title(\"R2 predicting [-100, 500] velocity \\nwith different lagging/leading info\")\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(t_before_range)):\n",
    "    for j in range(len(t_after_range)):\n",
    "        text = ax.text(j, i, str(int(whole_multi_R2s[i, j]*1000)/1000),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.tight_layout()\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/neurons/act/\"\n",
    "plt.savefig(figDir + monkey + '_multi_whole.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2cea1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_X = whole_multi_coefs[-1][-1][0] #which entry's weights to use\n",
    "\n",
    "t_label = np.arange(-200,201,50)\n",
    "\n",
    "n_weights = len(t_before_range) + len(t_after_range) - 1\n",
    "coef_X_reshaped = coef_X.reshape(n_weights,n_neurons)\n",
    "angDist_array = nans([n_weights,n_weights])\n",
    "for i in range(n_weights):\n",
    "    for j in range(n_weights):\n",
    "        angDist_array[i,j] = math.degrees(angle_between(coef_X_reshaped[i,:],coef_X_reshaped[j,:]))\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "im = ax.imshow(angDist_array)\n",
    "ax.set_xlabel('Bin time (ms)')\n",
    "ax.set_ylabel('Bin time (ms)')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_label)))\n",
    "ax.set_yticks(np.arange(len(t_label)))\n",
    "ax.set_xticklabels(labels=t_label)\n",
    "ax.set_yticklabels(labels=t_label)\n",
    "\n",
    "ax.set_title(\"Angle between weight vectors at time points\")\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(t_label)):\n",
    "    for j in range(len(t_label)):\n",
    "        text = ax.text(j, i, str(int(angDist_array[i, j])),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.tight_layout()\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/neurons/act/\"\n",
    "plt.savefig(figDir + monkey + '_multi_whole_deg.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8958e911",
   "metadata": {},
   "source": [
    "### with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6de7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_whole_multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "PCA_whole_multi_coefs = []\n",
    "j,k=0,0\n",
    "for time_before in t_before_range:\n",
    "    coef_arr = []\n",
    "    for time_after in t_after_range:\n",
    "        print('Predicting with',-time_before, 'to', time_after,'ms neural data')\n",
    "        \n",
    "        bins_before= int(time_before/dataset_50ms.bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "        bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "        bins_after= int(time_after/dataset_50ms.bin_width) #How many bins of neural data after the output are used for decoding\n",
    "\n",
    "        n_total_bins = bins_before + bins_current + bins_after\n",
    "\n",
    "        X =  nans([n_trials,idx2-idx1,n_total_bins*n_dims])\n",
    "        i = 0\n",
    "        for trial_data in active_trials_pca:\n",
    "            trial_hist=get_spikes_with_history(trial_data,bins_before,bins_after,bins_current)\n",
    "            trial_hist = trial_hist[idx1:idx2,:,:]\n",
    "            trial_hist_flat=trial_hist.reshape(trial_hist.shape[0],(trial_hist.shape[1]*trial_hist.shape[2]))\n",
    "            X[i,:,:] = trial_hist_flat\n",
    "            i+=1\n",
    "        \n",
    "        y = active_trials_vel[:,idx1:idx2,:]\n",
    "    \n",
    "        lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)})\n",
    "        X_reshaped = X.reshape((X.shape[0]*X.shape[1]),X.shape[2])\n",
    "        y_reshaped = y.reshape((y.shape[0]*y.shape[1]),y.shape[2])\n",
    "        lr_all.fit(X_reshaped, y_reshaped)\n",
    "        print(lr_all.best_params_['alpha'])\n",
    "        \n",
    "        skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "        true_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "        pred_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "        trial_save_idx = 0\n",
    "        for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "            #split training and testing by trials\n",
    "            X_train, X_test, y_train, y_test = process_train_test(X,y,training_set,test_set)\n",
    "            lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)}) \n",
    "            lr.fit(X_train, y_train)\n",
    "            y_test_predicted = lr.predict(X_test)\n",
    "            n = y_test_predicted.shape[0]\n",
    "            true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "            pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "            trial_save_idx += n\n",
    "\n",
    "        sses =get_sses_pred(true_concat,pred_concat)\n",
    "        sses_mean=get_sses_mean(true_concat)\n",
    "        PCA_whole_multi_R2s[j,k] =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "        print('R2:',PCA_whole_multi_R2s[j,k])\n",
    "        coef_arr.append(lr_all.best_estimator_.coef_)\n",
    "        k += 1\n",
    "    j += 1\n",
    "    k = 0\n",
    "    PCA_whole_multi_coefs.append(coef_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8ed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(PCA_whole_multi_R2s)\n",
    "ax.set_xlabel('Length of lagging info')\n",
    "ax.set_ylabel('Length of leading info')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_after_range)))\n",
    "ax.set_yticks(np.arange(len(t_before_range)))\n",
    "ax.set_xticklabels(labels=t_after_range)\n",
    "ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "ax.set_title(\"R2 predicting [-100, 500] velocity \\nwith different lagging/leading info\")\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(t_before_range)):\n",
    "    for j in range(len(t_after_range)):\n",
    "        text = ax.text(j, i, str(int(PCA_whole_multi_R2s[i, j]*1000)/1000),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.tight_layout()\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/PCA/act/\"\n",
    "plt.savefig(figDir + monkey + '_multi_whole.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c2c54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_X = PCA_whole_multi_coefs[-1][-1][0] #which entry's weights to use\n",
    "\n",
    "t_label = np.arange(-200,201,50)\n",
    "\n",
    "n_weights = len(t_before_range) + len(t_after_range) - 1\n",
    "coef_X_reshaped = coef_X.reshape(n_weights,n_dims)\n",
    "angDist_array = nans([n_weights,n_weights])\n",
    "for i in range(n_weights):\n",
    "    for j in range(n_weights):\n",
    "        angDist_array[i,j] = math.degrees(angle_between(coef_X_reshaped[i,:],coef_X_reshaped[j,:]))\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "im = ax.imshow(angDist_array)\n",
    "ax.set_xlabel('Bin time (ms)')\n",
    "ax.set_ylabel('Bin time (ms)')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_label)))\n",
    "ax.set_yticks(np.arange(len(t_label)))\n",
    "ax.set_xticklabels(labels=t_label)\n",
    "ax.set_yticklabels(labels=t_label)\n",
    "\n",
    "ax.set_title(\"Angle between weight vectors at time points\")\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(t_label)):\n",
    "    for j in range(len(t_label)):\n",
    "        text = ax.text(j, i, str(int(angDist_array[i, j])),\n",
    "                       ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.tight_layout()\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/PCA/act/\"\n",
    "plt.savefig(figDir + monkey + '_multi_whole_deg.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f22933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5384f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
