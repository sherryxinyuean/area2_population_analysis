{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n"
     ]
    }
   ],
   "source": [
    "###Import standard packages###\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "\n",
    "###Import functions for binning data for preprocessing###\n",
    "from Neural_Decoding.preprocessing_funcs import bin_spikes\n",
    "from Neural_Decoding.preprocessing_funcs import bin_output\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from Area2_analysis.multi_area_funcs import smooth_spk, fit_and_predict, sub_and_predict, mp_fit_lag_r2, mp_sub_lag_r2, mp_multi_fit_lag_r2\n",
    "import multiprocessing as mp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from Area2_analysis.funcs import nans\n",
    "from Neural_Decoding.preprocessing_funcs import get_spikes_with_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foldername = \"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "# filename = foldername + \"s1_data_raw.mat\"\n",
    "# s1_data_raw = io.loadmat(filename)\n",
    "\n",
    "# spike_times=s1_data_raw['spike_times']\n",
    "# acc = s1_data_raw['acc']\n",
    "# vel = s1_data_raw['vels']\n",
    "# times = s1_data_raw['vel_times']\n",
    "\n",
    "# #original data has 0.01 s = 10 ms bins \n",
    "# dt = 0.01\n",
    "# t_start = times[0]\n",
    "# t_end = times[-1]\n",
    "\n",
    "# spike_times = np.squeeze(spike_times)\n",
    "# for i in range(spike_times.shape[0]):\n",
    "#     spike_times[i]=np.squeeze(spike_times[i])\n",
    "\n",
    "# neural_data=bin_spikes(spike_times,dt,t_start,t_end)\n",
    "# gauss_width = 40 #in ms\n",
    "# bin_width = dt*1000\n",
    "# smth_40 = smooth_spk(neural_data, gauss_width, bin_width)\n",
    "# smth_20 = smooth_spk(neural_data, 20, bin_width)\n",
    "\n",
    "# accs_binned=bin_output(acc,times,dt,t_start,t_end)\n",
    "# vels_binned=bin_output(vel,times,dt,t_start,t_end)\n",
    "\n",
    "# with open(foldername+'proc_data_s1.pickle','wb') as f:\n",
    "#     pickle.dump([smth_40,smth_20,accs_binned,vels_binned],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(306698, 52)\n",
      "(306698, 52)\n",
      "(306698, 2)\n",
      "(306698, 2)\n"
     ]
    }
   ],
   "source": [
    "folder=\"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "\n",
    "with open(folder+'proc_data_s1.pickle','rb') as f:\n",
    "    s1_smth_40,s1_smth_20,s1_accs_binned, s1_vels_binned=pickle.load(f,encoding='latin1')\n",
    "print(s1_smth_40.shape)\n",
    "print(s1_smth_20.shape)\n",
    "print(s1_accs_binned.shape)\n",
    "print(s1_vels_binned.shape)\n",
    "\n",
    "n_neurons = s1_smth_20.shape[1]\n",
    "\n",
    "n_dims = 20\n",
    "if not np.isnan(s1_smth_40).any():\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(s1_smth_40)\n",
    "    pca = PCA(n_components=n_dims,random_state = 42)\n",
    "    smth_40_pca = pca.fit_transform(X)\n",
    "    print(smth_40_pca.shape)\n",
    "    print('PCA total var explained:',sum(pca.explained_variance_ratio_))\n",
    "s1_40_pca = smth_40_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n"
     ]
    }
   ],
   "source": [
    "x_field = 'PCA'\n",
    "y_field = 'hand_acc'\n",
    "\n",
    "if x_field == 'neurons':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/neurons/S1/\"\n",
    "    x = s1_smth_40\n",
    "if x_field == 'PCA':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/PCA/S1/\"\n",
    "    x = s1_40_pca\n",
    "if y_field == 'hand_vel':\n",
    "    y = s1_vels_binned\n",
    "if y_field == 'hand_acc':\n",
    "    y = s1_accs_binned\n",
    "\n",
    "lag_axis = np.arange(-300,300,20)\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "s1_r2_array = [pool.starmap(mp_fit_lag_r2, [(x,y,lag,10) for lag in lag_axis])][0]\n",
    "pool.close()\n",
    "idx_max = np.argmax(s1_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "plt.plot(lag_axis, s1_r2_array)\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.title('R2 score predicting ' + y_field )\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + y_field +'_0.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "_, weights, _ = fit_and_predict(x,y,time_max,bin_size=10)\n",
    "#subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "s1_sub_r2_array = [pool.starmap(mp_sub_lag_r2, [(x,y,lag,10,weights) for lag in lag_axis])][0]\n",
    "pool.close()\n",
    "\n",
    "plt.plot(lag_axis,s1_sub_r2_array)\n",
    "plt.title('R2 score projecting out #1 t_max dim')\n",
    "idx_max = np.argmax(s1_sub_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + y_field +'_1.png', dpi = 'figure')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foldername = \"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "# filename = foldername + \"s1_data_raw.mat\"\n",
    "# s1_data_raw = io.loadmat(filename)\n",
    "\n",
    "# spike_times=s1_data_raw['spike_times']\n",
    "# acc = s1_data_raw['acc']\n",
    "# vel = s1_data_raw['vels']\n",
    "# times = s1_data_raw['vel_times']\n",
    "\n",
    "# #original data has 0.01 s = 10 ms bins \n",
    "# dt = 0.05 #50ms bins\n",
    "# t_start = times[0]\n",
    "# t_end = times[-1]\n",
    "\n",
    "# spike_times = np.squeeze(spike_times)\n",
    "# for i in range(spike_times.shape[0]):\n",
    "#     spike_times[i]=np.squeeze(spike_times[i])\n",
    "\n",
    "# neural_data_50=bin_spikes(spike_times,dt,t_start,t_end)\n",
    "# accs_50_binned=bin_output(acc,times,dt,t_start,t_end)\n",
    "# vels_50_binned=bin_output(vel,times,dt,t_start,t_end)\n",
    "\n",
    "# with open(foldername+'proc_50_data_s1.pickle','wb') as f:\n",
    "#     pickle.dump([neural_data_50,accs_50_binned,vels_50_binned],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61339, 52)\n",
      "(61339, 2)\n",
      "(61339, 2)\n",
      "(61339, 20)\n",
      "PCA total var explained: 0.48676931827230147\n"
     ]
    }
   ],
   "source": [
    "folder=\"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "\n",
    "with open(folder+'proc_50_data_s1.pickle','rb') as f:\n",
    "    s1_neural_data_50,s1_accs_50_binned,s1_vels_50_binned=pickle.load(f,encoding='latin1')\n",
    "print(s1_neural_data_50.shape)\n",
    "print(s1_accs_50_binned.shape)\n",
    "print(s1_vels_50_binned.shape)\n",
    "\n",
    "bin_width = 50\n",
    "\n",
    "n_dims = 20\n",
    "if not np.isnan(s1_neural_data_50).any():\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(s1_neural_data_50)\n",
    "    pca = PCA(n_components=n_dims,random_state = 42)\n",
    "    neural_data_50_pca = pca.fit_transform(X)\n",
    "    print(neural_data_50_pca.shape)\n",
    "    print('PCA total var explained:',sum(pca.explained_variance_ratio_))\n",
    "s1_neural_data_50_pca = neural_data_50_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with 0 to 0 ms neural data\n",
      "(61339, 20)\n",
      "R2: 0.08129166045406244\n",
      "Predicting with 0 to 50 ms neural data\n",
      "(61339, 40)\n",
      "R2: 0.20007120523457256\n",
      "Predicting with 0 to 100 ms neural data\n",
      "(61339, 60)\n",
      "R2: 0.2573699027208781\n",
      "Predicting with 0 to 150 ms neural data\n",
      "(61339, 80)\n",
      "R2: 0.27596734988481497\n",
      "Predicting with 0 to 200 ms neural data\n",
      "(61339, 100)\n",
      "R2: 0.2862983749398812\n",
      "Predicting with 0 to 250 ms neural data\n",
      "(61339, 120)\n",
      "R2: 0.2923957032277533\n",
      "Predicting with 0 to 300 ms neural data\n",
      "(61339, 140)\n",
      "R2: 0.2958720463954052\n",
      "Predicting with 0 to 350 ms neural data\n",
      "(61339, 160)\n",
      "R2: 0.2983368756436272\n",
      "Predicting with 0 to 400 ms neural data\n",
      "(61339, 180)\n",
      "R2: 0.2999474473798721\n",
      "Predicting with 0 to 450 ms neural data\n",
      "(61339, 200)\n",
      "R2: 0.30066696609770416\n",
      "Predicting with 0 to 500 ms neural data\n",
      "(61339, 220)\n",
      "R2: 0.3009058966097744\n",
      "Predicting with -50 to 0 ms neural data\n",
      "(61339, 40)\n",
      "R2: 0.17533898129492664\n",
      "Predicting with -50 to 50 ms neural data\n",
      "(61339, 60)\n",
      "R2: 0.29665080309124936\n",
      "Predicting with -50 to 100 ms neural data\n",
      "(61339, 80)\n",
      "R2: 0.3538450615871266\n",
      "Predicting with -50 to 150 ms neural data\n",
      "(61339, 100)\n",
      "R2: 0.36988731776438366\n",
      "Predicting with -50 to 200 ms neural data\n",
      "(61339, 120)\n",
      "R2: 0.37843068275267266\n",
      "Predicting with -50 to 250 ms neural data\n",
      "(61339, 140)\n",
      "R2: 0.383104826641258\n",
      "Predicting with -50 to 300 ms neural data\n",
      "(61339, 160)\n",
      "R2: 0.38557856864767204\n",
      "Predicting with -50 to 350 ms neural data\n",
      "(61339, 180)\n",
      "R2: 0.3872099591470909\n",
      "Predicting with -50 to 400 ms neural data\n",
      "(61339, 200)\n",
      "R2: 0.3881860240337921\n",
      "Predicting with -50 to 450 ms neural data\n",
      "(61339, 220)\n",
      "R2: 0.38847902808583756\n",
      "Predicting with -50 to 500 ms neural data\n",
      "(61339, 240)\n",
      "R2: 0.38854648797521996\n",
      "Predicting with -100 to 0 ms neural data\n",
      "(61339, 60)\n",
      "R2: 0.2652439728324375\n",
      "Predicting with -100 to 50 ms neural data\n",
      "(61339, 80)\n",
      "R2: 0.3909251708100403\n",
      "Predicting with -100 to 100 ms neural data\n",
      "(61339, 100)\n",
      "R2: 0.445489638870881\n",
      "Predicting with -100 to 150 ms neural data\n",
      "(61339, 120)\n",
      "R2: 0.46020926155324404\n",
      "Predicting with -100 to 200 ms neural data\n",
      "(61339, 140)\n",
      "R2: 0.4678257642938727\n",
      "Predicting with -100 to 250 ms neural data\n",
      "(61339, 160)\n",
      "R2: 0.4716354313025538\n",
      "Predicting with -100 to 300 ms neural data\n",
      "(61339, 180)\n",
      "R2: 0.4733550675533582\n",
      "Predicting with -100 to 350 ms neural data\n",
      "(61339, 200)\n",
      "R2: 0.47446017849492284\n",
      "Predicting with -100 to 400 ms neural data\n",
      "(61339, 220)\n",
      "R2: 0.4750013560457257\n",
      "Predicting with -100 to 450 ms neural data\n",
      "(61339, 240)\n",
      "R2: 0.4751632891900749\n",
      "Predicting with -100 to 500 ms neural data\n",
      "(61339, 260)\n",
      "R2: 0.47517969707880625\n",
      "Predicting with -150 to 0 ms neural data\n",
      "(61339, 80)\n",
      "R2: 0.31848391927465547\n",
      "Predicting with -150 to 50 ms neural data\n",
      "(61339, 100)\n",
      "R2: 0.4429994886652945\n",
      "Predicting with -150 to 100 ms neural data\n",
      "(61339, 120)\n",
      "R2: 0.4973995672778351\n",
      "Predicting with -150 to 150 ms neural data\n",
      "(61339, 140)\n",
      "R2: 0.5118214790798159\n",
      "Predicting with -150 to 200 ms neural data\n",
      "(61339, 160)\n",
      "R2: 0.5188409460087999\n",
      "Predicting with -150 to 250 ms neural data\n",
      "(61339, 180)\n",
      "R2: 0.5222225028639924\n",
      "Predicting with -150 to 300 ms neural data\n",
      "(61339, 200)\n",
      "R2: 0.5236255415406645\n",
      "Predicting with -150 to 350 ms neural data\n",
      "(61339, 220)\n",
      "R2: 0.5244625841799597\n",
      "Predicting with -150 to 400 ms neural data\n",
      "(61339, 240)\n",
      "R2: 0.5248593262085213\n",
      "Predicting with -150 to 450 ms neural data\n",
      "(61339, 260)\n",
      "R2: 0.524993211499005\n",
      "Predicting with -150 to 500 ms neural data\n",
      "(61339, 280)\n",
      "R2: 0.5249864349193596\n",
      "Predicting with -200 to 0 ms neural data\n",
      "(61339, 100)\n",
      "R2: 0.3406481256211895\n",
      "Predicting with -200 to 50 ms neural data\n",
      "(61339, 120)\n",
      "R2: 0.4655914628790614\n",
      "Predicting with -200 to 100 ms neural data\n",
      "(61339, 140)\n",
      "R2: 0.520073685772214\n",
      "Predicting with -200 to 150 ms neural data\n",
      "(61339, 160)\n",
      "R2: 0.5340330887084555\n",
      "Predicting with -200 to 200 ms neural data\n",
      "(61339, 180)\n",
      "R2: 0.5408132744161909\n",
      "Predicting with -200 to 250 ms neural data\n",
      "(61339, 200)\n",
      "R2: 0.5440050421083843\n",
      "Predicting with -200 to 300 ms neural data\n",
      "(61339, 220)\n",
      "R2: 0.5452722807179111\n",
      "Predicting with -200 to 350 ms neural data\n",
      "(61339, 240)\n",
      "R2: 0.546005942735067\n",
      "Predicting with -200 to 400 ms neural data\n",
      "(61339, 260)\n",
      "R2: 0.5463196073262371\n",
      "Predicting with -200 to 450 ms neural data\n",
      "(61339, 280)\n",
      "R2: 0.5464306261800747\n",
      "Predicting with -200 to 500 ms neural data\n",
      "(61339, 300)\n",
      "R2: 0.5464039682870515\n",
      "Predicting with -250 to 0 ms neural data\n",
      "(61339, 120)\n",
      "R2: 0.3508143432193501\n",
      "Predicting with -250 to 50 ms neural data\n",
      "(61339, 140)\n",
      "R2: 0.475675063689295\n",
      "Predicting with -250 to 100 ms neural data\n",
      "(61339, 160)\n",
      "R2: 0.5298538383704499\n",
      "Predicting with -250 to 150 ms neural data\n",
      "(61339, 180)\n",
      "R2: 0.5437466945977195\n",
      "Predicting with -250 to 200 ms neural data\n",
      "(61339, 200)\n",
      "R2: 0.5503522797760516\n",
      "Predicting with -250 to 250 ms neural data\n",
      "(61339, 220)\n",
      "R2: 0.553449576864526\n",
      "Predicting with -250 to 300 ms neural data\n",
      "(61339, 240)\n",
      "R2: 0.5546938150024261\n",
      "Predicting with -250 to 350 ms neural data\n",
      "(61339, 260)\n",
      "R2: 0.5553500860591405\n",
      "Predicting with -250 to 400 ms neural data\n",
      "(61339, 280)\n",
      "R2: 0.5556163860384324\n",
      "Predicting with -250 to 450 ms neural data\n",
      "(61339, 300)\n",
      "R2: 0.5556942772599612\n",
      "Predicting with -250 to 500 ms neural data\n",
      "(61339, 320)\n",
      "R2: 0.5556617390070528\n",
      "Predicting with -300 to 0 ms neural data\n",
      "(61339, 140)\n",
      "R2: 0.3552019096355806\n",
      "Predicting with -300 to 50 ms neural data\n",
      "(61339, 160)\n",
      "R2: 0.47984022445786956\n",
      "Predicting with -300 to 100 ms neural data\n",
      "(61339, 180)\n",
      "R2: 0.5339950073899001\n",
      "Predicting with -300 to 150 ms neural data\n",
      "(61339, 200)\n",
      "R2: 0.5477140590983403\n",
      "Predicting with -300 to 200 ms neural data\n",
      "(61339, 220)\n",
      "R2: 0.5541884420398547\n",
      "Predicting with -300 to 250 ms neural data\n",
      "(61339, 240)\n",
      "R2: 0.5572736683269564\n",
      "Predicting with -300 to 300 ms neural data\n",
      "(61339, 260)\n",
      "R2: 0.5584686971374353\n",
      "Predicting with -300 to 350 ms neural data\n",
      "(61339, 280)\n",
      "R2: 0.5590905687830112\n",
      "Predicting with -300 to 400 ms neural data\n",
      "(61339, 300)\n",
      "R2: 0.5593188978209054\n",
      "Predicting with -300 to 450 ms neural data\n",
      "(61339, 320)\n",
      "R2: 0.5593785158495956\n",
      "Predicting with -300 to 500 ms neural data\n",
      "(61339, 340)\n",
      "R2: 0.5593402742079542\n",
      "Predicting with -350 to 0 ms neural data\n",
      "(61339, 160)\n",
      "R2: 0.35820817527888715\n",
      "Predicting with -350 to 50 ms neural data\n",
      "(61339, 180)\n",
      "R2: 0.482648772277513\n",
      "Predicting with -350 to 100 ms neural data\n",
      "(61339, 200)\n",
      "R2: 0.5365170328893973\n",
      "Predicting with -350 to 150 ms neural data\n",
      "(61339, 220)\n",
      "R2: 0.5500534158413588\n",
      "Predicting with -350 to 200 ms neural data\n",
      "(61339, 240)\n",
      "R2: 0.5564569500888575\n",
      "Predicting with -350 to 250 ms neural data\n",
      "(61339, 260)\n",
      "R2: 0.5595209468832114\n",
      "Predicting with -350 to 300 ms neural data\n",
      "(61339, 280)\n",
      "R2: 0.5606927604758511\n",
      "Predicting with -350 to 350 ms neural data\n",
      "(61339, 300)\n",
      "R2: 0.5612773709092291\n",
      "Predicting with -350 to 400 ms neural data\n",
      "(61339, 320)\n",
      "R2: 0.5614946023754295\n",
      "Predicting with -350 to 450 ms neural data\n",
      "(61339, 340)\n",
      "R2: 0.5615398618151344\n",
      "Predicting with -350 to 500 ms neural data\n",
      "(61339, 360)\n",
      "R2: 0.5615005913951483\n",
      "Predicting with -400 to 0 ms neural data\n",
      "(61339, 180)\n",
      "R2: 0.36074634177277576\n",
      "Predicting with -400 to 50 ms neural data\n",
      "(61339, 200)\n",
      "R2: 0.48476491059779125\n",
      "Predicting with -400 to 100 ms neural data\n",
      "(61339, 220)\n",
      "R2: 0.5383960942236116\n",
      "Predicting with -400 to 150 ms neural data\n",
      "(61339, 240)\n",
      "R2: 0.551799751818602\n",
      "Predicting with -400 to 200 ms neural data\n",
      "(61339, 260)\n",
      "R2: 0.5581673933691225\n",
      "Predicting with -400 to 250 ms neural data\n",
      "(61339, 280)\n",
      "R2: 0.5612045899619178\n",
      "Predicting with -400 to 300 ms neural data\n",
      "(61339, 300)\n",
      "R2: 0.5623346304350392\n",
      "Predicting with -400 to 350 ms neural data\n",
      "(61339, 320)\n",
      "R2: 0.5629086781083122\n",
      "Predicting with -400 to 400 ms neural data\n",
      "(61339, 340)\n",
      "R2: 0.5631095299092718\n",
      "Predicting with -400 to 450 ms neural data\n",
      "(61339, 360)\n",
      "R2: 0.5631590153236039\n",
      "Predicting with -400 to 500 ms neural data\n",
      "(61339, 380)\n",
      "R2: 0.5631174922259172\n",
      "Predicting with -450 to 0 ms neural data\n",
      "(61339, 200)\n",
      "R2: 0.36232431877997895\n",
      "Predicting with -450 to 50 ms neural data\n",
      "(61339, 220)\n",
      "R2: 0.48608772040644754\n",
      "Predicting with -450 to 100 ms neural data\n",
      "(61339, 240)\n",
      "R2: 0.5395899814637939\n",
      "Predicting with -450 to 150 ms neural data\n",
      "(61339, 260)\n",
      "R2: 0.5529691922020441\n",
      "Predicting with -450 to 200 ms neural data\n",
      "(61339, 280)\n",
      "R2: 0.5593199301428169\n",
      "Predicting with -450 to 250 ms neural data\n",
      "(61339, 300)\n",
      "R2: 0.5623157474199378\n",
      "Predicting with -450 to 300 ms neural data\n",
      "(61339, 320)\n",
      "R2: 0.5634214731766509\n",
      "Predicting with -450 to 350 ms neural data\n",
      "(61339, 340)\n",
      "R2: 0.5639735497319291\n",
      "Predicting with -450 to 400 ms neural data\n",
      "(61339, 360)\n",
      "R2: 0.5641681891433622\n",
      "Predicting with -450 to 450 ms neural data\n",
      "(61339, 380)\n",
      "R2: 0.5642083870860051\n",
      "Predicting with -450 to 500 ms neural data\n",
      "(61339, 400)\n",
      "R2: 0.5641713898637453\n",
      "Predicting with -500 to 0 ms neural data\n",
      "(61339, 220)\n",
      "R2: 0.36314682648300856\n",
      "Predicting with -500 to 50 ms neural data\n",
      "(61339, 240)\n",
      "R2: 0.48686141932817795\n",
      "Predicting with -500 to 100 ms neural data\n",
      "(61339, 260)\n",
      "R2: 0.5403983491135645\n",
      "Predicting with -500 to 150 ms neural data\n",
      "(61339, 280)\n",
      "R2: 0.5537514453230006\n",
      "Predicting with -500 to 200 ms neural data\n",
      "(61339, 300)\n",
      "R2: 0.5600535670778755\n",
      "Predicting with -500 to 250 ms neural data\n",
      "(61339, 320)\n",
      "R2: 0.5630373217534594\n",
      "Predicting with -500 to 300 ms neural data\n",
      "(61339, 340)\n",
      "R2: 0.5641333426220284\n",
      "Predicting with -500 to 350 ms neural data\n",
      "(61339, 360)\n",
      "R2: 0.5646708787045123\n",
      "Predicting with -500 to 400 ms neural data\n",
      "(61339, 380)\n",
      "R2: 0.5648470570859822\n",
      "Predicting with -500 to 450 ms neural data\n",
      "(61339, 400)\n",
      "R2: 0.5648922923650805\n",
      "Predicting with -500 to 500 ms neural data\n",
      "(61339, 420)\n",
      "R2: 0.5648585928037755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/3p5f6szx247fkf6ftdgp147w0000gn/T/ipykernel_46561/1936292039.py:53: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "x_field = 'PCA'\n",
    "y_field = 'hand_acc'\n",
    "\n",
    "if x_field == 'neurons':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/neurons/S1/\"\n",
    "    x = s1_neural_data_50\n",
    "if x_field == 'PCA':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/PCA/S1/\"\n",
    "    x = s1_neural_data_50_pca\n",
    "if y_field == 'hand_vel':\n",
    "    y = s1_vels_50_binned\n",
    "if y_field == 'hand_acc':\n",
    "    y = s1_accs_50_binned\n",
    "\n",
    "t_before_range = range(0,301,50)\n",
    "t_after_range = range(0,301,50)\n",
    "s1_multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "j,k = 0,0\n",
    "for t_before in t_after_range:\n",
    "    for t_after in t_after_range:\n",
    "        print('Predicting with',-t_before, 'to', t_after,'ms neural data')\n",
    "        bins_before= int(t_before/bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "        bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "        bins_after= int(t_after/bin_width) #How many bins of neural data after the output are used for decoding\n",
    "        X_cov = get_spikes_with_history(x,bins_before,bins_after,bins_current)\n",
    "        X_flat = X_cov.reshape(X_cov.shape[0],(X_cov.shape[1]*X_cov.shape[2]))\n",
    "        print(X_flat.shape)\n",
    "        X_chopped = X_flat[~np.isnan(X_flat).any(axis = 1)]\n",
    "        y_chopped = y[0+bins_before:y.shape[0]-bins_after,:]\n",
    "        s1_multi_R2s[j,k] = mp_multi_fit_lag_r2(X_chopped,y_chopped)\n",
    "        print('R2:',s1_multi_R2s[j,k])\n",
    "        k+=1\n",
    "    j+=1\n",
    "    k=0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(s1_multi_R2s)\n",
    "ax.set_xlabel('Length of lagging info')\n",
    "ax.set_ylabel('Length of leading info')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_after_range)))\n",
    "ax.set_yticks(np.arange(len(t_before_range)))\n",
    "ax.set_xticklabels(labels=t_after_range)\n",
    "ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "ax.set_title('R2 predicting ' + y_field +' with different lagging/leading info')\n",
    "fig.tight_layout()\n",
    "for i in range(len(t_before_range)):\n",
    "    for j in range(len(t_after_range)):\n",
    "        text = ax.text(j, i, str(int(s1_multi_R2s[i, j]*1000)/1000),\n",
    "                        ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + y_field + '_multi_lag_.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foldername = \"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "# filename = foldername + \"m1_data_raw.mat\"\n",
    "# m1_data_raw = io.loadmat(filename)\n",
    "\n",
    "# spike_times=m1_data_raw['spike_times'][:70,:] #only first 70 are M1 neurons\n",
    "# acc = m1_data_raw['acc']\n",
    "# vel = m1_data_raw['vels']\n",
    "# times = m1_data_raw['vel_times']\n",
    "\n",
    "# #original data has 0.001 s = 1 ms bins \n",
    "# dt = 0.01\n",
    "# t_start = times[0]\n",
    "# t_end = times[-1]\n",
    "\n",
    "# spike_times = np.squeeze(spike_times)\n",
    "# for i in range(spike_times.shape[0]):\n",
    "#     spike_times[i]=np.squeeze(spike_times[i])\n",
    "\n",
    "# neural_data=bin_spikes(spike_times,dt,t_start,t_end)\n",
    "# gauss_width = 40 #in ms\n",
    "# bin_width = dt*1000\n",
    "# smth_40 = smooth_spk(neural_data, gauss_width, bin_width)\n",
    "# smth_20 = smooth_spk(neural_data, 20, bin_width)\n",
    "\n",
    "# accs_binned=bin_output(acc,times,dt,t_start,t_end)\n",
    "# vels_binned=bin_output(vel,times,dt,t_start,t_end)\n",
    "\n",
    "# with open(foldername+'proc_data_m1.pickle','wb') as f:\n",
    "#     pickle.dump([smth_40, smth_20,accs_binned,vels_binned],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126499, 70)\n",
      "(126499, 70)\n",
      "(126499, 2)\n",
      "(126499, 2)\n",
      "(126499, 20)\n",
      "PCA total var explained: 0.5520019353069091\n"
     ]
    }
   ],
   "source": [
    "folder=\"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "\n",
    "with open(folder+'proc_data_m1.pickle','rb') as f:\n",
    "    m1_smth_40,m1_smth_20,m1_accs_binned, m1_vels_binned=pickle.load(f,encoding='latin1')\n",
    "print(m1_smth_40.shape)\n",
    "print(m1_smth_20.shape)\n",
    "print(m1_accs_binned.shape)\n",
    "print(m1_vels_binned.shape)\n",
    "\n",
    "n_neurons = m1_smth_20.shape[1]\n",
    "\n",
    "n_dims = 20\n",
    "if not np.isnan(m1_smth_40).any():\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(m1_smth_40)\n",
    "    pca = PCA(n_components=n_dims,random_state = 42)\n",
    "    smth_40_pca = pca.fit_transform(X)\n",
    "    print(smth_40_pca.shape)\n",
    "    print('PCA total var explained:',sum(pca.explained_variance_ratio_))\n",
    "m1_40_pca = smth_40_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n"
     ]
    }
   ],
   "source": [
    "x_field = 'PCA'\n",
    "y_field = 'hand_vel'\n",
    "\n",
    "if x_field == 'neurons':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/neurons/M1/\"\n",
    "    x = m1_smth_40\n",
    "if x_field == 'PCA':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/PCA/M1/\"\n",
    "    x = m1_40_pca\n",
    "if y_field == 'hand_vel':\n",
    "    y = m1_vels_binned\n",
    "if y_field == 'hand_acc':\n",
    "    y = m1_accs_binned\n",
    "\n",
    "lag_axis = np.arange(-300,300,20)\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "m1_r2_array = [pool.starmap(mp_fit_lag_r2, [(x,y,lag,10) for lag in lag_axis])][0]\n",
    "pool.close()\n",
    "\n",
    "idx_max = np.argmax(m1_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "plt.plot(lag_axis, m1_r2_array)\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.title('R2 score predicting ' + y_field )\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + y_field +'_0.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "_, weights, _ = fit_and_predict(x,y,time_max,bin_size=10)\n",
    "#subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "m1_sub_r2_array = [pool.starmap(mp_sub_lag_r2, [(x,y,lag,10,weights) for lag in lag_axis])][0]\n",
    "pool.close()\n",
    "plt.plot(lag_axis,m1_sub_r2_array)\n",
    "plt.title('R2 score projecting out #1 t_max dim')\n",
    "idx_max = np.argmax(m1_sub_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + y_field +'_1.png', dpi = 'figure')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foldername = \"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "# filename = foldername + \"m1_data_raw.mat\"\n",
    "# m1_data_raw = io.loadmat(filename)\n",
    "\n",
    "# spike_times=m1_data_raw['spike_times']\n",
    "# acc = m1_data_raw['acc']\n",
    "# vel = m1_data_raw['vels']\n",
    "# times = m1_data_raw['vel_times']\n",
    "\n",
    "# #original data has 0.01 s = 10 ms bins \n",
    "# dt = 0.05 #50ms bins\n",
    "# t_start = times[0]\n",
    "# t_end = times[-1]\n",
    "\n",
    "# spike_times = np.squeeze(spike_times)\n",
    "# for i in range(spike_times.shape[0]):\n",
    "#     spike_times[i]=np.squeeze(spike_times[i])\n",
    "\n",
    "# neural_data_50=bin_spikes(spike_times,dt,t_start,t_end)\n",
    "# accs_50_binned=bin_output(acc,times,dt,t_start,t_end)\n",
    "# vels_50_binned=bin_output(vel,times,dt,t_start,t_end)\n",
    "\n",
    "# with open(foldername+'proc_50_data_m1.pickle','wb') as f:\n",
    "#     pickle.dump([neural_data_50,accs_50_binned,vels_50_binned],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25299, 164)\n",
      "(25299, 2)\n",
      "(25299, 2)\n",
      "(25299, 20)\n",
      "PCA total var explained: 0.2596326642721701\n"
     ]
    }
   ],
   "source": [
    "folder=\"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "\n",
    "with open(folder+'proc_50_data_m1.pickle','rb') as f:\n",
    "    m1_neural_data_50,m1_accs_50_binned,m1_vels_50_binned=pickle.load(f,encoding='latin1')\n",
    "print(m1_neural_data_50.shape)\n",
    "print(m1_accs_50_binned.shape)\n",
    "print(m1_vels_50_binned.shape)\n",
    "\n",
    "bin_width = 50\n",
    "\n",
    "n_dims = 20\n",
    "if not np.isnan(m1_neural_data_50).any():\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(m1_neural_data_50)\n",
    "    pca = PCA(n_components=n_dims,random_state = 42)\n",
    "    neural_data_50_pca = pca.fit_transform(X)\n",
    "    print(neural_data_50_pca.shape)\n",
    "    print('PCA total var explained:',sum(pca.explained_variance_ratio_))\n",
    "m1_neural_data_50_pca = neural_data_50_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with 0 to 0 ms neural data\n",
      "(25299, 20)\n",
      "R2: 0.12739857372050623\n",
      "Predicting with 0 to 50 ms neural data\n",
      "(25299, 40)\n",
      "R2: 0.1514747962418208\n",
      "Predicting with 0 to 100 ms neural data\n",
      "(25299, 60)\n",
      "R2: 0.16549421271656062\n",
      "Predicting with 0 to 150 ms neural data\n",
      "(25299, 80)\n",
      "R2: 0.17790198715031302\n",
      "Predicting with 0 to 200 ms neural data\n",
      "(25299, 100)\n",
      "R2: 0.18584209551058473\n",
      "Predicting with 0 to 250 ms neural data\n",
      "(25299, 120)\n",
      "R2: 0.18956395063798614\n",
      "Predicting with 0 to 300 ms neural data\n",
      "(25299, 140)\n",
      "R2: 0.19166312636213567\n",
      "Predicting with 0 to 350 ms neural data\n",
      "(25299, 160)\n",
      "R2: 0.19322630067884117\n",
      "Predicting with 0 to 400 ms neural data\n",
      "(25299, 180)\n",
      "R2: 0.19517098879416694\n",
      "Predicting with 0 to 450 ms neural data\n",
      "(25299, 200)\n",
      "R2: 0.1965687356692708\n",
      "Predicting with 0 to 500 ms neural data\n",
      "(25299, 220)\n",
      "R2: 0.19752414667398255\n",
      "Predicting with -50 to 0 ms neural data\n",
      "(25299, 40)\n",
      "R2: 0.21109251465470147\n",
      "Predicting with -50 to 50 ms neural data\n",
      "(25299, 60)\n",
      "R2: 0.23258533576814178\n",
      "Predicting with -50 to 100 ms neural data\n",
      "(25299, 80)\n",
      "R2: 0.24581316334185022\n",
      "Predicting with -50 to 150 ms neural data\n",
      "(25299, 100)\n",
      "R2: 0.2568187870560247\n",
      "Predicting with -50 to 200 ms neural data\n",
      "(25299, 120)\n",
      "R2: 0.26372268369141627\n",
      "Predicting with -50 to 250 ms neural data\n",
      "(25299, 140)\n",
      "R2: 0.26717738843461825\n",
      "Predicting with -50 to 300 ms neural data\n",
      "(25299, 160)\n",
      "R2: 0.26851571555432163\n",
      "Predicting with -50 to 350 ms neural data\n",
      "(25299, 180)\n",
      "R2: 0.26972263216488757\n",
      "Predicting with -50 to 400 ms neural data\n",
      "(25299, 200)\n",
      "R2: 0.27103885750831047\n",
      "Predicting with -50 to 450 ms neural data\n",
      "(25299, 220)\n",
      "R2: 0.2719306050272402\n",
      "Predicting with -50 to 500 ms neural data\n",
      "(25299, 240)\n",
      "R2: 0.27237461335860036\n",
      "Predicting with -100 to 0 ms neural data\n",
      "(25299, 60)\n",
      "R2: 0.27764887309166275\n",
      "Predicting with -100 to 50 ms neural data\n",
      "(25299, 80)\n",
      "R2: 0.30133231214342626\n",
      "Predicting with -100 to 100 ms neural data\n",
      "(25299, 100)\n",
      "R2: 0.3156435179802499\n",
      "Predicting with -100 to 150 ms neural data\n",
      "(25299, 120)\n",
      "R2: 0.32612962744519647\n",
      "Predicting with -100 to 200 ms neural data\n",
      "(25299, 140)\n",
      "R2: 0.33235143308287307\n",
      "Predicting with -100 to 250 ms neural data\n",
      "(25299, 160)\n",
      "R2: 0.334910909271264\n",
      "Predicting with -100 to 300 ms neural data\n",
      "(25299, 180)\n",
      "R2: 0.3362659531657376\n",
      "Predicting with -100 to 350 ms neural data\n",
      "(25299, 200)\n",
      "R2: 0.33724736777385034\n",
      "Predicting with -100 to 400 ms neural data\n",
      "(25299, 220)\n",
      "R2: 0.3382150612256567\n",
      "Predicting with -100 to 450 ms neural data\n",
      "(25299, 240)\n",
      "R2: 0.3388216350397333\n",
      "Predicting with -100 to 500 ms neural data\n",
      "(25299, 260)\n",
      "R2: 0.3389801690482557\n",
      "Predicting with -150 to 0 ms neural data\n",
      "(25299, 80)\n",
      "R2: 0.33094112855986657\n",
      "Predicting with -150 to 50 ms neural data\n",
      "(25299, 100)\n",
      "R2: 0.3549541045319917\n",
      "Predicting with -150 to 100 ms neural data\n",
      "(25299, 120)\n",
      "R2: 0.36914240581518565\n",
      "Predicting with -150 to 150 ms neural data\n",
      "(25299, 140)\n",
      "R2: 0.37850551444471403\n",
      "Predicting with -150 to 200 ms neural data\n",
      "(25299, 160)\n",
      "R2: 0.3833613706694201\n",
      "Predicting with -150 to 250 ms neural data\n",
      "(25299, 180)\n",
      "R2: 0.3858029172663938\n",
      "Predicting with -150 to 300 ms neural data\n",
      "(25299, 200)\n",
      "R2: 0.3871249928883602\n",
      "Predicting with -150 to 350 ms neural data\n",
      "(25299, 220)\n",
      "R2: 0.38789743960864453\n",
      "Predicting with -150 to 400 ms neural data\n",
      "(25299, 240)\n",
      "R2: 0.3887325109982279\n",
      "Predicting with -150 to 450 ms neural data\n",
      "(25299, 260)\n",
      "R2: 0.3890857651231514\n",
      "Predicting with -150 to 500 ms neural data\n",
      "(25299, 280)\n",
      "R2: 0.38908255941325065\n",
      "Predicting with -200 to 0 ms neural data\n",
      "(25299, 100)\n",
      "R2: 0.3820767205000699\n",
      "Predicting with -200 to 50 ms neural data\n",
      "(25299, 120)\n",
      "R2: 0.4049454724625926\n",
      "Predicting with -200 to 100 ms neural data\n",
      "(25299, 140)\n",
      "R2: 0.4179594239683513\n",
      "Predicting with -200 to 150 ms neural data\n",
      "(25299, 160)\n",
      "R2: 0.42590223962711204\n",
      "Predicting with -200 to 200 ms neural data\n",
      "(25299, 180)\n",
      "R2: 0.4304204847542592\n",
      "Predicting with -200 to 250 ms neural data\n",
      "(25299, 200)\n",
      "R2: 0.4326379081622693\n",
      "Predicting with -200 to 300 ms neural data\n",
      "(25299, 220)\n",
      "R2: 0.4335769481844446\n",
      "Predicting with -200 to 350 ms neural data\n",
      "(25299, 240)\n",
      "R2: 0.4343009454674076\n",
      "Predicting with -200 to 400 ms neural data\n",
      "(25299, 260)\n",
      "R2: 0.435093052420239\n",
      "Predicting with -200 to 450 ms neural data\n",
      "(25299, 280)\n",
      "R2: 0.4351682928629198\n",
      "Predicting with -200 to 500 ms neural data\n",
      "(25299, 300)\n",
      "R2: 0.43513228248313873\n",
      "Predicting with -250 to 0 ms neural data\n",
      "(25299, 120)\n",
      "R2: 0.4253686196631866\n",
      "Predicting with -250 to 50 ms neural data\n",
      "(25299, 140)\n",
      "R2: 0.44668153644476827\n",
      "Predicting with -250 to 100 ms neural data\n",
      "(25299, 160)\n",
      "R2: 0.4581872577207299\n",
      "Predicting with -250 to 150 ms neural data\n",
      "(25299, 180)\n",
      "R2: 0.46574851144344787\n",
      "Predicting with -250 to 200 ms neural data\n",
      "(25299, 200)\n",
      "R2: 0.46984029643591885\n",
      "Predicting with -250 to 250 ms neural data\n",
      "(25299, 220)\n",
      "R2: 0.47165171539285156\n",
      "Predicting with -250 to 300 ms neural data\n",
      "(25299, 240)\n",
      "R2: 0.4724656155717716\n",
      "Predicting with -250 to 350 ms neural data\n",
      "(25299, 260)\n",
      "R2: 0.47325362352060263\n",
      "Predicting with -250 to 400 ms neural data\n",
      "(25299, 280)\n",
      "R2: 0.47388523713951447\n",
      "Predicting with -250 to 450 ms neural data\n",
      "(25299, 300)\n",
      "R2: 0.47387558644777594\n",
      "Predicting with -250 to 500 ms neural data\n",
      "(25299, 320)\n",
      "R2: 0.4737800321471807\n",
      "Predicting with -300 to 0 ms neural data\n",
      "(25299, 140)\n",
      "R2: 0.455368079681027\n",
      "Predicting with -300 to 50 ms neural data\n",
      "(25299, 160)\n",
      "R2: 0.47513480488232007\n",
      "Predicting with -300 to 100 ms neural data\n",
      "(25299, 180)\n",
      "R2: 0.4858609247999921\n",
      "Predicting with -300 to 150 ms neural data\n",
      "(25299, 200)\n",
      "R2: 0.49283599487849794\n",
      "Predicting with -300 to 200 ms neural data\n",
      "(25299, 220)\n",
      "R2: 0.49656404122659537\n",
      "Predicting with -300 to 250 ms neural data\n",
      "(25299, 240)\n",
      "R2: 0.4980659033928274\n",
      "Predicting with -300 to 300 ms neural data\n",
      "(25299, 260)\n",
      "R2: 0.49884874773878185\n",
      "Predicting with -300 to 350 ms neural data\n",
      "(25299, 280)\n",
      "R2: 0.49957443705471516\n",
      "Predicting with -300 to 400 ms neural data\n",
      "(25299, 300)\n",
      "R2: 0.5001275881246976\n",
      "Predicting with -300 to 450 ms neural data\n",
      "(25299, 320)\n",
      "R2: 0.5001079327199146\n",
      "Predicting with -300 to 500 ms neural data\n",
      "(25299, 340)\n",
      "R2: 0.4999920566734084\n",
      "Predicting with -350 to 0 ms neural data\n",
      "(25299, 160)\n",
      "R2: 0.47558323911422684\n",
      "Predicting with -350 to 50 ms neural data\n",
      "(25299, 180)\n",
      "R2: 0.49409209335883064\n",
      "Predicting with -350 to 100 ms neural data\n",
      "(25299, 200)\n",
      "R2: 0.5041809537851213\n",
      "Predicting with -350 to 150 ms neural data\n",
      "(25299, 220)\n",
      "R2: 0.5106621977006313\n",
      "Predicting with -350 to 200 ms neural data\n",
      "(25299, 240)\n",
      "R2: 0.5138616638066149\n",
      "Predicting with -350 to 250 ms neural data\n",
      "(25299, 260)\n",
      "R2: 0.5152832727429695\n",
      "Predicting with -350 to 300 ms neural data\n",
      "(25299, 280)\n",
      "R2: 0.515982763906764\n",
      "Predicting with -350 to 350 ms neural data\n",
      "(25299, 300)\n",
      "R2: 0.5166377491372536\n",
      "Predicting with -350 to 400 ms neural data\n",
      "(25299, 320)\n",
      "R2: 0.5171376765654843\n",
      "Predicting with -350 to 450 ms neural data\n",
      "(25299, 340)\n",
      "R2: 0.5170682012505212\n",
      "Predicting with -350 to 500 ms neural data\n",
      "(25299, 360)\n",
      "R2: 0.5168275515381708\n",
      "Predicting with -400 to 0 ms neural data\n",
      "(25299, 180)\n",
      "R2: 0.4891845686447498\n",
      "Predicting with -400 to 50 ms neural data\n",
      "(25299, 200)\n",
      "R2: 0.506966447156779\n",
      "Predicting with -400 to 100 ms neural data\n",
      "(25299, 220)\n",
      "R2: 0.5164109431288859\n",
      "Predicting with -400 to 150 ms neural data\n",
      "(25299, 240)\n",
      "R2: 0.5222171942382526\n",
      "Predicting with -400 to 200 ms neural data\n",
      "(25299, 260)\n",
      "R2: 0.5252278609460748\n",
      "Predicting with -400 to 250 ms neural data\n",
      "(25299, 280)\n",
      "R2: 0.5265301563022915\n",
      "Predicting with -400 to 300 ms neural data\n",
      "(25299, 300)\n",
      "R2: 0.5271522721296366\n",
      "Predicting with -400 to 350 ms neural data\n",
      "(25299, 320)\n",
      "R2: 0.5277683511141225\n",
      "Predicting with -400 to 400 ms neural data\n",
      "(25299, 340)\n",
      "R2: 0.5282389432230614\n",
      "Predicting with -400 to 450 ms neural data\n",
      "(25299, 360)\n",
      "R2: 0.5280768330568555\n",
      "Predicting with -400 to 500 ms neural data\n",
      "(25299, 380)\n",
      "R2: 0.5278190836834197\n",
      "Predicting with -450 to 0 ms neural data\n",
      "(25299, 200)\n",
      "R2: 0.49882654417421246\n",
      "Predicting with -450 to 50 ms neural data\n",
      "(25299, 220)\n",
      "R2: 0.5158609678649293\n",
      "Predicting with -450 to 100 ms neural data\n",
      "(25299, 240)\n",
      "R2: 0.5246706609091679\n",
      "Predicting with -450 to 150 ms neural data\n",
      "(25299, 260)\n",
      "R2: 0.5301417111638276\n",
      "Predicting with -450 to 200 ms neural data\n",
      "(25299, 280)\n",
      "R2: 0.532946695387308\n",
      "Predicting with -450 to 250 ms neural data\n",
      "(25299, 300)\n",
      "R2: 0.5341660933347772\n",
      "Predicting with -450 to 300 ms neural data\n",
      "(25299, 320)\n",
      "R2: 0.5347213075373883\n",
      "Predicting with -450 to 350 ms neural data\n",
      "(25299, 340)\n",
      "R2: 0.5353596313111713\n",
      "Predicting with -450 to 400 ms neural data\n",
      "(25299, 360)\n",
      "R2: 0.5358002716404038\n",
      "Predicting with -450 to 450 ms neural data\n",
      "(25299, 380)\n",
      "R2: 0.5356640578821785\n",
      "Predicting with -450 to 500 ms neural data\n",
      "(25299, 400)\n",
      "R2: 0.5353904939468755\n",
      "Predicting with -500 to 0 ms neural data\n",
      "(25299, 220)\n",
      "R2: 0.5054019687954929\n",
      "Predicting with -500 to 50 ms neural data\n",
      "(25299, 240)\n",
      "R2: 0.5218904662488888\n",
      "Predicting with -500 to 100 ms neural data\n",
      "(25299, 260)\n",
      "R2: 0.5304285661431893\n",
      "Predicting with -500 to 150 ms neural data\n",
      "(25299, 280)\n",
      "R2: 0.5356246861520337\n",
      "Predicting with -500 to 200 ms neural data\n",
      "(25299, 300)\n",
      "R2: 0.5384015089381387\n",
      "Predicting with -500 to 250 ms neural data\n",
      "(25299, 320)\n",
      "R2: 0.5395400756439237\n",
      "Predicting with -500 to 300 ms neural data\n",
      "(25299, 340)\n",
      "R2: 0.5400766326574422\n",
      "Predicting with -500 to 350 ms neural data\n",
      "(25299, 360)\n",
      "R2: 0.5407098516173744\n",
      "Predicting with -500 to 400 ms neural data\n",
      "(25299, 380)\n",
      "R2: 0.5411688840898756\n",
      "Predicting with -500 to 450 ms neural data\n",
      "(25299, 400)\n",
      "R2: 0.5410030441942506\n",
      "Predicting with -500 to 500 ms neural data\n",
      "(25299, 420)\n",
      "R2: 0.5407659637907332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/3p5f6szx247fkf6ftdgp147w0000gn/T/ipykernel_46561/1474082026.py:53: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "x_field = 'PCA'\n",
    "y_field = 'hand_acc'\n",
    "\n",
    "if x_field == 'neurons':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/neurons/M1/\"\n",
    "    x = m1_neural_data_50\n",
    "if x_field == 'PCA':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/PCA/M1/\"\n",
    "    x = m1_neural_data_50_pca\n",
    "if y_field == 'hand_vel':\n",
    "    y = m1_vels_50_binned\n",
    "if y_field == 'hand_acc':\n",
    "    y = m1_accs_50_binned\n",
    "\n",
    "t_before_range = range(0,301,50)\n",
    "t_after_range = range(0,301,50)\n",
    "m1_multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "j,k = 0,0\n",
    "for t_before in t_after_range:\n",
    "    for t_after in t_after_range:\n",
    "        print('Predicting with',-t_before, 'to', t_after,'ms neural data')\n",
    "        bins_before= int(t_before/bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "        bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "        bins_after= int(t_after/bin_width) #How many bins of neural data after the output are used for decoding\n",
    "        X_cov = get_spikes_with_history(x,bins_before,bins_after,bins_current)\n",
    "        X_flat = X_cov.reshape(X_cov.shape[0],(X_cov.shape[1]*X_cov.shape[2]))\n",
    "        print(X_flat.shape)\n",
    "        X_chopped = X_flat[~np.isnan(X_flat).any(axis = 1)]\n",
    "        y_chopped = y[0+bins_before:y.shape[0]-bins_after,:]\n",
    "        m1_multi_R2s[j,k] = mp_multi_fit_lag_r2(X_chopped,y_chopped)\n",
    "        print('R2:',m1_multi_R2s[j,k])\n",
    "        k+=1\n",
    "    j+=1\n",
    "    k=0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(m1_multi_R2s)\n",
    "ax.set_xlabel('Length of lagging info')\n",
    "ax.set_ylabel('Length of leading info')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_after_range)))\n",
    "ax.set_yticks(np.arange(len(t_before_range)))\n",
    "ax.set_xticklabels(labels=t_after_range)\n",
    "ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "ax.set_title('R2 predicting ' + y_field +' with different lagging/leading info')\n",
    "fig.tight_layout()\n",
    "for i in range(len(t_before_range)):\n",
    "    for j in range(len(t_after_range)):\n",
    "        text = ax.text(j, i, str(int(m1_multi_R2s[i, j]*1000)/1000),\n",
    "                        ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + y_field + '_multi_lag.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
