{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Import standard packages###\n",
    "import numpy as np\n",
    "from scipy import io\n",
    "\n",
    "###Import functions for binning data for preprocessing###\n",
    "from Neural_Decoding.preprocessing_funcs import bin_spikes\n",
    "from Neural_Decoding.preprocessing_funcs import bin_output\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from Area2_analysis.multi_area_funcs import smooth_spk, fit_and_predict, sub_and_predict, mp_fit_lag_r2, mp_sub_lag_r2, multi_fit_r2, multi_fit_coef\n",
    "import multiprocessing as mp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from Area2_analysis.lr_funcs import nans, angle_between\n",
    "from Neural_Decoding.preprocessing_funcs import get_spikes_with_history\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foldername = \"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "# filename = foldername + \"s1_data_raw.mat\"\n",
    "# s1_data_raw = io.loadmat(filename)\n",
    "\n",
    "# spike_times=s1_data_raw['spike_times']\n",
    "# acc = s1_data_raw['acc']\n",
    "# vel = s1_data_raw['vels']\n",
    "# pos = s1_data_raw['pos']\n",
    "# times = s1_data_raw['vel_times']\n",
    "\n",
    "# #original data has 0.01 s = 10 ms bins \n",
    "# dt = 0.01\n",
    "# t_start = times[0]\n",
    "# t_end = times[-1]\n",
    "\n",
    "# spike_times = np.squeeze(spike_times)\n",
    "# for i in range(spike_times.shape[0]):\n",
    "#     spike_times[i]=np.squeeze(spike_times[i])\n",
    "\n",
    "# neural_data=bin_spikes(spike_times,dt,t_start,t_end)\n",
    "# gauss_width = 40 #in ms\n",
    "# bin_width = dt*1000\n",
    "# smth_40 = smooth_spk(neural_data, gauss_width, bin_width)\n",
    "# smth_20 = smooth_spk(neural_data, 20, bin_width)\n",
    "\n",
    "# accs_binned=bin_output(acc,times,dt,t_start,t_end)\n",
    "# vels_binned=bin_output(vel,times,dt,t_start,t_end)\n",
    "# pos_binned=bin_output(pos,times,dt,t_start,t_end)\n",
    "\n",
    "# with open(foldername+'proc_data_s1.pickle','wb') as f:\n",
    "#     pickle.dump([smth_40,smth_20,accs_binned,vels_binned, pos_binned],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = \"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "filename = foldername + \"s1_data_raw.mat\"\n",
    "s1_data_raw = io.loadmat(filename)\n",
    "\n",
    "spike_times=s1_data_raw['spike_times']\n",
    "acc = s1_data_raw['acc']\n",
    "vel = s1_data_raw['vels']\n",
    "pos = s1_data_raw['pos']\n",
    "times = s1_data_raw['vel_times']\n",
    "\n",
    "#original data has 0.01 s = 10 ms bins \n",
    "dt = 0.02 #20ms bins\n",
    "t_start = times[0]\n",
    "t_end = times[-1]\n",
    "\n",
    "spike_times = np.squeeze(spike_times)\n",
    "for i in range(spike_times.shape[0]):\n",
    "    spike_times[i]=np.squeeze(spike_times[i])\n",
    "\n",
    "neural_data_20=bin_spikes(spike_times,dt,t_start,t_end)\n",
    "accs_20_binned=bin_output(acc,times,dt,t_start,t_end)\n",
    "vels_20_binned=bin_output(vel,times,dt,t_start,t_end)\n",
    "pos_20_binned=bin_output(pos,times,dt,t_start,t_end)\n",
    "\n",
    "with open(foldername+'proc_20_data_s1.pickle','wb') as f:\n",
    "    pickle.dump([neural_data_20,accs_20_binned,vels_20_binned,pos_20_binned],f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder=\"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "\n",
    "# with open(folder+'proc_20_data_s1.pickle','rb') as f:\n",
    "#     neural_data_20,accs_20_binned,vels_20_binned, pos_20_binned =pickle.load(f,encoding='latin1')\n",
    "# print(neural_data_20.shape)\n",
    "# print(accs_20_binned.shape)\n",
    "# print(vels_20_binned.shape)\n",
    "# print(pos_20_binned.shape)\n",
    "\n",
    "# n_neurons = neural_data_20.shape[1]\n",
    "\n",
    "# n_dims = 20\n",
    "# if not np.isnan(neural_data_20).any():\n",
    "#     scaler = StandardScaler()\n",
    "#     X = scaler.fit_transform(neural_data_20)\n",
    "#     pca = PCA(n_components=n_dims,random_state = 42)\n",
    "#     smth_20_pca = pca.fit_transform(X)\n",
    "#     print(smth_20_pca.shape)\n",
    "#     print('PCA total var explained:',sum(pca.explained_variance_ratio_))\n",
    "# s1_20_pca = smth_20_pca\n",
    "\n",
    "folder=\"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "\n",
    "with open(folder+'proc_data_s1.pickle','rb') as f:\n",
    "    s1_smth_40, s1_smth_20, s1_accs_binned, s1_vels_binned, s1_pos_binned=pickle.load(f,encoding='latin1')\n",
    "print(s1_smth_40.shape)\n",
    "print(s1_smth_20.shape)\n",
    "print(s1_accs_binned.shape)\n",
    "print(s1_vels_binned.shape)\n",
    "\n",
    "n_neurons = s1_smth_20.shape[1]\n",
    "\n",
    "n_dims = 20\n",
    "if not np.isnan(s1_smth_40).any():\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(s1_smth_40)\n",
    "    pca = PCA(n_components=n_dims,random_state = 42)\n",
    "    smth_40_pca = pca.fit_transform(X)\n",
    "    print(smth_40_pca.shape)\n",
    "    print('PCA total var explained:',sum(pca.explained_variance_ratio_))\n",
    "s1_40_pca = smth_40_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Area2_analysis.lr_funcs import comp_cc\n",
    "acc_array = s1_accs_binned.reshape(1, -1, 2)\n",
    "print(acc_array.shape)\n",
    "maxTimeLag = 600\n",
    "binSize = 10\n",
    "numBin = acc_array.shape[1]\n",
    "x1 = acc_array[:,:,0]\n",
    "x2 = acc_array[:,:,0]\n",
    "ac_x = comp_cc(x1,x2,maxTimeLag,binSize,numBin)\n",
    "\n",
    "x1 = acc_array[:,:,1]\n",
    "x2 = acc_array[:,:,1]\n",
    "ac_y = comp_cc(x1,x2,maxTimeLag,binSize,numBin)\n",
    "\n",
    "time_axis = np.arange(0, maxTimeLag, binSize)\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.plot(time_axis,ac_x/ac_x[0],color = 'green', label = 'x-acc')\n",
    "ax.plot(time_axis,ac_y/ac_y[0],color = 'blue', label = 'y-acc')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time lag (ms)\")\n",
    "plt.ylabel(\"Normalized autocorrelation\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_autocorrelation_acc.pdf',dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_field = 'PCA'\n",
    "y_field = 'hand_vel'\n",
    "\n",
    "if x_field == 'neurons':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/neurons/S1/\"\n",
    "    x = s1_smth_40\n",
    "if x_field == 'PCA':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/PCA/S1/\"\n",
    "    x = s1_40_pca\n",
    "if y_field == 'hand_vel':\n",
    "    y = s1_vels_binned\n",
    "if y_field == 'hand_acc':\n",
    "    y = s1_accs_binned\n",
    "if y_field == 'hand_pos':\n",
    "    y = s1_pos_binned\n",
    "\n",
    "lag_axis = np.arange(-300,300,20)\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "s1_r2_array = [pool.starmap(mp_fit_lag_r2, [(x,y,lag,10) for lag in lag_axis])][0]\n",
    "pool.close()\n",
    "\n",
    "idx_max = np.argmax(s1_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "time_\n",
    "_, weights, _ = fit_and_predict(x,y,time_max,bin_size=10)\n",
    "#subtract projection on primary decoding dimensions (at time with max R2)\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "s1_sub_r2_array = [pool.starmap(mp_sub_lag_r2, [(x,y,lag,10,weights) for lag in lag_axis])][0]\n",
    "pool.close()\n",
    "\n",
    "\n",
    "\n",
    "# x = s1_20_pca\n",
    "# y = accs_20_binned\n",
    "# lag_axis = np.arange(-300,300,20)\n",
    "# pool = mp.Pool(mp.cpu_count())\n",
    "# s1_r2_array = [pool.starmap(mp_fit_lag_r2, [(x,y,lag,20) for lag in lag_axis])][0]\n",
    "# pool.close()\n",
    "\n",
    "# idx_max = np.argmax(s1_r2_array)\n",
    "# time_max = lag_axis[idx_max]\n",
    "# _, weights, _ = fit_and_predict(x,y,time_max,bin_size=10)\n",
    "# #subtract projection on primary decoding dimensions (at time with max R2)\n",
    "# pool = mp.Pool(mp.cpu_count())\n",
    "# s1_sub_r2_array = [pool.starmap(mp_sub_lag_r2, [(x,y,lag,20,weights) for lag in lag_axis])][0]\n",
    "# pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lag_axis, s1_r2_array)\n",
    "# plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.title('R2 score predicting velocity' )\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + y_field +'_0.png', dpi = 'figure')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(lag_axis,s1_sub_r2_array)\n",
    "plt.title('R2 score projecting out #1 t_max dim')\n",
    "idx_max = np.argmax(s1_sub_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + y_field +'_1.png', dpi = 'figure')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Area2_analysis.lr_funcs import nans\n",
    "x = s1_20_pca\n",
    "y = vels_20_binned\n",
    "r2_array = nans([len(lag_axis)])\n",
    "coef_array = nans([len(lag_axis),2,n_dims])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    r2, coef,_ = fit_and_predict(x,y,lag,bin_size=10)\n",
    "    r2_array[i] = r2\n",
    "    coef_array[i,:,:] = coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_max_pos = np.argwhere(r2_array == np.max(r2_array[np.argwhere(lag_axis==0)[0,0]:]))[0,0]\n",
    "idx_max_neg = np.argwhere(r2_array == np.max(r2_array[:np.argwhere(lag_axis==0)[0,0]]))[0,0]\n",
    "\n",
    "idx_max_pos = np.argwhere(lag_axis==40)[0,0]\n",
    "idx_max_neg = np.argwhere(lag_axis==-60)[0,0]\n",
    "\n",
    "ang_to_max_x = nans([len(lag_axis)])\n",
    "ang_to_max_y = nans([len(lag_axis)])\n",
    "for i in range(0, len(coef_array)):\n",
    "    ang_to_max_x[i] = math.degrees(angle_between(coef_array[i,0,:],coef_array[idx_max_neg,0,:]))\n",
    "    ang_to_max_y[i] = math.degrees(angle_between(coef_array[i,1,:],coef_array[idx_max_neg,1,:]))\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "# plt.ylim([-5, 130])\n",
    "plt.xlim([-310, 310])\n",
    "plt.scatter(lag_axis, ang_to_max_x,label = 'x-axis',color = 'green')\n",
    "plt.scatter(lag_axis, ang_to_max_y,label = 'y-axis',color = 'blue')\n",
    "plt.legend()\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('Angle (degrees)')\n",
    "mean = np.mean([ang_to_max_x[idx_max_pos], ang_to_max_y[idx_max_pos]])\n",
    "print(mean)\n",
    "plt.vlines(lag_axis[idx_max_pos],-5, mean, color = 'k',linestyle=\"dashed\")\n",
    "plt.hlines(mean, -310, lag_axis[idx_max_pos], color = 'k',linestyle=\"dashed\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + label + str(0) +'_angle.pdf', dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=\"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "\n",
    "with open(folder+'proc_50_data_s1.pickle','rb') as f:\n",
    "    s1_neural_data_50,s1_accs_50_binned,s1_vels_50_binned,s1_pos_50_binned=pickle.load(f,encoding='latin1')\n",
    "print(s1_neural_data_50.shape)\n",
    "print(s1_accs_50_binned.shape)\n",
    "print(s1_vels_50_binned.shape)\n",
    "print(s1_pos_50_binned.shape)\n",
    "\n",
    "bin_width = 50\n",
    "\n",
    "n_dims = 20\n",
    "if not np.isnan(s1_neural_data_50).any():\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(s1_neural_data_50)\n",
    "    pca = PCA(n_components=n_dims,random_state = 42)\n",
    "    neural_data_50_pca = pca.fit_transform(X)\n",
    "    print(neural_data_50_pca.shape)\n",
    "    print('PCA total var explained:',sum(pca.explained_variance_ratio_))\n",
    "s1_neural_data_50_pca = neural_data_50_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_field = 'PCA'\n",
    "y_field = 'hand_acc'\n",
    "\n",
    "if x_field == 'neurons':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/neurons/S1/\"\n",
    "    x = s1_neural_data_50\n",
    "if x_field == 'PCA':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/PCA/S1/\"\n",
    "    x = s1_neural_data_50_pca\n",
    "if y_field == 'hand_vel':\n",
    "    y = s1_vels_50_binned\n",
    "if y_field == 'hand_acc':\n",
    "    y = s1_accs_50_binned\n",
    "\n",
    "t_before_range = range(0,301,50)\n",
    "t_after_range = range(0,301,50)\n",
    "s1_multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "j,k = 0,0\n",
    "for t_before in t_after_range:\n",
    "    for t_after in t_after_range:\n",
    "        print('Predicting with',-t_before, 'to', t_after,'ms neural data')\n",
    "        bins_before= int(t_before/bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "        bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "        bins_after= int(t_after/bin_width) #How many bins of neural data after the output are used for decoding\n",
    "        X_cov = get_spikes_with_history(x,bins_before,bins_after,bins_current)\n",
    "        X_flat = X_cov.reshape(X_cov.shape[0],(X_cov.shape[1]*X_cov.shape[2]))\n",
    "        print(X_flat.shape)\n",
    "        X_chopped = X_flat[~np.isnan(X_flat).any(axis = 1)]\n",
    "        y_chopped = y[0+bins_before:y.shape[0]-bins_after,:]\n",
    "        s1_multi_R2s[j,k] = multi_fit_r2(X_chopped,y_chopped)\n",
    "        print('R2:',s1_multi_R2s[j,k])\n",
    "        k+=1\n",
    "    j+=1\n",
    "    k=0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(s1_multi_R2s)\n",
    "ax.set_xlabel('Length of lagging info')\n",
    "ax.set_ylabel('Length of leading info')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_after_range)))\n",
    "ax.set_yticks(np.arange(len(t_before_range)))\n",
    "ax.set_xticklabels(labels=t_after_range)\n",
    "ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "ax.set_title('R2 predicting ' + y_field +' with different lagging/leading info')\n",
    "fig.tight_layout()\n",
    "for i in range(len(t_before_range)):\n",
    "    for j in range(len(t_after_range)):\n",
    "        text = ax.text(j, i, str(int(s1_multi_R2s[i, j]*1000)/1000),\n",
    "                        ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.savefig(figDir + y_field + '_multi_lag.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "t_before = 300\n",
    "t_after = 300\n",
    "dim = n_dims\n",
    "print('Predicting with',-t_before, 'to', t_after,'ms neural data')\n",
    "bins_before= int(t_before/bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "bins_after= int(t_after/bin_width) #How many bins of neural data after the output are used for decoding\n",
    "X_cov = get_spikes_with_history(x,bins_before,bins_after,bins_current)\n",
    "X_flat = X_cov.reshape(X_cov.shape[0],(X_cov.shape[1]*X_cov.shape[2]))\n",
    "print(X_flat.shape)\n",
    "X_chopped = X_flat[~np.isnan(X_flat).any(axis = 1)]\n",
    "y_chopped = y[0+bins_before:y.shape[0]-bins_after,:]\n",
    "coef_X = multi_fit_coef(X_chopped,y_chopped)\n",
    "\n",
    "t_label = np.arange(-300,301,50)\n",
    "n_weights = len(t_label)\n",
    "coef_X_reshaped = coef_X[0,:].reshape(n_weights,dim)\n",
    "angDist_array = nans([n_weights,n_weights])\n",
    "for i in range(n_weights):\n",
    "    for j in range(n_weights):\n",
    "        angDist_array[i,j] = math.degrees(angle_between(coef_X_reshaped[i,:],coef_X_reshaped[j,:]))\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "im = ax.imshow(angDist_array)\n",
    "ax.set_xlabel('Bin time (ms)')\n",
    "ax.set_ylabel('Bin time (ms)')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_label)))\n",
    "ax.set_yticks(np.arange(len(t_label)))\n",
    "ax.set_xticklabels(labels=t_label)\n",
    "ax.set_yticklabels(labels=t_label)\n",
    "\n",
    "ax.set_title(\"Angle between weight vectors at time points\")\n",
    "fig.tight_layout()\n",
    "\n",
    "for i in range(len(t_label)):\n",
    "    for j in range(len(t_label)):\n",
    "        text = ax.text(j, i, str(int(angDist_array[i, j])),\n",
    "                        ha=\"center\", va=\"center\", color=\"w\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + y_field + '_multi_lag_angles.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foldername = \"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "# filename = foldername + \"m1_data_raw.mat\"\n",
    "# m1_data_raw = io.loadmat(filename)\n",
    "\n",
    "# spike_times=m1_data_raw['spike_times'][:70,:] #only first 70 are M1 neurons\n",
    "# acc = m1_data_raw['acc']\n",
    "# vel = m1_data_raw['vels']\n",
    "# times = m1_data_raw['vel_times']\n",
    "\n",
    "# #original data has 0.001 s = 1 ms bins \n",
    "# dt = 0.01\n",
    "# t_start = times[0]\n",
    "# t_end = times[-1]\n",
    "\n",
    "# spike_times = np.squeeze(spike_times)\n",
    "# for i in range(spike_times.shape[0]):\n",
    "#     spike_times[i]=np.squeeze(spike_times[i])\n",
    "\n",
    "# neural_data=bin_spikes(spike_times,dt,t_start,t_end)\n",
    "# gauss_width = 40 #in ms\n",
    "# bin_width = dt*1000\n",
    "# smth_40 = smooth_spk(neural_data, gauss_width, bin_width)\n",
    "# smth_20 = smooth_spk(neural_data, 20, bin_width)\n",
    "\n",
    "# accs_binned=bin_output(acc,times,dt,t_start,t_end)\n",
    "# vels_binned=bin_output(vel,times,dt,t_start,t_end)\n",
    "\n",
    "# with open(foldername+'proc_data_m1.pickle','wb') as f:\n",
    "#     pickle.dump([smth_40, smth_20,accs_binned,vels_binned],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foldername = \"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "# filename = foldername + \"m1_data_raw.mat\"\n",
    "# m1_data_raw = io.loadmat(filename)\n",
    "\n",
    "# spike_times=m1_data_raw['spike_times'][:70,:]\n",
    "# acc = m1_data_raw['acc']\n",
    "# vel = m1_data_raw['vels']\n",
    "# times = m1_data_raw['vel_times']\n",
    "\n",
    "# #original data has 0.001 s = 1 ms bins \n",
    "# dt = 0.05 #50ms bins\n",
    "# t_start = times[0]\n",
    "# t_end = times[-1]\n",
    "\n",
    "# spike_times = np.squeeze(spike_times)\n",
    "# for i in range(spike_times.shape[0]):\n",
    "#     spike_times[i]=np.squeeze(spike_times[i])\n",
    "\n",
    "# neural_data_50=bin_spikes(spike_times,dt,t_start,t_end)\n",
    "# accs_50_binned=bin_output(acc,times,dt,t_start,t_end)\n",
    "# vels_50_binned=bin_output(vel,times,dt,t_start,t_end)\n",
    "\n",
    "# with open(foldername+'proc_50_data_m1.pickle','wb') as f:\n",
    "#     pickle.dump([neural_data_50,accs_50_binned,vels_50_binned],f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=\"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "\n",
    "with open(folder+'proc_data_m1.pickle','rb') as f:\n",
    "    m1_smth_40,m1_smth_20,m1_accs_binned, m1_vels_binned=pickle.load(f,encoding='latin1')\n",
    "print(m1_smth_40.shape)\n",
    "print(m1_smth_20.shape)\n",
    "print(m1_accs_binned.shape)\n",
    "print(m1_vels_binned.shape)\n",
    "\n",
    "n_neurons = m1_smth_20.shape[1]\n",
    "\n",
    "n_dims = 20\n",
    "if not np.isnan(m1_smth_40).any():\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(m1_smth_40)\n",
    "    pca = PCA(n_components=n_dims,random_state = 42)\n",
    "    smth_40_pca = pca.fit_transform(X)\n",
    "    print(smth_40_pca.shape)\n",
    "    print('PCA total var explained:',sum(pca.explained_variance_ratio_))\n",
    "m1_40_pca = smth_40_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_field = 'PCA'\n",
    "y_field = 'hand_vel'\n",
    "\n",
    "if x_field == 'neurons':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/neurons/M1/\"\n",
    "    x = m1_smth_40\n",
    "if x_field == 'PCA':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/PCA/M1/\"\n",
    "    x = m1_40_pca\n",
    "if y_field == 'hand_vel':\n",
    "    y = m1_vels_binned\n",
    "if y_field == 'hand_acc':\n",
    "    y = m1_accs_binned\n",
    "\n",
    "lag_axis = np.arange(-300,300,20)\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "m1_r2_array = [pool.starmap(mp_fit_lag_r2, [(x,y,lag,10) for lag in lag_axis])][0]\n",
    "pool.close()\n",
    "\n",
    "idx_max = np.argmax(m1_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "plt.plot(lag_axis, m1_r2_array)\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.title('R2 score predicting ' + y_field )\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + y_field +'_0.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "_, weights, _ = fit_and_predict(x,y,time_max,bin_size=10)\n",
    "#subtract projection on primary decoding dimensions (at time with max R2)\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "m1_sub_r2_array = [pool.starmap(mp_sub_lag_r2, [(x,y,lag,10,weights) for lag in lag_axis])][0]\n",
    "pool.close()\n",
    "plt.plot(lag_axis,m1_sub_r2_array)\n",
    "plt.title('R2 score projecting out #1 t_max dim')\n",
    "idx_max = np.argmax(m1_sub_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + y_field +'_1.png', dpi = 'figure')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=\"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "\n",
    "with open(folder+'proc_50_data_m1.pickle','rb') as f:\n",
    "    m1_neural_data_50,m1_accs_50_binned,m1_vels_50_binned=pickle.load(f,encoding='latin1')\n",
    "print(m1_neural_data_50.shape)\n",
    "print(m1_accs_50_binned.shape)\n",
    "print(m1_vels_50_binned.shape)\n",
    "\n",
    "bin_width = 50\n",
    "\n",
    "n_dims = 20\n",
    "if not np.isnan(m1_neural_data_50).any():\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(m1_neural_data_50)\n",
    "    pca = PCA(n_components=n_dims,random_state = 42)\n",
    "    neural_data_50_pca = pca.fit_transform(X)\n",
    "    print(neural_data_50_pca.shape)\n",
    "    print('PCA total var explained:',sum(pca.explained_variance_ratio_))\n",
    "m1_neural_data_50_pca = neural_data_50_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_field = 'PCA'\n",
    "y_field = 'hand_vel'\n",
    "\n",
    "if x_field == 'neurons':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/neurons/M1/\"\n",
    "    x = m1_neural_data_50\n",
    "if x_field == 'PCA':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/PCA/M1/\"\n",
    "    x = m1_neural_data_50_pca\n",
    "if y_field == 'hand_vel':\n",
    "    y = m1_vels_50_binned\n",
    "if y_field == 'hand_acc':\n",
    "    y = m1_accs_50_binned\n",
    "\n",
    "t_before_range = range(0,301,50)\n",
    "t_after_range = range(0,301,50)\n",
    "m1_multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "j,k = 0,0\n",
    "for t_before in t_after_range:\n",
    "    for t_after in t_after_range:\n",
    "        print('Predicting with',-t_before, 'to', t_after,'ms neural data')\n",
    "        bins_before= int(t_before/bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "        bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "        bins_after= int(t_after/bin_width) #How many bins of neural data after the output are used for decoding\n",
    "        X_cov = get_spikes_with_history(x,bins_before,bins_after,bins_current)\n",
    "        X_flat = X_cov.reshape(X_cov.shape[0],(X_cov.shape[1]*X_cov.shape[2]))\n",
    "        print(X_flat.shape)\n",
    "        X_chopped = X_flat[~np.isnan(X_flat).any(axis = 1)]\n",
    "        y_chopped = y[0+bins_before:y.shape[0]-bins_after,:]\n",
    "        m1_multi_R2s[j,k] = multi_fit_r2(X_chopped,y_chopped)\n",
    "        print('R2:',m1_multi_R2s[j,k])\n",
    "        k+=1\n",
    "    j+=1\n",
    "    k=0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(m1_multi_R2s)\n",
    "ax.set_xlabel('Length of lagging info')\n",
    "ax.set_ylabel('Length of leading info')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_after_range)))\n",
    "ax.set_yticks(np.arange(len(t_before_range)))\n",
    "ax.set_xticklabels(labels=t_after_range)\n",
    "ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "ax.set_title('R2 predicting ' + y_field +' with different lagging/leading info')\n",
    "fig.tight_layout()\n",
    "for i in range(len(t_before_range)):\n",
    "    for j in range(len(t_after_range)):\n",
    "        text = ax.text(j, i, str(int(m1_multi_R2s[i, j]*1000)/1000),\n",
    "                        ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + y_field + '_multi_lag.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foldername = \"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "# filename = foldername + \"m1_data_raw.mat\"\n",
    "# pmd_data_raw = io.loadmat(filename)\n",
    "\n",
    "# spike_times=pmd_data_raw['spike_times'][70:,:] #neurons after 70 are PMd neurons\n",
    "# acc = pmd_data_raw['acc']\n",
    "# vel = pmd_data_raw['vels']\n",
    "# times = pmd_data_raw['vel_times']\n",
    "\n",
    "# #original data has 0.001 s = 1 ms bins \n",
    "# dt = 0.01\n",
    "# t_start = times[0]\n",
    "# t_end = times[-1]\n",
    "\n",
    "# spike_times = np.squeeze(spike_times)\n",
    "# for i in range(spike_times.shape[0]):\n",
    "#     spike_times[i]=np.squeeze(spike_times[i])\n",
    "\n",
    "# neural_data=bin_spikes(spike_times,dt,t_start,t_end)\n",
    "# gauss_width = 40 #in ms\n",
    "# bin_width = dt*1000\n",
    "# smth_40 = smooth_spk(neural_data, gauss_width, bin_width)\n",
    "# smth_20 = smooth_spk(neural_data, 20, bin_width)\n",
    "\n",
    "# accs_binned=bin_output(acc,times,dt,t_start,t_end)\n",
    "# vels_binned=bin_output(vel,times,dt,t_start,t_end)\n",
    "\n",
    "# with open(foldername+'proc_data_pmd.pickle','wb') as f:\n",
    "#     pickle.dump([smth_40, smth_20,accs_binned,vels_binned],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# foldername = \"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "# filename = foldername + \"m1_data_raw.mat\"\n",
    "# pmd_data_raw = io.loadmat(filename)\n",
    "\n",
    "# spike_times=pmd_data_raw['spike_times'][70:,:]\n",
    "# acc = pmd_data_raw['acc']\n",
    "# vel = pmd_data_raw['vels']\n",
    "# times = pmd_data_raw['vel_times']\n",
    "\n",
    "# #original data has 0.001 s = 1 ms bins \n",
    "# dt = 0.05 #50ms bins\n",
    "# t_start = times[0]\n",
    "# t_end = times[-1]\n",
    "\n",
    "# spike_times = np.squeeze(spike_times)\n",
    "# for i in range(spike_times.shape[0]):\n",
    "#     spike_times[i]=np.squeeze(spike_times[i])\n",
    "\n",
    "# neural_data_50=bin_spikes(spike_times,dt,t_start,t_end)\n",
    "# accs_50_binned=bin_output(acc,times,dt,t_start,t_end)\n",
    "# vels_50_binned=bin_output(vel,times,dt,t_start,t_end)\n",
    "\n",
    "# with open(foldername+'proc_50_data_pmd.pickle','wb') as f:\n",
    "#     pickle.dump([neural_data_50,accs_50_binned,vels_50_binned],f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=\"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "\n",
    "with open(folder+'proc_data_pmd.pickle','rb') as f:\n",
    "    pmd_smth_40,pmd_smth_20,pmd_accs_binned, pmd_vels_binned=pickle.load(f,encoding='latin1')\n",
    "print(pmd_smth_40.shape)\n",
    "print(pmd_smth_20.shape)\n",
    "print(pmd_accs_binned.shape)\n",
    "print(pmd_vels_binned.shape)\n",
    "\n",
    "n_neurons = pmd_smth_20.shape[1]\n",
    "\n",
    "n_dims = 20\n",
    "if not np.isnan(pmd_smth_40).any():\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(pmd_smth_40)\n",
    "    pca = PCA(n_components=n_dims,random_state = 42)\n",
    "    smth_40_pca = pca.fit_transform(X)\n",
    "    print(smth_40_pca.shape)\n",
    "    print('PCA total var explained:',sum(pca.explained_variance_ratio_))\n",
    "pmd_40_pca = smth_40_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_field = 'PCA'\n",
    "y_field = 'hand_vel'\n",
    "\n",
    "if x_field == 'neurons':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/neurons/PMd/\"\n",
    "    x = pmd_smth_40\n",
    "if x_field == 'PCA':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/PCA/PMd/\"\n",
    "    x = pmd_40_pca\n",
    "if y_field == 'hand_vel':\n",
    "    y = pmd_vels_binned\n",
    "if y_field == 'hand_acc':\n",
    "    y = pmd_accs_binned\n",
    "\n",
    "lag_axis = np.arange(-300,300,20)\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "pmd_r2_array = [pool.starmap(mp_fit_lag_r2, [(x,y,lag,10) for lag in lag_axis])][0]\n",
    "pool.close()\n",
    "\n",
    "idx_max = np.argmax(pmd_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "plt.plot(lag_axis, pmd_r2_array)\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.title('R2 score predicting ' + y_field )\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + y_field +'_0.png', dpi = 'figure')\n",
    "plt.close()\n",
    "\n",
    "_, weights, _ = fit_and_predict(x,y,time_max,bin_size=10)\n",
    "#subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "pmd_sub_r2_array = [pool.starmap(mp_sub_lag_r2, [(x,y,lag,10,weights) for lag in lag_axis])][0]\n",
    "pool.close()\n",
    "plt.plot(lag_axis,pmd_sub_r2_array)\n",
    "plt.title('R2 score projecting out #1 t_max dim')\n",
    "idx_max = np.argmax(pmd_sub_r2_array)\n",
    "time_max = lag_axis[idx_max]\n",
    "plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "plt.legend()\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + y_field +'_1.png', dpi = 'figure')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder=\"/Users/sherryan/area2_population_analysis/multi_area/\"\n",
    "\n",
    "with open(folder+'proc_50_data_pmd.pickle','rb') as f:\n",
    "    pmd_neural_data_50,pmd_accs_50_binned,pmd_vels_50_binned=pickle.load(f,encoding='latin1')\n",
    "print(pmd_neural_data_50.shape)\n",
    "print(pmd_accs_50_binned.shape)\n",
    "print(pmd_vels_50_binned.shape)\n",
    "\n",
    "bin_width = 50\n",
    "\n",
    "n_dims = 20\n",
    "if not np.isnan(pmd_neural_data_50).any():\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(pmd_neural_data_50)\n",
    "    pca = PCA(n_components=n_dims,random_state = 42)\n",
    "    neural_data_50_pca = pca.fit_transform(X)\n",
    "    print(neural_data_50_pca.shape)\n",
    "    print('PCA total var explained:',sum(pca.explained_variance_ratio_))\n",
    "pmd_neural_data_50_pca = neural_data_50_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_field = 'PCA'\n",
    "y_field = 'hand_acc'\n",
    "\n",
    "if x_field == 'neurons':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/neurons/PMd/\"\n",
    "    x = pmd_neural_data_50\n",
    "if x_field == 'PCA':\n",
    "    figDir = \"/Users/sherryan/area2_population_analysis/figures/multi/PCA/PMd/\"\n",
    "    x = pmd_neural_data_50_pca\n",
    "if y_field == 'hand_vel':\n",
    "    y = pmd_vels_50_binned\n",
    "if y_field == 'hand_acc':\n",
    "    y = pmd_accs_50_binned\n",
    "\n",
    "t_before_range = range(0,301,50)\n",
    "t_after_range = range(0,301,50)\n",
    "pmd_multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "j,k = 0,0\n",
    "for t_before in t_after_range:\n",
    "    for t_after in t_after_range:\n",
    "        print('Predicting with',-t_before, 'to', t_after,'ms neural data')\n",
    "        bins_before= int(t_before/bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "        bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "        bins_after= int(t_after/bin_width) #How many bins of neural data after the output are used for decoding\n",
    "        X_cov = get_spikes_with_history(x,bins_before,bins_after,bins_current)\n",
    "        X_flat = X_cov.reshape(X_cov.shape[0],(X_cov.shape[1]*X_cov.shape[2]))\n",
    "        print(X_flat.shape)\n",
    "        X_chopped = X_flat[~np.isnan(X_flat).any(axis = 1)]\n",
    "        y_chopped = y[0+bins_before:y.shape[0]-bins_after,:]\n",
    "        pmd_multi_R2s[j,k] = multi_fit_r2(X_chopped,y_chopped)\n",
    "        print('R2:',pmd_multi_R2s[j,k])\n",
    "        k+=1\n",
    "    j+=1\n",
    "    k=0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(pmd_multi_R2s)\n",
    "ax.set_xlabel('Length of lagging info')\n",
    "ax.set_ylabel('Length of leading info')\n",
    "\n",
    "ax.set_xticks(np.arange(len(t_after_range)))\n",
    "ax.set_yticks(np.arange(len(t_before_range)))\n",
    "ax.set_xticklabels(labels=t_after_range)\n",
    "ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "ax.set_title('R2 predicting ' + y_field +' with different lagging/leading info')\n",
    "fig.tight_layout()\n",
    "for i in range(len(t_before_range)):\n",
    "    for j in range(len(t_after_range)):\n",
    "        text = ax.text(j, i, str(int(pmd_multi_R2s[i, j]*1000)/1000),\n",
    "                        ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + y_field + '_multi_lag.png', dpi = 'figure')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
