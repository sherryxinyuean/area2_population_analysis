{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc4476f",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "import os\n",
    "foldername = \"~/area2_population_analysis/s1-kinematics/actpas_NWB/\"\n",
    "foldername = os.path.expanduser(foldername)\n",
    "# monkey = \"Han_20171207\"\n",
    "# monkey = 'Duncan_20190710'\n",
    "# monkey = \"Chips_20170913\"\n",
    "# monkey = \"Lando_20170731\"\n",
    "\n",
    "# monkey = \"Han_20171201\"\n",
    "# monkey = \"Han_20171204\"\n",
    "# monkey = 'Duncan_20191016'\n",
    "# monkey = 'Duncan_20191106'âˆ‚\n",
    "\n",
    "monkey = \"Lando_20170803\"\n",
    "\n",
    "filename = foldername + monkey + \"_COactpas_TD_offset6.nwb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca741cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlb_tools.nwb_interface import NWBDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "from sklearn.linear_model import Ridge, LinearRegression, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, StratifiedShuffleSplit\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "from scipy.linalg import orth\n",
    "\n",
    "from Neural_Decoding.preprocessing_funcs import get_spikes_with_history\n",
    "from Area2_analysis.lr_funcs import process_train_test, gaussian_filter1d_oneside, gaussian_filter1d_twoside, comp_cc, xcorr, r2_score\n",
    "from Area2_analysis.lr_funcs import get_sses_pred, get_sses_mean, nans\n",
    "# from Area2_analysis.lr_funcs import fit_and_predict, sub_and_predict, pred_with_new_weights\n",
    "# from Area2_analysis.lr_funcs import fit_and_predict_lasso, sub_and_predict_lasso, \n",
    "from Area2_analysis.lr_funcs import fit_and_predict_MC, calc_proj, principal_angles, angle_between\n",
    "figDir = '/Users/sherryan/Desktop/paper/'\n",
    "matplotlib.rc('font', size=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d56629",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_10ms = NWBDataset(filename, split_heldout=False)\n",
    "\n",
    "dataset_10ms.resample(10) #in 10-ms bin, has to resample first for Duncan\n",
    "bin_width = dataset_10ms.bin_width\n",
    "print(bin_width)\n",
    "\n",
    "dataset_10ms.smooth_spk(40, name='smth_40')\n",
    "n_dims = 20 \n",
    "all_data = np.array(dataset_10ms.data.spikes_smth_40)\n",
    "print(all_data.shape)\n",
    "if not np.isnan(all_data).any():\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(all_data)\n",
    "    pca = PCA(n_components=n_dims,random_state = 42)\n",
    "    PCA_data = pca.fit_transform(X)\n",
    "print(PCA_data.shape)\n",
    "dataset_10ms.add_continuous_data(PCA_data,'PCA_40')\n",
    "print('PCA total var explained:',sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b52c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_10ms\n",
    "trial_info = dataset.trial_info\n",
    "\n",
    "# Basic counts\n",
    "n_trials = trial_info.shape[0]\n",
    "print(n_trials, 'total trials')\n",
    "\n",
    "n_neurons = dataset.data.spikes.shape[1]\n",
    "print(n_neurons, 'neurons')\n",
    "\n",
    "# Masks\n",
    "valid_mask   = (trial_info['split'] != 'none')\n",
    "active_mask  = (trial_info.ctr_hold_bump == 0) & valid_mask\n",
    "passive_mask = (trial_info.ctr_hold_bump == 1) & valid_mask\n",
    "nan_mask     = trial_info.ctr_hold_bump.isna() & valid_mask\n",
    "\n",
    "print(trial_info.loc[valid_mask].shape[0],   'valid trials')\n",
    "print(trial_info.loc[active_mask].shape[0],  'active trials')\n",
    "print(trial_info.loc[passive_mask].shape[0], 'passive trials')\n",
    "print(trial_info.loc[nan_mask].shape[0],     'reach bump trials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2091fc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mask_and_cond_dict(\n",
    "    dataset,\n",
    "    base_mask,                 # e.g. active_mask / passive_mask / nan_mask\n",
    "    align_field,\n",
    "    align_range,\n",
    "    dir_col='cond_dir',\n",
    "    drop_to_four_if_not_full8=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      new_mask: mask with trials removed that are not present in aligned_df OR weird dirs\n",
    "      cond_dict: integer labels, aligned to trial_ids_kept (trial order in aligned_df)\n",
    "      trial_ids_kept: the trial IDs used (same order as cond_dict)\n",
    "    \"\"\"\n",
    "    trial_info = dataset.trial_info\n",
    "\n",
    "    # 1) keep only trials that survive this alignment\n",
    "    df = dataset.make_trial_data(\n",
    "        align_field=align_field,\n",
    "        align_range=align_range,\n",
    "        ignored_trials=~base_mask\n",
    "    )\n",
    "    trial_ids = df['trial_id'].drop_duplicates().to_numpy()\n",
    "\n",
    "    # Update mask to only trials that appear in df\n",
    "    new_mask = base_mask & trial_info['trial_id'].isin(trial_ids)\n",
    "\n",
    "    # 2) compute directions for these trial_ids (in same order)\n",
    "    ti = trial_info.set_index('trial_id') if trial_info.index.name != 'trial_id' else trial_info\n",
    "    dirs = (ti.loc[trial_ids, dir_col] % 360).to_numpy().astype(float)\n",
    "\n",
    "    full_dirs = np.array([0,45,90,135,180,225,270,315], dtype=float)\n",
    "    four_dirs = np.array([0,90,180,270], dtype=float)\n",
    "\n",
    "    # drop weird values not in full_dirs\n",
    "    canon_mask = np.isin(dirs, full_dirs)\n",
    "    trial_ids = trial_ids[canon_mask]\n",
    "    dirs = dirs[canon_mask]\n",
    "\n",
    "    # decide which canonical set to use\n",
    "    unique_dirs = np.sort(np.unique(dirs))\n",
    "    if (set(unique_dirs) == set(full_dirs)) or (not drop_to_four_if_not_full8):\n",
    "        cond_dirs = full_dirs\n",
    "    else:\n",
    "        cond_dirs = np.array([d for d in four_dirs if d in set(unique_dirs)], dtype=float)\n",
    "\n",
    "    # drop trials not in cond_dirs (this removes diagonals for 6-dir monkeys, etc.)\n",
    "    keep = np.isin(dirs, cond_dirs)\n",
    "    trial_ids_kept = trial_ids[keep]\n",
    "    dirs_kept = dirs[keep]\n",
    "\n",
    "    # update mask again to drop those trials globally\n",
    "    new_mask = new_mask & trial_info['trial_id'].isin(trial_ids_kept)\n",
    "\n",
    "    # build cond_dict aligned to trial_ids_kept\n",
    "    dir_to_cond = {d: i for i, d in enumerate(cond_dirs)}\n",
    "    cond_dict = np.array([dir_to_cond[d] for d in dirs_kept], dtype=int)\n",
    "\n",
    "    return new_mask, cond_dict, trial_ids_kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41654edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_10ms\n",
    "trial_info = dataset.trial_info\n",
    "\n",
    "valid_mask   = (trial_info['split'] != 'none')\n",
    "active_mask  = (trial_info.ctr_hold_bump == 0) & valid_mask\n",
    "passive_mask = (trial_info.ctr_hold_bump == 1) & valid_mask\n",
    "nan_mask     = trial_info.ctr_hold_bump.isna() & valid_mask\n",
    "\n",
    "# Build cond_dict that matches *whatever alignment you plan to use later*\n",
    "active_mask,  active_cond_dict,  active_trial_ids  = build_mask_and_cond_dict(\n",
    "    dataset, active_mask,  align_field='move_onset_time',  align_range=(-100, 0), dir_col='cond_dir'\n",
    ")\n",
    "print('active (onset):', len(active_trial_ids), 'trials')\n",
    "print('active_cond_dict_onset length:', len(active_cond_dict))\n",
    "\n",
    "active_mask_offset, active_cond_dict_offset, active_trial_ids_offset = build_mask_and_cond_dict(\n",
    "    dataset, active_mask,  align_field='move_offset_time', align_range=(-100, 0), dir_col='cond_dir'\n",
    ")\n",
    "print('active (offset):', len(active_trial_ids_offset), 'trials')\n",
    "print('active_cond_dict_offset length:', len(active_cond_dict_offset))\n",
    "\n",
    "passive_mask, passive_cond_dict, passive_trial_ids = build_mask_and_cond_dict(\n",
    "    dataset, passive_mask, align_field='move_onset_time',  align_range=(-100, 0), dir_col='cond_dir'\n",
    ")\n",
    "print('passive:', len(passive_trial_ids), 'trials')\n",
    "print('passive_cond_dict length:', len(passive_cond_dict))\n",
    "\n",
    "# counts you said you still need\n",
    "active_n_trials  = len(active_trial_ids)\n",
    "passive_n_trials = len(passive_trial_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756e8923",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_rel, wilcoxon\n",
    "## TODO: corrections for multiple comparisons\n",
    "\n",
    "def df_to_trial_matrix(df, field='spikes', agg='mean'):\n",
    "    \"\"\"\n",
    "    Returns A: [n_trials, n_time]\n",
    "    agg: 'mean' -> mean over neurons, 'sum' -> sum over neurons\n",
    "    \"\"\"\n",
    "    mats = []\n",
    "    for _, trial in df.groupby('trial_id'):\n",
    "        X = getattr(trial, field).to_numpy()  # [n_time, n_neurons]\n",
    "        mats.append(X.mean(axis=1) if agg=='mean' else X.sum(axis=1))\n",
    "    return np.vstack(mats)\n",
    "\n",
    "def window_mean_matrix(A, x_axis, window):\n",
    "    idx = (x_axis >= window[0]) & (x_axis <= window[1])\n",
    "    return A[:, idx].mean(axis=1)\n",
    "\n",
    "# ---- config ----\n",
    "plot_range = (-1000, 500)\n",
    "x_axis = np.arange(plot_range[0], plot_range[1], dataset_10ms.bin_width)\n",
    "\n",
    "active_df = dataset_10ms.make_trial_data(\n",
    "    align_field='move_onset_time', align_range=plot_range,\n",
    "    ignored_trials=~active_mask, allow_overlap=True\n",
    ")\n",
    "\n",
    "A = df_to_trial_matrix(active_df, field='spikes', agg='mean')  # [n_trials, n_time]\n",
    "\n",
    "baseline_window = (-250, -150)\n",
    "baseline_vals = window_mean_matrix(A, x_axis, baseline_window)\n",
    "\n",
    "window_size = 20\n",
    "step_size = 10\n",
    "test_centers = np.arange(-150, 0, step_size)\n",
    "\n",
    "p_ttest, p_wilcoxon = [], []\n",
    "for c in test_centers:\n",
    "    w = (c - window_size/2, c + window_size/2)\n",
    "    test_vals = window_mean_matrix(A, x_axis, w)\n",
    "\n",
    "    # paired tests\n",
    "    p_ttest.append(ttest_rel(test_vals, baseline_vals, nan_policy='omit').pvalue)\n",
    "\n",
    "    # wilcoxon \n",
    "    diff = test_vals - baseline_vals\n",
    "    if np.allclose(diff, 0):\n",
    "        p_wilcoxon.append(1.0)\n",
    "    else:\n",
    "        p_wilcoxon.append(wilcoxon(test_vals, baseline_vals).pvalue)\n",
    "\n",
    "# plot\n",
    "plt.plot(test_centers, p_wilcoxon, marker='o', label='wilcoxon')\n",
    "plt.plot(test_centers, p_ttest, marker='o', label='ttest')\n",
    "plt.axhline(0.05, color='red', linestyle='--')\n",
    "plt.xlabel('Time relative to movement onset (ms)')\n",
    "plt.ylabel('p-value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psth_from_df(df, x_axis, bin_width_ms, n_neurons, field='spikes'):\n",
    "    A = df_to_trial_matrix(df, field=field, agg='sum')  # [n_trials, n_time] counts per bin (summed neurons)\n",
    "    fr = A / bin_width_ms * 1000.0 / n_neurons          # spikes/s/neuron\n",
    "    mean = fr.mean(axis=0)\n",
    "    sem  = fr.std(axis=0, ddof=1) / np.sqrt(fr.shape[0])\n",
    "    return mean, sem, fr\n",
    "\n",
    "plot_range = (-300, 600)\n",
    "x_axis = np.arange(plot_range[0], plot_range[1], dataset_10ms.bin_width)\n",
    "\n",
    "active_df = dataset_10ms.make_trial_data(\n",
    "    align_field='move_onset_time', align_range=plot_range,\n",
    "    ignored_trials=~active_mask, allow_overlap=True\n",
    ")\n",
    "passive_df = dataset_10ms.make_trial_data(\n",
    "    align_field='move_onset_time', align_range=plot_range,\n",
    "    ignored_trials=~passive_mask, allow_overlap=True\n",
    ")\n",
    "\n",
    "active_mean, active_sem, _ = psth_from_df(active_df, x_axis, dataset_10ms.bin_width, n_neurons)\n",
    "passive_mean, passive_sem, _ = psth_from_df(passive_df, x_axis, dataset_10ms.bin_width, n_neurons)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "ax.plot(x_axis, active_mean, linewidth=2, color='k', label='Active')\n",
    "ax.fill_between(x_axis, active_mean-active_sem, active_mean+active_sem, alpha=0.2, color='k')\n",
    "\n",
    "ax.plot(x_axis, passive_mean, linewidth=2, color='red', label='Passive')\n",
    "ax.fill_between(x_axis, passive_mean-passive_sem, passive_mean+passive_sem, alpha=0.2, color='red')\n",
    "\n",
    "ax.axvline(0, color='k', linestyle='--')\n",
    "ax.set_xlim([-300, 600])\n",
    "ax.set_ylabel('Average firing rate (sp/s/neuron)')\n",
    "ax.set_xlabel('Time after movement onset (ms)')\n",
    "ax.legend(frameon=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(figDir + monkey + '_psth.pdf', dpi='figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb535b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_ref(align_field, onset_ref, offset_ref):\n",
    "    return offset_ref if \"offset\" in align_field else onset_ref\n",
    "\n",
    "def align_cond_dict_to_df(df, ref_trial_ids, ref_cond_dict):\n",
    "    trial_ids_df = df['trial_id'].drop_duplicates().to_numpy()\n",
    "    ref_map = {tid: int(ref_cond_dict[i]) for i, tid in enumerate(ref_trial_ids)}\n",
    "\n",
    "    keep = np.array([tid in ref_map for tid in trial_ids_df])\n",
    "    kept_ids = trial_ids_df[keep]\n",
    "    dropped_ids = trial_ids_df[~keep]\n",
    "\n",
    "    cond_df = np.array([ref_map[tid] for tid in kept_ids], dtype=int)\n",
    "    return kept_ids, cond_df, dropped_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d63be3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_global_zscore(dataset, x_field, z_cfg):\n",
    "    df = dataset.make_trial_data(\n",
    "        align_field=z_cfg[\"align_field\"],\n",
    "        align_range=z_cfg[\"align_range\"],\n",
    "        ignored_trials=~z_cfg[\"trial_mask\"],\n",
    "    )\n",
    "    dim = dataset.data[x_field].shape[1]\n",
    "    X = df[x_field].to_numpy().reshape((-1, dim))\n",
    "    mean = np.nanmean(X, axis=0)\n",
    "    std  = np.nanstd(X, axis=0)\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a92db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epoch_X_mean_and_labels(dataset, x_field, epoch_cfg, mean, std, onset_ref, offset_ref):\n",
    "    df = dataset.make_trial_data(\n",
    "        align_field=epoch_cfg[\"align_field\"],\n",
    "        align_range=epoch_cfg[\"align_range\"],\n",
    "        ignored_trials=~epoch_cfg[\"trial_mask\"],\n",
    "    )\n",
    "\n",
    "    ref_ids, ref_cond = pick_ref(epoch_cfg[\"align_field\"], onset_ref, offset_ref)\n",
    "    trial_ids, cond_dict, dropped = align_cond_dict_to_df(df, ref_ids, ref_cond)\n",
    "\n",
    "    # keep only kept trial rows to make reshape consistent\n",
    "    df2 = df[df[\"trial_id\"].isin(trial_ids)]\n",
    "\n",
    "    dim = dataset.data[x_field].shape[1]\n",
    "    X = df2[x_field].to_numpy().reshape((-1, dim))\n",
    "    X = (X - mean) / std\n",
    "\n",
    "    n_trials = len(trial_ids)\n",
    "    n_time = X.shape[0] // n_trials\n",
    "    X_trials = X.reshape((n_trials, n_time, dim))\n",
    "    X_mean = np.nanmean(X_trials, axis=1)\n",
    "\n",
    "    # trial directions (only for cos/sin target)\n",
    "    ti = dataset.trial_info.set_index(\"trial_id\") if dataset.trial_info.index.name != \"trial_id\" else dataset.trial_info\n",
    "    dirs = (ti.loc[trial_ids, \"cond_dir\"] % 360).to_numpy().astype(float)\n",
    "\n",
    "    return dict(\n",
    "        name=epoch_cfg[\"name\"],\n",
    "        X_mean=X_mean,\n",
    "        dirs=dirs,\n",
    "        cond_dict=cond_dict,\n",
    "        trial_ids=trial_ids,\n",
    "        dropped_ids=dropped,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660ecea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "def find_axes_iterative(X, y, cond_dict, N=10, r2_thresh=0.0,\n",
    "                        alpha_grid=None, n_folds=10, random_state=42):\n",
    "    if alpha_grid is None:\n",
    "        alpha_grid = np.logspace(-3, 3, 7)\n",
    "\n",
    "    n_trials, dim = X.shape\n",
    "    X_proc = X.copy()\n",
    "    axes_all = np.full((N, dim), np.nan)\n",
    "    r2_cv = np.full((N,), np.nan)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for i in range(N):\n",
    "        reg = GridSearchCV(Ridge(), {'alpha': alpha_grid}).fit(X_proc, y)\n",
    "        w = reg.best_estimator_.coef_.reshape(-1)\n",
    "        axes_all[i, :] = w\n",
    "\n",
    "        true_concat = np.full((n_trials, 1), np.nan)\n",
    "        pred_concat = np.full((n_trials, 1), np.nan)\n",
    "        save = 0\n",
    "        for tr, te in skf.split(np.arange(n_trials), cond_dict):\n",
    "            lr = GridSearchCV(Ridge(), {'alpha': alpha_grid})\n",
    "            lr.fit(X_proc[tr], y[tr])\n",
    "            y_pred = lr.predict(X_proc[te]).reshape(-1, 1)\n",
    "\n",
    "            n = len(te)\n",
    "            true_concat[save:save+n] = y[te].reshape(-1, 1)\n",
    "            pred_concat[save:save+n] = y_pred\n",
    "            save += n\n",
    "\n",
    "        sses = get_sses_pred(true_concat, pred_concat)\n",
    "        sses_mean = get_sses_mean(true_concat)\n",
    "        r2_cv[i] = 1 - np.sum(sses) / np.sum(sses_mean)\n",
    "\n",
    "        X_proc = X_proc - calc_proj(X_proc, w.reshape(-1, 1)).T\n",
    "\n",
    "    axes_kept = axes_all[r2_cv > r2_thresh, :]\n",
    "    return axes_kept, r2_cv\n",
    "\n",
    "def compute_axes_cos_sin(epoch_data, N=10, r2_thresh=0.0, proj_out_axes=None):\n",
    "    X = epoch_data[\"X_mean\"].copy()\n",
    "    if proj_out_axes is not None and proj_out_axes.size:\n",
    "        X = X - calc_proj(X, proj_out_axes.T).T\n",
    "\n",
    "    dirs = epoch_data[\"dirs\"]\n",
    "    cond = epoch_data[\"cond_dict\"]\n",
    "\n",
    "    cos_sig = np.cos(np.deg2rad(dirs)).reshape(-1, 1)\n",
    "    sin_sig = np.sin(np.deg2rad(dirs)).reshape(-1, 1)\n",
    "\n",
    "    axes_x, r2x = find_axes_iterative(X, cos_sig, cond, N=N, r2_thresh=r2_thresh)\n",
    "    axes_y, r2y = find_axes_iterative(X, sin_sig, cond, N=N, r2_thresh=r2_thresh)\n",
    "\n",
    "    axes = np.vstack([axes_x, axes_y]) if (axes_x.size or axes_y.size) else np.zeros((0, X.shape[1]))\n",
    "    return axes, r2x, r2y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88ac777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_continuous(dataset, x_field, mean, std, axes):\n",
    "    X = dataset.data[x_field].to_numpy()\n",
    "    Xz = (X - mean) / std\n",
    "    return Xz @ axes.T if axes.size else np.zeros((Xz.shape[0], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3889147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def run_cdfb_pipeline(\n",
    "    monkey,\n",
    "    dataset,\n",
    "    x_field,\n",
    "    onset_ref,          # (active_trial_ids, active_cond_dict)\n",
    "    offset_ref,         # (active_trial_ids_offset, active_cond_dict_offset)\n",
    "    z_cfg,\n",
    "    epoch_cfgs,         # list of configs\n",
    "    N=10,\n",
    "    r2_thresh=0.0,\n",
    "    save_dir=\".\",\n",
    "    save_tag=\"v6_zscore\",\n",
    "):\n",
    "    # 1) global zscore\n",
    "    mean, std = compute_global_zscore(dataset, x_field, z_cfg)\n",
    "\n",
    "    # 2) compute axes per epoch (with optional proj_out)\n",
    "    axes_dict = {}\n",
    "    meta = {\"epochs\": [], \"x_field\": x_field, \"z_cfg\": z_cfg, \"N\": N, \"r2_thresh\": r2_thresh}\n",
    "\n",
    "    for ep in epoch_cfgs:\n",
    "        ep_data = get_epoch_X_mean_and_labels(dataset, x_field, ep, mean, std, onset_ref, offset_ref)\n",
    "\n",
    "        proj_out_name = ep.get(\"proj_out\", None)\n",
    "        proj_out_axes = axes_dict.get(proj_out_name, None) if proj_out_name else None\n",
    "\n",
    "        axes, r2x, r2y = compute_axes_cos_sin(ep_data, N=N, r2_thresh=r2_thresh, proj_out_axes=proj_out_axes)\n",
    "        axes_dict[ep[\"name\"]] = axes\n",
    "\n",
    "        meta[\"epochs\"].append({\n",
    "            \"name\": ep[\"name\"],\n",
    "            \"align_field\": ep[\"align_field\"],\n",
    "            \"align_range\": ep[\"align_range\"],\n",
    "            \"trial_mask_name\": ep.get(\"mask_name\", \"\"),\n",
    "            \"n_trials\": int(len(ep_data[\"trial_ids\"])),\n",
    "            \"n_dropped_not_in_ref\": int(len(ep_data[\"dropped_ids\"])),\n",
    "            \"proj_out\": proj_out_name,\n",
    "            \"axes_shape\": tuple(axes.shape),\n",
    "            \"r2x\": r2x.tolist(),\n",
    "            \"r2y\": r2y.tolist(),\n",
    "        })\n",
    "\n",
    "        print(f\"[{ep['name']}] axes {axes.shape}, trials {len(ep_data['trial_ids'])}, dropped(not-in-ref) {len(ep_data['dropped_ids'])}\")\n",
    "\n",
    "    # 3) project continuous\n",
    "    proj_dict = {f\"{name}_proj\": project_continuous(dataset, x_field, mean, std, axes)\n",
    "                 for name, axes in axes_dict.items()}\n",
    "\n",
    "    # common combos if present\n",
    "    if \"CD\" in axes_dict and \"FB_onset\" in axes_dict:\n",
    "        proj_dict[\"CD_FB_onset_proj\"] = np.hstack([proj_dict[\"CD_proj\"], proj_dict[\"FB_onset_proj\"]])\n",
    "    if \"CD\" in axes_dict and \"FB_offset\" in axes_dict:\n",
    "        proj_dict[\"CD_FB_offset_proj\"] = np.hstack([proj_dict[\"CD_proj\"], proj_dict[\"FB_offset_proj\"]])\n",
    "\n",
    "    # 4) save 2 npz\n",
    "    weights_path = os.path.join(save_dir, f\"{monkey}_{save_tag}_cdfb_weights_{x_field}.npz\")\n",
    "    data_path    = os.path.join(save_dir, f\"{monkey}_{save_tag}_cdfb_data_{x_field}.npz\")\n",
    "\n",
    "    np.savez(weights_path, mean=mean, std=std,\n",
    "             **{f\"{k}_axes\": v for k, v in axes_dict.items()},\n",
    "             meta=np.array([meta], dtype=object))\n",
    "    np.savez(data_path, **proj_dict)\n",
    "\n",
    "    print(\"Saved weights:\", weights_path)\n",
    "    print(\"Saved data   :\", data_path)\n",
    "    return weights_path, data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d256eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_continuous(dataset, x_field, mean, std, axes):\n",
    "    X = dataset.data[x_field].to_numpy()\n",
    "    Xz = (X - mean) / std\n",
    "    return Xz @ axes.T if axes.size else np.zeros((Xz.shape[0], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8eaee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def run_cdfb_pipeline(\n",
    "    monkey,\n",
    "    dataset,\n",
    "    x_field,\n",
    "    onset_ref,          # (active_trial_ids, active_cond_dict)\n",
    "    offset_ref,         # (active_trial_ids_offset, active_cond_dict_offset)\n",
    "    z_cfg,\n",
    "    epoch_cfgs,         # list of configs\n",
    "    N=10,\n",
    "    r2_thresh=0.0,\n",
    "    save_dir=\".\",\n",
    "    save_tag=\"v6_zscore\",\n",
    "):\n",
    "    # 1) global zscore\n",
    "    mean, std = compute_global_zscore(dataset, x_field, z_cfg)\n",
    "\n",
    "    # 2) compute axes per epoch (with optional proj_out)\n",
    "    axes_dict = {}\n",
    "    meta = {\"epochs\": [], \"x_field\": x_field, \"z_cfg\": z_cfg, \"N\": N, \"r2_thresh\": r2_thresh}\n",
    "\n",
    "    for ep in epoch_cfgs:\n",
    "        ep_data = get_epoch_X_mean_and_labels(dataset, x_field, ep, mean, std, onset_ref, offset_ref)\n",
    "\n",
    "        proj_out_name = ep.get(\"proj_out\", None)\n",
    "        proj_out_axes = axes_dict.get(proj_out_name, None) if proj_out_name else None\n",
    "\n",
    "        axes, r2x, r2y = compute_axes_cos_sin(ep_data, N=N, r2_thresh=r2_thresh, proj_out_axes=proj_out_axes)\n",
    "        axes_dict[ep[\"name\"]] = axes\n",
    "\n",
    "        meta[\"epochs\"].append({\n",
    "            \"name\": ep[\"name\"],\n",
    "            \"align_field\": ep[\"align_field\"],\n",
    "            \"align_range\": ep[\"align_range\"],\n",
    "            \"trial_mask_name\": ep.get(\"mask_name\", \"\"),\n",
    "            \"n_trials\": int(len(ep_data[\"trial_ids\"])),\n",
    "            \"n_dropped_not_in_ref\": int(len(ep_data[\"dropped_ids\"])),\n",
    "            \"proj_out\": proj_out_name,\n",
    "            \"axes_shape\": tuple(axes.shape),\n",
    "            \"r2x\": r2x.tolist(),\n",
    "            \"r2y\": r2y.tolist(),\n",
    "        })\n",
    "\n",
    "        print(f\"[{ep['name']}] axes {axes.shape}, trials {len(ep_data['trial_ids'])}, dropped(not-in-ref) {len(ep_data['dropped_ids'])}\")\n",
    "\n",
    "    # 3) project continuous\n",
    "    proj_dict = {f\"{name}_proj\": project_continuous(dataset, x_field, mean, std, axes)\n",
    "                 for name, axes in axes_dict.items()}\n",
    "\n",
    "    # common combos if present\n",
    "    if \"CD\" in axes_dict and \"FB_onset\" in axes_dict:\n",
    "        proj_dict[\"CD_FB_onset_proj\"] = np.hstack([proj_dict[\"CD_proj\"], proj_dict[\"FB_onset_proj\"]])\n",
    "    if \"CD\" in axes_dict and \"FB_offset\" in axes_dict:\n",
    "        proj_dict[\"CD_FB_offset_proj\"] = np.hstack([proj_dict[\"CD_proj\"], proj_dict[\"FB_offset_proj\"]])\n",
    "\n",
    "    # 4) save 2 npz\n",
    "    weights_path = os.path.join(save_dir, f\"{monkey}_{save_tag}_cdfb_weights_{x_field}.npz\")\n",
    "    data_path    = os.path.join(save_dir, f\"{monkey}_{save_tag}_cdfb_data_{x_field}.npz\")\n",
    "\n",
    "    np.savez(weights_path, mean=mean, std=std,\n",
    "             **{f\"{k}_axes\": v for k, v in axes_dict.items()},\n",
    "             meta=np.array([meta], dtype=object))\n",
    "    np.savez(data_path, **proj_dict)\n",
    "\n",
    "    print(\"Saved weights:\", weights_path)\n",
    "    print(\"Saved data   :\", data_path)\n",
    "    return weights_path, data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5f1b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "onset_ref  = (active_trial_ids, active_cond_dict)\n",
    "offset_ref = (active_trial_ids_offset, active_cond_dict_offset)\n",
    "\n",
    "z_cfg = dict(\n",
    "    align_field=\"move_onset_time\",\n",
    "    align_range=(-100, 1500),\n",
    "    trial_mask=active_mask,          # ä½ æƒ³ç”¨å“ªä¸ª mask ç»Ÿè®¡ mean/std å°±å¡«å“ªä¸ª\n",
    ")\n",
    "\n",
    "epoch_cfgs = [\n",
    "    dict(name=\"CD\", align_field=\"move_onset_time\", align_range=(-100, 0),  trial_mask=active_mask, mask_name=\"active\"),\n",
    "    dict(name=\"FB_onset\", align_field=\"move_onset_time\", align_range=(200, 400), trial_mask=active_mask, mask_name=\"active\",\n",
    "         proj_out=\"CD\"),\n",
    "    # optional\n",
    "    dict(name=\"FB_offset\", align_field=\"move_offset_time\", align_range=(-100, 0), trial_mask=active_mask_offset, mask_name=\"active_offset\",\n",
    "         proj_out=\"CD\"),\n",
    "]\n",
    "\n",
    "weights_path, data_path = run_cdfb_pipeline(\n",
    "    monkey=monkey,\n",
    "    dataset=dataset_10ms,\n",
    "    x_field=\"spikes\",\n",
    "    onset_ref=onset_ref,\n",
    "    offset_ref=offset_ref,\n",
    "    z_cfg=z_cfg,\n",
    "    epoch_cfgs=epoch_cfgs,\n",
    "    N=10,\n",
    "    r2_thresh=0.0,\n",
    "    save_dir=\".\",\n",
    "    save_tag=\"v6_zscore_unsmoothed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cea75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_10ms\n",
    "x_field = 'spikes'\n",
    "unsmoothed = np.load(monkey + f'_v6_zscore_unsmoothed_cdfb_data_{x_field}.npz')\n",
    "gaussian_kernel_width = 40  # ms\n",
    "sigma = int(gaussian_kernel_width / bin_width)\n",
    "\n",
    "proj_keys = {\n",
    "    'CD_proj':     'unsmoothed_CD_proj',\n",
    "    'FB_onset_proj':     'unsmoothed_FB_proj',\n",
    "    'CD_FB_onset_proj':  'unsmoothed_CD_FB_proj',\n",
    "}\n",
    "\n",
    "smoothed_data = {}\n",
    "\n",
    "for key, dataset_name in proj_keys.items():\n",
    "    X = unsmoothed[key].astype(np.float64)\n",
    "    X_sm = gaussian_filter1d_twoside(X, sigma, axis=0)\n",
    "\n",
    "    smoothed_data[key] = X_sm\n",
    "    # dataset.add_continuous_data(X_sm, f'smoothed_{key}_{x_field}')\n",
    "\n",
    "print(\"Added smoothed data to dataset:\")\n",
    "print(dataset.data.keys().unique(0))\n",
    "np.savez(\n",
    "    monkey + f'_v6_zscore_smoothed_cdfb_data_{x_field}.npz',\n",
    "    **smoothed_data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c165e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_map = {\n",
    "    'CD_proj':            'CD_proj',\n",
    "    'FB_onset_proj':      'FB_proj',\n",
    "    'CD_FB_onset_proj':   'CD_FB_proj',\n",
    "}\n",
    "dataset = dataset_10ms\n",
    "x_field = 'spikes'\n",
    "\n",
    "data = np.load(monkey + f'_v6_zscore_smoothed_cdfb_data_{x_field}.npz')\n",
    "print(\"Keys in file:\", data.files)\n",
    "\n",
    "for file_key, dataset_key in rename_map.items():\n",
    "    dataset.add_continuous_data(data[file_key], dataset_key)\n",
    "\n",
    "print(dataset.data.keys().unique(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad37c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(np.unique(active_cond_dict_offset)) == 8:\n",
    "    plot_dir = np.array([0,45,90,135,180,225,270,315]) \n",
    "    directions = np.array([0,45,90,135,180,225,270,315])\n",
    "else:\n",
    "    plot_dir = np.array([0,90,180,270]) \n",
    "    directions = np.array([0,90,180,270])\n",
    "cmap = plt.get_cmap('coolwarm',len(plot_dir))\n",
    "custom_palette = [mpl.colors.rgb2hex(cmap(i)) for i in range(len(plot_dir))]\n",
    "plot_field = 'CD_FB_proj'\n",
    "N = dataset_10ms.data[plot_field].shape[1]\n",
    "order = range(N)\n",
    "\n",
    "pred_range = (-200, 1100)\n",
    "trial_mask = active_mask\n",
    "cond_dict = active_cond_dict\n",
    "n_timepoints = int((pred_range[1] - pred_range[0])/dataset_10ms.bin_width)\n",
    "data = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range=pred_range, ignored_trials=~trial_mask, allow_overlap=True)\n",
    "n_trials = data['trial_id'].nunique()\n",
    "trials_pca = nans([n_trials,n_timepoints,N])\n",
    "i = 0\n",
    "for idx, trial in data.groupby('trial_id'):\n",
    "    trials_pca[i,:,:]=trial[plot_field].to_numpy()\n",
    "    i+=1\n",
    "print(trials_pca.shape)\n",
    "\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_10ms.bin_width)\n",
    "\n",
    "# define some useful time points\n",
    "move_idx=0\n",
    "ret_idx = 500\n",
    "\n",
    "plot_dims = N\n",
    "\n",
    "fig,ax=plt.subplots(plot_dims,1,figsize=(10,N+4))\n",
    "for i in range(plot_dims):\n",
    "    for j in range(len(plot_dir)):\n",
    "        color = custom_palette[j]\n",
    "        dir_idx = np.argwhere(directions == plot_dir[j])[0]\n",
    "        cond_mean_proj = np.mean(trials_pca[np.argwhere(cond_dict==dir_idx).flatten(),:,:], axis = 0)[:,order[i]] \n",
    "        pca_mean = np.mean(data[plot_field].to_numpy(),axis = 0)[order[i]] \n",
    "        ax[i].plot(x_axis,cond_mean_proj - pca_mean,linewidth=2.25,color = color,label = plot_dir[j])\n",
    "        \n",
    "        ax[i].axvline(move_idx, color='k',linewidth = 1)\n",
    "        ax[i].axvline(ret_idx, color='k',linewidth = 1)\n",
    "        \n",
    "        ax[i].set_xlim([-200,1000])\n",
    "        # ax[i].set_ylim([-.5, .5])\n",
    "        ax[i].axhline(0,color ='k',ls = '--')\n",
    "        if i<plot_dims-1:\n",
    "            ax[i].set_xticks([])\n",
    "        else:\n",
    "            ax[i].set_xlabel('Time after movement onset (ms)')\n",
    "            \n",
    "        ax[i].set_yticks([])\n",
    "        ax[i].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "    ax[0].set_title('Active trials')\n",
    "     \n",
    "plt.legend(bbox_to_anchor = (1, 1), loc = 'upper left')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_ylim_cdfb_active_smooth.pdf',dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e06a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA projections over trial, for different reaching directions\n",
    "pred_range = (-100, 600)\n",
    "trial_mask = passive_mask\n",
    "cond_dict = passive_cond_dict\n",
    "n_timepoints = int((pred_range[1] - pred_range[0])/dataset_10ms.bin_width)\n",
    "data = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range=pred_range, ignored_trials=~trial_mask, allow_overlap=True)\n",
    "n_trials = data['trial_id'].nunique()\n",
    "trials_pca = nans([n_trials,n_timepoints,N])\n",
    "i = 0\n",
    "for idx, trial in data.groupby('trial_id'):\n",
    "    trials_pca[i,:,:]=trial[plot_field].to_numpy()\n",
    "    i+=1\n",
    "print(trials_pca.shape)\n",
    "\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_10ms.bin_width)\n",
    "\n",
    "# define some useful time points\n",
    "move_idx=0\n",
    "ret_idx = 120\n",
    "\n",
    "plot_dims = N\n",
    "\n",
    "fig,ax=plt.subplots(plot_dims,1,figsize=(10,N+4))\n",
    "for i in range(plot_dims):\n",
    "    for j in range(len(plot_dir)):\n",
    "        color = custom_palette[j]\n",
    "        dir_idx = np.argwhere(directions == plot_dir[j])[0]\n",
    "        cond_mean_proj = np.mean(trials_pca[np.argwhere(cond_dict==dir_idx).flatten(),:,:], axis = 0)[:,order[i]] \n",
    "        pca_mean = np.mean(data[plot_field].to_numpy(),axis = 0)[order[i]]\n",
    "        ax[i].plot(x_axis,cond_mean_proj - pca_mean,linewidth=2.25,color = color,label = plot_dir[j])\n",
    "        \n",
    "        ax[i].axvline(move_idx, color='k',linewidth = 1)\n",
    "        # ax[i].axvline(120, color='k',linewidth = 1)\n",
    "        ax[i].axvline(ret_idx, color='k',linewidth = 1)\n",
    "        ax[i].set_xlim([-100,500])\n",
    "        # ax[i].set_ylim([-.5, .5])\n",
    "        ax[i].axhline(0,color ='k',ls = '--')\n",
    "        if i<plot_dims-1:\n",
    "            ax[i].set_xticks([])\n",
    "        else:\n",
    "            ax[i].set_xlabel('Time after movement onset (ms)')\n",
    "\n",
    "        ax[i].set_yticks([])\n",
    "        ax[i].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "    ax[0].set_title('Passive trials')\n",
    "\n",
    "plt.legend(bbox_to_anchor = (1, 1), loc = 'upper left')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_ylim_cdfb_passive_smooth.pdf',dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41ddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data.keys().unique(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8788e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cd_dims = data['CD_proj'].shape[1]\n",
    "print(n_cd_dims,\"CD dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c81cc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_field = 'hand_vel'\n",
    "lag_axis = np.arange(-300, 320, 20)\n",
    "norm_x    = True\n",
    "n_splits = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2578cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_decoding_for_feature(\n",
    "    name,            # e.g. 'cd_only', 'SC_cd_only', 'fb_only'\n",
    "    x_field,         # e.g. 'CD_proj', 'FB_proj', 'CD_FB_proj', 'spikes_smth_40', 'PCA_40'\n",
    "    dataset,\n",
    "    trial_mask,\n",
    "    cond_dict,\n",
    "    lag_axis,\n",
    "    pred_range,\n",
    "    y_field='hand_vel',\n",
    "    norm_x=True,\n",
    "    pos_bool=False,\n",
    "    n_cd_dims=0,\n",
    "    n_splits=20,\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs fit_and_predict_MC over all lags for a given feature set x_field.\n",
    "    Uses your existing fit_and_predict_MC signature exactly.\n",
    "    \"\"\"\n",
    "    dim   = dataset.data[x_field].shape[1]         # # of features\n",
    "    y_dim = dataset.data[y_field].shape[1]         # e.g. 2 for x,y velocity\n",
    "\n",
    "    r2_array_MC      = np.full((len(lag_axis), n_splits),        np.nan)\n",
    "    r2_feature_array = np.full((len(lag_axis), n_splits, y_dim), np.nan)\n",
    "    coef_array       = np.full((len(lag_axis), y_dim, dim),      np.nan)\n",
    "\n",
    "    for i, lag in enumerate(lag_axis):\n",
    "        print(f\"{name}: lag {lag} ms ({i+1}/{len(lag_axis)})\")\n",
    "\n",
    "        r2, coef, _, vel_df, r2_arr = fit_and_predict_MC(\n",
    "            dataset,\n",
    "            trial_mask,\n",
    "            align_field='move_onset_time',\n",
    "            align_range=pred_range,\n",
    "            lag=lag,\n",
    "            x_field=x_field,\n",
    "            y_field=y_field,\n",
    "            norm_x=norm_x,\n",
    "            pos_bool=pos_bool,\n",
    "            split_pred=False,     # your default; keep as-is\n",
    "            n_cd_dims=n_cd_dims,  # varies per model\n",
    "            n_splits=n_splits,    # explicit, same as array size\n",
    "            cond_dict=cond_dict,\n",
    "        )\n",
    "\n",
    "        r2_array_MC[i, :]        = r2\n",
    "        r2_feature_array[i, ...] = r2_arr\n",
    "        coef_array[i, ...]       = coef\n",
    "\n",
    "    results = {}\n",
    "    # feature 0 -> x, feature 1 -> y\n",
    "    results[f\"x_r2_{name}\"]   = r2_feature_array[:, :, 0]\n",
    "    results[f\"y_r2_{name}\"]   = r2_feature_array[:, :, 1]\n",
    "    results[f\"r2_{name}\"]     = r2_array_MC\n",
    "    results[f\"{name}_coefs\"]  = coef_array\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca592d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_configs = [\n",
    "    {\n",
    "        \"cond_name\":  \"early_act\",\n",
    "        \"trial_mask\": active_mask,\n",
    "        \"cond_dict\":  active_cond_dict,\n",
    "        \"pred_range\": (-100, 120),\n",
    "    },\n",
    "    {\n",
    "        \"cond_name\":  \"act\",\n",
    "        \"trial_mask\": active_mask,\n",
    "        \"cond_dict\":  active_cond_dict,\n",
    "        \"pred_range\": (-100, 1000),\n",
    "    },\n",
    "    {\n",
    "        \"cond_name\":  \"pas\",\n",
    "        \"trial_mask\": passive_mask,\n",
    "        \"cond_dict\":  passive_cond_dict,\n",
    "        \"pred_range\": (-100, 120),\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506b344",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = [\n",
    "    #  name          x_field           pos_bool   n_cd_dims\n",
    "    (\"cd_only\",     \"CD_proj\",        False,     0),\n",
    "    (\"SC_cd_only\",  \"CD_proj\",        True,      0),\n",
    "\n",
    "    (\"fb_only\",     \"FB_proj\",        False,     0),\n",
    "    (\"SC_fb_only\",  \"FB_proj\",        True,      0),\n",
    "\n",
    "    (\"cd_fb\",       \"CD_FB_proj\",     False,     n_cd_dims),\n",
    "    (\"SC_cd_fb\",    \"CD_FB_proj\",     True,      n_cd_dims),\n",
    "\n",
    "    (\"nrn\",         \"spikes_smth_40\", False,     0),\n",
    "    (\"pc\",          \"PCA_40\",         False,     0),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b562635",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond_cfg in condition_configs:\n",
    "    cond_name        = cond_cfg[\"cond_name\"]\n",
    "    trial_mask       = cond_cfg[\"trial_mask\"]\n",
    "    cond_dict        = cond_cfg[\"cond_dict\"]\n",
    "    pred_range_cond  = cond_cfg[\"pred_range\"]\n",
    "\n",
    "    print(f\"\\n=== Running condition: {cond_name} ===\")\n",
    "    all_results = {}\n",
    "\n",
    "    for (name, x_field_i, pos_bool_i, n_cd_dims_i) in model_configs:\n",
    "\n",
    "        res = run_decoding_for_feature(\n",
    "            name=name,\n",
    "            x_field=x_field_i,\n",
    "            dataset=dataset,\n",
    "            trial_mask=trial_mask,\n",
    "            cond_dict=cond_dict,\n",
    "            lag_axis=lag_axis,\n",
    "            pred_range=pred_range_cond,   # ðŸ”¥ condition controls pred_range\n",
    "            y_field=y_field,\n",
    "            norm_x=norm_x,\n",
    "            pos_bool=pos_bool_i,\n",
    "            n_cd_dims=n_cd_dims_i,\n",
    "            n_splits=n_splits,\n",
    "        )\n",
    "        all_results.update(res)\n",
    "\n",
    "    save_name = f\"{monkey}_MC_norm_zscore_smooth40_spikes_{y_field}_{cond_name}_r2s.npz\"\n",
    "    np.savez(save_name, **all_results)\n",
    "    print(\"Saved:\", save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9552a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "LAG_AXIS = np.arange(-300, 320, 20) \n",
    "LW = 3\n",
    "\n",
    "def load_decoding_results(monkey, y_field, cond_name,\n",
    "                          base_dir='.', \n",
    "                          prefix='MC_norm_zscore_smooth40_spikes'):\n",
    "    \"\"\"\n",
    "      f\"{monkey}_{prefix}_{y_field}_{cond_name}_r2s.npz\"\n",
    "    \"\"\"\n",
    "    fname = f\"{monkey}_{prefix}_{y_field}_{cond_name}_r2s.npz\"\n",
    "    path = os.path.join(base_dir, fname)\n",
    "    data = np.load(path)\n",
    "    print(\"Loaded:\", path)\n",
    "    return data\n",
    "\n",
    "def plot_r2_for_model(data, model_name, lag_axis=LAG_AXIS, color='brown', label=None,\n",
    "                      ax=None, lw=LW, alpha_fill=0.3, print_stats=True):\n",
    "    if label is None:\n",
    "        label = model_name\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(5.5, 4))\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "\n",
    "    r2 = data[f\"r2_{model_name}\"]          # shape [n_lags, n_splits]\n",
    "    mean_r2 = np.nanmean(r2, axis=1)\n",
    "    std_r2  = np.nanstd(r2, axis=1)\n",
    "\n",
    "    ax.plot(lag_axis, mean_r2, linewidth=lw, color=color, label=label)\n",
    "    ax.fill_between(lag_axis, mean_r2 - std_r2, mean_r2 + std_r2,\n",
    "                    color=color, alpha=alpha_fill)\n",
    "\n",
    "    if print_stats:\n",
    "        best_idx = np.nanargmax(mean_r2)\n",
    "        best_lag = lag_axis[best_idx]\n",
    "        best_r2  = mean_r2[best_idx]\n",
    "        print(f\"{model_name}: best RÂ² = {best_r2:.3f} at lag {best_lag} ms\")\n",
    "\n",
    "        for frac in [0.95, 0.9, 0.8, 0.7]:\n",
    "            good_r2 = best_r2 * frac\n",
    "            good_idx = np.where(mean_r2 >= good_r2)[0]\n",
    "            if len(good_idx) > 0:\n",
    "                good_lag = lag_axis[good_idx[0]]\n",
    "                print(f\"  {frac*100:.0f}% of max (RÂ²={good_r2:.3f}) first at lag {good_lag} ms\")\n",
    "            else:\n",
    "                print(f\"  {frac*100:.0f}% of max: no lag reaches this threshold\")\n",
    "\n",
    "    return ax\n",
    "\n",
    "def get_mean_std(data, key_prefix, model_name):\n",
    "    \"\"\"\n",
    "    key_prefix: 'r2_' / 'x_r2_' / 'y_r2_'\n",
    "    \"\"\"\n",
    "    arr = data[f\"{key_prefix}{model_name}\"]   # [n_lags, n_splits]\n",
    "    mean = np.nanmean(arr, axis=1)\n",
    "    std  = np.nanstd(arr, axis=1)\n",
    "    return mean, std\n",
    "\n",
    "def plot_r2_comparison_overall(data, lag_axis=LAG_AXIS, title=None, ylim=(-0.1, 0.9),\n",
    "                               ax=None, lw=LW):\n",
    "    \"\"\"\n",
    "    RÂ²: cd / fb / cd+fb / nrn / pc\n",
    "    key: 'r2_*'\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(5.5, 4))\n",
    "\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "    # (model_name, color, linestyle, label, alpha_fill)\n",
    "    models = [\n",
    "        ('cd_only', 'green',   '-', 'SC_cd',      0.3),\n",
    "        ('fb_only', 'magenta', '-', 'SC_fb',      0.3),\n",
    "        ('cd_fb',   'brown',   '-', 'cd+fb',   0.3),\n",
    "        ('nrn',     'grey',    '--','neurons', 0.5),\n",
    "        ('pc',      'lightgrey','--','PCs',    0.5),\n",
    "    ]\n",
    "\n",
    "    for model_name, color, ls, label, alpha_fill in models:\n",
    "        mean_r2, std_r2 = get_mean_std(data, 'r2_', model_name)\n",
    "        ax.plot(lag_axis, mean_r2, linewidth=lw, color=color,\n",
    "                linestyle=ls, label=label)\n",
    "        ax.fill_between(lag_axis, mean_r2 - std_r2, mean_r2 + std_r2,\n",
    "                        color=color, alpha=alpha_fill)\n",
    "\n",
    "        print(f\"[overall] {model_name}: max RÂ² = {np.nanmax(mean_r2):.3f} at lag {lag_axis[np.nanargmax(mean_r2)]} ms\")\n",
    "\n",
    "    ax.axvline(0, color='k', linestyle='--')\n",
    "    ax.set_xlabel('Time lag (ms)')\n",
    "    ax.set_ylabel('RÂ²')\n",
    "    ax.set_ylim(*ylim)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    ax.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def plot_r2_comparison_xy(data, comp='x', lag_axis=LAG_AXIS, title=None,\n",
    "                          ylim=(-0.1, 0.9), ax=None, lw=LW):\n",
    "    \"\"\"\n",
    "    comp: 'x' or 'y'\n",
    "    key: 'x_r2_*' / 'y_r2_*'\n",
    "    \"\"\"\n",
    "    assert comp in ('x', 'y')\n",
    "    prefix = f\"{comp}_r2_\"\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(5.5, 4))\n",
    "\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "    models = [\n",
    "        ('cd_only', 'green',   '-', 'SC_cd',      0.3),\n",
    "        ('fb_only', 'magenta', '-', 'SC_fb',      0.3),\n",
    "        ('cd_fb',   'brown',   '-', 'cd+fb',   0.3),\n",
    "        ('nrn',     'grey',    '--','neurons', 0.5),\n",
    "        ('pc',      'lightgrey','--','PCs',    0.5),\n",
    "    ]\n",
    "\n",
    "    for model_name, color, ls, label, alpha_fill in models:\n",
    "        mean_r2, std_r2 = get_mean_std(data, prefix, model_name)\n",
    "        ax.plot(lag_axis, mean_r2, linewidth=lw, color=color,\n",
    "                linestyle=ls, label=label)\n",
    "        ax.fill_between(lag_axis, mean_r2 - std_r2, mean_r2 + std_r2,\n",
    "                        color=color, alpha=alpha_fill)\n",
    "\n",
    "        print(f\"[{comp.upper()}] {model_name}: max RÂ² = {np.nanmax(mean_r2):.3f} at lag {lag_axis[np.nanargmax(mean_r2)]} ms\")\n",
    "\n",
    "    ax.axvline(0, color='k', linestyle='--')\n",
    "    ax.set_xlabel('Time lag (ms)')\n",
    "    ax.set_ylabel(f\"{comp.upper()} RÂ²\")\n",
    "    ax.set_ylim(*ylim)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    # ax.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def plot_r2_SC_vs_nonSC(data, lag_axis=LAG_AXIS, title=None,\n",
    "                        ylim=(-0.1, 0.9), ax=None, lw=LW):\n",
    "    \"\"\"\n",
    "    compare cd_only vs SC_cd_only, fb_only vs SC_fb_only, cd_fb vs SC_cd_fb\n",
    "    'r2_*' total RÂ²\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(5.5, 4))\n",
    "\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "    pair_models = [\n",
    "        ('cd_only',   'SC_cd_only',  'green',   'cd',   'SC cd'),\n",
    "        ('fb_only',   'SC_fb_only',  'magenta', 'fb',   'SC fb'),\n",
    "        ('cd_fb',     'SC_cd_fb',    'brown',   'cd+fb','SC cd+fb'),\n",
    "    ]\n",
    "\n",
    "    for base, sc, color, base_label, sc_label in pair_models:\n",
    "        mean_base, std_base = get_mean_std(data, 'r2_', base)\n",
    "        mean_sc,   std_sc   = get_mean_std(data, 'r2_', sc)\n",
    "\n",
    "        # Non-SCï¼šlighter\n",
    "        ax.plot(lag_axis, mean_base, linewidth=lw, color=color,\n",
    "                linestyle='--', label=base_label, alpha=0.4)\n",
    "        ax.fill_between(lag_axis, mean_base - std_base, mean_base + std_base,\n",
    "                        color=color, alpha=0.1)\n",
    "\n",
    "        # SCï¼šsolid\n",
    "        ax.plot(lag_axis, mean_sc, linewidth=lw, color=color,\n",
    "                linestyle='-', label=sc_label, alpha=0.9)\n",
    "        ax.fill_between(lag_axis, mean_sc - std_sc, mean_sc + std_sc,\n",
    "                        color=color, alpha=0.3)\n",
    "\n",
    "        print(f\"[SC compare] {base}: max {np.nanmax(mean_base):.3f} at {lag_axis[np.nanargmax(mean_base)]} ms\")\n",
    "        print(f\"[SC compare] {sc}:   max {np.nanmax(mean_sc):.3f} at {lag_axis[np.nanargmax(mean_sc)]} ms\")\n",
    "\n",
    "    ax.axvline(0, color='k', linestyle='--')\n",
    "    ax.set_xlabel('Time lag (ms)')\n",
    "    ax.set_ylabel('RÂ²')\n",
    "    ax.set_ylim(*ylim)\n",
    "    if title is not None:\n",
    "        ax.set_title(title)\n",
    "    ax.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a268e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_condition_overview(monkey, y_field, cond_name,\n",
    "                            base_dir='.',\n",
    "                            fig_dir='.',      \n",
    "                            save_fig=False):\n",
    "    \"\"\"\n",
    "      1. overall RÂ² (cd / fb / cd+fb / nrn / pc)\n",
    "      2. X RÂ²\n",
    "      3. Y RÂ²\n",
    "      4. SC vs non-SC\n",
    "    \"\"\"\n",
    "    data = load_decoding_results(monkey, y_field, cond_name, base_dir=base_dir)\n",
    "    title_suffix = f\"{monkey}_{y_field}_{cond_name}\"\n",
    "    \n",
    "    ylim_overall = (-0.1, 0.9)\n",
    "\n",
    "    # 1. overall\n",
    "    fig = plot_r2_comparison_overall(\n",
    "        data, LAG_AXIS,\n",
    "        title=f\"{monkey} {y_field} {cond_name} overall\",\n",
    "        ylim=ylim_overall\n",
    "    )\n",
    "    if save_fig:\n",
    "        fname = os.path.join(fig_dir, f\"{title_suffix}_overall_r2.pdf\")\n",
    "        plt.savefig(fname, dpi='figure', bbox_inches='tight')\n",
    "        print(\"Saved:\", fname)\n",
    "    plt.show()\n",
    "\n",
    "    # 2. X RÂ²\n",
    "    fig = plot_r2_comparison_xy(\n",
    "        data, comp='x', lag_axis=LAG_AXIS,\n",
    "        title=f\"{monkey} {y_field} {cond_name} X\",\n",
    "        ylim=ylim_overall\n",
    "    )\n",
    "    if save_fig:\n",
    "        fname = os.path.join(fig_dir, f\"{title_suffix}_x_r2.pdf\")\n",
    "        plt.savefig(fname, dpi='figure', bbox_inches='tight')\n",
    "        print(\"Saved:\", fname)\n",
    "    plt.show()\n",
    "\n",
    "    # 3. Y RÂ²\n",
    "    fig = plot_r2_comparison_xy(\n",
    "        data, comp='y', lag_axis=LAG_AXIS,\n",
    "        title=f\"{monkey} {y_field} {cond_name} Y\",\n",
    "        ylim=ylim_overall\n",
    "    )\n",
    "    if save_fig:\n",
    "        fname = os.path.join(fig_dir, f\"{title_suffix}_y_r2.pdf\")\n",
    "        plt.savefig(fname, dpi='figure', bbox_inches='tight')\n",
    "        print(\"Saved:\", fname)\n",
    "    plt.show()\n",
    "\n",
    "    # 4. SC vs non-SC\n",
    "    fig = plot_r2_SC_vs_nonSC(\n",
    "        data, lag_axis=LAG_AXIS,\n",
    "        title=f\"{monkey} {y_field} {cond_name} SC vs non-SC\",\n",
    "        ylim=ylim_overall\n",
    "    )\n",
    "    if save_fig:\n",
    "        fname = os.path.join(fig_dir, f\"{title_suffix}_SC_vs_nonSC_r2.pdf\")\n",
    "        plt.savefig(fname, dpi='figure', bbox_inches='tight')\n",
    "        print(\"Saved:\", fname)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4bc038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monkey = \"Lando_20170731\"\n",
    "# monkey = \"Chips_20170913\"\n",
    "\n",
    "y_field  = 'hand_vel'\n",
    "base_dir = '/Users/sherryan/area2_population_analysis'\n",
    "fig_dir = '/Users/sherryan/Desktop/paper/'\n",
    "\n",
    "# passive\n",
    "plot_condition_overview(monkey, y_field, 'pas', base_dir=base_dir, fig_dir=fig_dir, save_fig=False)\n",
    "\n",
    "# act\n",
    "plot_condition_overview(monkey, y_field, 'early_act', base_dir=base_dir, fig_dir=fig_dir, save_fig=False)\n",
    " ## whole trial\n",
    "plot_condition_overview(monkey, y_field, 'act', base_dir=base_dir, fig_dir=fig_dir, save_fig=False)\n",
    "\n",
    "\n",
    "# # plot for a single condition, i.e. passive cd+fb:\n",
    "# data_pas = load_decoding_results(monkey, y_field, 'pas')\n",
    "# fig, ax = plt.subplots(figsize=(5.5, 4))\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# plot_r2_for_model(data_pas, 'cd_fb', lag_axis=LAG_AXIS,\n",
    "#                   color='brown', label='cd+fb', ax=ax)\n",
    "# ax.set_xlabel('Time lag (ms)')\n",
    "# ax.set_ylabel('RÂ²')\n",
    "# ax.set_ylim([-0.1, 0.85])\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdt_env",
   "language": "python",
   "name": "sdt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
