{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "from Neural_Decoding.preprocessing_funcs import get_spikes_with_history\n",
    "matplotlib.rc('font', size=18)\n",
    "import scipy\n",
    "from sklearn.model_selection import KFold\n",
    "from Area2_analysis.multi_area_funcs import process_train_test\n",
    "from Area2_analysis.lr_funcs import get_sses_pred, get_sses_mean\n",
    "from Neural_Decoding.decoders import DenseNNDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = \"/Users/sherryan/area2_population_analysis/random-target/\"\n",
    "import scipy.io as sio\n",
    "data = sio.loadmat(foldername+'s1_data_trialized.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acceleration = data['acceleration']\n",
    "velocity = data['velocity']\n",
    "position = data['position']\n",
    "neural_data = data['neural_data']\n",
    "print(acceleration.shape,acceleration[0,0].shape,'kinematics')\n",
    "print(neural_data.shape,neural_data[0,0].shape,'neural data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = len(neural_data)\n",
    "print(n_trials,'trials')\n",
    "n_neurons = neural_data[0,0].shape[1]\n",
    "print(n_neurons,'neurons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Area2_analysis.multi_area_funcs import smooth_spk\n",
    "#original data has 0.01 s = 10 ms bins \n",
    "dt = 0.01\n",
    "gauss_width = 40 #in ms\n",
    "bin_width = dt*1000\n",
    "\n",
    "neural_smth_40 = []\n",
    "for i in range(n_trials):\n",
    "    neural_d = neural_data[i,0]\n",
    "    smth_40 = smooth_spk(neural_d, gauss_width, bin_width)\n",
    "    neural_smth_40.append(smth_40)\n",
    "print(len(neural_smth_40),neural_smth_40[0].shape,'neural data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(neural_data[43,0])\n",
    "plt.show()\n",
    "plt.plot(neural_smth_40[43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for i in range(len(velocity)):\n",
    "    counter+=velocity[i,0].shape[0]\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Area2_analysis.lr_funcs import nans\n",
    "def all_concat_lagged_neural(x, lag_idx):\n",
    "    x_out = nans([counter,n_neurons])\n",
    "    trial_save_idx = 0\n",
    "    for tr in range(len(x)):\n",
    "        trial_data = x[tr]\n",
    "        start, end = 20+lag_idx, len(trial_data)-80+lag_idx\n",
    "        n = len(trial_data[start:end,:])\n",
    "        x_out[trial_save_idx:trial_save_idx+n,:] = trial_data[start:end,:]\n",
    "        trial_save_idx+=n\n",
    "    return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_kin(y):\n",
    "    y_flat = nans([counter,2])\n",
    "    trial_save_idx = 0\n",
    "    for tr in range(n_trials):\n",
    "        n = len(y[tr,0])\n",
    "        y_flat[trial_save_idx:trial_save_idx+n,:] = y[tr,0]\n",
    "        trial_save_idx+=n\n",
    "    return y_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_nrn = np.nan \n",
    "for i in range(len(lag_axis)):\n",
    "    x_flat = all_concat_lagged_neural(x, i*2)[:50000]\n",
    "    x_proc = (x_flat - np.nanmean(x_flat,axis=0))/np.nanstd(x_flat,axis=0)\n",
    "    if np.isnan(invalid_nrn).all():\n",
    "        invalid_nrn = np.isnan(x_proc).any(axis=0)\n",
    "    else:\n",
    "        invalid_nrn = invalid_nrn & (np.isnan(x_proc).any(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(invalid_nrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Neural_Decoding.metrics import get_R2\n",
    "from Neural_Decoding.metrics import get_rho\n",
    "\n",
    "lag_axis = np.arange(-300, 300, 20)\n",
    "dim = n_neurons\n",
    "x = neural_smth_40\n",
    "y = velocity\n",
    "y_flat = flat_kin(y)\n",
    "y_proc = y_flat - np.nanmean(y_flat,axis=0)\n",
    "\n",
    "r2_array = nans([len(lag_axis)])\n",
    "r_array = nans([len(lag_axis)])\n",
    "coef_array = nans([len(lag_axis),2,dim])\n",
    "for i in range(len(lag_axis)):\n",
    "    x_flat = all_concat_lagged_neural(x, i*2)\n",
    "    # x_flat = x_flat[:,~invalid_nrn]\n",
    "    # dnn_all = DenseNNDecoder(units=400,dropout=0.25,num_epochs=10)\n",
    "    lr_all = GridSearchCV(Ridge(),{'alpha':np.logspace(-4,1,6)})\n",
    "    x_proc = (x_flat - np.nanmean(x_flat,axis=0))/np.nanstd(x_flat,axis=0)\n",
    "    lr_all.fit(x_proc, y_proc)\n",
    "    # #Get predictions\n",
    "    # y_pred=lr_all.predict(x_proc)\n",
    "    # #Get metric of fit\n",
    "    # r2_array[i]=np.mean(get_R2(y_proc,y_pred))\n",
    "    # r_array[i]=np.mean(get_rho(y_proc,y_pred)) \n",
    "    coef_array[i,:,:] = lr_all.best_estimator_.coef_\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=False)\n",
    "    true_concat = nans([counter,2])\n",
    "    pred_concat = nans([counter,2])\n",
    "    save_idx = 0\n",
    "    for training_set, test_set in kf.split(range(0,len(x_flat))):\n",
    "        X_train, X_test, y_train, y_test = process_train_test(x_flat,y_flat,training_set,test_set)\n",
    "        lr = Ridge(alpha=lr_all.best_params_['alpha'])\n",
    "        lr.fit(X_train, y_train)\n",
    "        # dnn = DenseNNDecoder(units=400,dropout=0.25,num_epochs=10)\n",
    "        # dnn.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[save_idx:save_idx+n,:] = y_test\n",
    "        pred_concat[save_idx:save_idx+n,:] = y_test_predicted\n",
    "        save_idx += n\n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    r2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    r = np.mean([scipy.stats.spearmanr(pred_concat[:,0], true_concat[:,0]).correlation, scipy.stats.spearmanr(pred_concat[:,1], true_concat[:,1]).correlation])\n",
    "    r2_array[i] = r2; r_array[i] = r;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_max = np.argmax(r2_array)\n",
    "x_flat = all_concat_lagged_neural(x, idx_max*2)\n",
    "# x_flat = x_flat[:,~invalid_nrn]\n",
    "best_decoder = Ridge(alpha=lr_all.best_params_['alpha'])\n",
    "x_proc = (x_flat - np.nanmean(x_flat,axis=0))/np.nanstd(x_flat,axis=0)\n",
    "best_decoder.fit(x_proc, y_proc)\n",
    "gen_r2_array = nans([len(lag_axis)])\n",
    "for i in range(len(lag_axis)):\n",
    "    x_flat = all_concat_lagged_neural(x, i*2)\n",
    "    x_flat = x_flat[:,~invalid_nrn]\n",
    "    x_proc = (x_flat - np.nanmean(x_flat,axis=0))/np.nanstd(x_flat,axis=0)\n",
    "    y_pred=best_decoder.predict(x_proc)\n",
    "    #Get metric of fit\n",
    "    gen_r2_array[i]=np.mean(get_R2(y_proc,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lag_axis,r2_array, color = 'k', label = 'Original')\n",
    "plt.plot(lag_axis,gen_r2_array, color = 'r', label = 'Best decoder')\n",
    "plt.axvline(lag_axis[idx_max],color = 'k',linestyle='--')\n",
    "plt.ylim([0,1])\n",
    "plt.legend()\n",
    "plt.title('RT-v, LR')\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lag_axis,r_array)\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Area2_analysis.lr_funcs import nans, angle_between\n",
    "\n",
    "idx_max = np.argmax(r2_array)\n",
    "\n",
    "ang_to_max_x = nans([len(lag_axis)])\n",
    "ang_to_max_y = nans([len(lag_axis)])\n",
    "for i in range(0, len(coef_array)):\n",
    "    ang_to_max_x[i] = math.degrees(angle_between(coef_array[i,0,:],coef_array[idx_max,0,:]))\n",
    "    ang_to_max_y[i] = math.degrees(angle_between(coef_array[i,1,:],coef_array[idx_max,1,:]))\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "# plt.ylim([-5, 130])\n",
    "plt.xlim([-310, 310])\n",
    "plt.scatter(lag_axis, ang_to_max_x,label = 'x-axis',color = 'green')\n",
    "plt.scatter(lag_axis, ang_to_max_y,label = 'y-axis',color = 'blue')\n",
    "plt.legend()\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('Angle (degrees)')\n",
    "mean = np.mean([ang_to_max_x[idx_max], ang_to_max_y[idx_max]])\n",
    "print(mean)\n",
    "# plt.vlines(lag_axis[idx_max],-5, mean, color = 'k',linestyle=\"dashed\")\n",
    "# plt.hlines(mean, -310, lag_axis[idx_max], color = 'k',linestyle=\"dashed\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + label + str(0) +'_angle.pdf', dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.argmax(r2_array)\n",
    "print(lag_axis[i],'ms')\n",
    "# x_flat = all_concat_lagged_neural(x, i)\n",
    "# lr_best = GridSearchCV(Ridge(),{'alpha':np.logspace(-4,4,9)})\n",
    "# x_proc = (x_flat - np.nanmean(x_flat,axis=0))/np.nanstd(x_flat,axis=0)\n",
    "# lr_best.fit(x_proc, y_proc)\n",
    "# pred = lr_best.predict(x_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lag_axis,r2_array)\n",
    "plt.axvline(lag_axis[i])\n",
    "plt.axvline(100)\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_proc[:1000,0])\n",
    "plt.plot(pred[:1000,0])\n",
    "plt.show()\n",
    "plt.plot(y_proc[:,0])\n",
    "plt.plot(pred[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.argwhere(lag_axis==80)[0,0]\n",
    "print(lag_axis[i],'ms')\n",
    "x_flat = all_concat_lagged_neural(x, i)\n",
    "lr_best = GridSearchCV(Ridge(),{'alpha':np.logspace(-4,4,9)})\n",
    "x_proc = (x_flat - np.nanmean(x_flat,axis=0))/np.nanstd(x_flat,axis=0)\n",
    "lr_best.fit(x_proc, y_proc)\n",
    "pred = lr_best.predict(x_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_proc[:1000,0])\n",
    "plt.plot(pred[:1000,0])\n",
    "plt.show()\n",
    "plt.plot(y_proc[:,0])\n",
    "plt.plot(pred[:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdt_env",
   "language": "python",
   "name": "sdt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
