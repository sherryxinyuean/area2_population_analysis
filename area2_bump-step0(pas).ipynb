{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8d2edb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable to use the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to use all neural net decoders\n"
     ]
    }
   ],
   "source": [
    "from nlb_tools.nwb_interface import NWBDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math\n",
    "def unit_vector(vector):\n",
    "    \"\"\" Returns the unit vector of the vector.  \"\"\"\n",
    "    return vector / np.linalg.norm(vector)\n",
    "\n",
    "def angle_between(v1, v2):\n",
    "    \"\"\" Returns the angle in radians between vectors 'v1' and 'v2'::\n",
    "\n",
    "            >>> angle_between((1, 0, 0), (0, 1, 0))\n",
    "            1.5707963267948966 (90 deg)\n",
    "            >>> angle_between((1, 0, 0), (1, 0, 0))\n",
    "            0.0 (0 deg)\n",
    "            >>> angle_between((1, 0, 0), (-1, 0, 0))\n",
    "            3.141592653589793 (180 deg)\n",
    "    \"\"\"\n",
    "    v1_u = unit_vector(v1)\n",
    "    v2_u = unit_vector(v2)\n",
    "    return np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))\n",
    "\n",
    "#Import standard packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy import io\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "# If you would prefer to load the '.h5' example file rather than the '.pickle' example file. You need the deepdish package\n",
    "# import deepdish as dd \n",
    "\n",
    "#Import function to get the covariate matrix that includes spike history from previous bins\n",
    "from Neural_Decoding.preprocessing_funcs import get_spikes_with_history\n",
    "\n",
    "#Import metrics\n",
    "from Neural_Decoding.metrics import get_R2\n",
    "from Neural_Decoding.metrics import get_rho\n",
    "\n",
    "#Import decoder functions\n",
    "from Neural_Decoding.decoders import WienerCascadeDecoder\n",
    "from Neural_Decoding.decoders import WienerFilterDecoder\n",
    "from Neural_Decoding.decoders import DenseNNDecoder\n",
    "from Neural_Decoding.decoders import SimpleRNNDecoder\n",
    "from Neural_Decoding.decoders import GRUDecoder\n",
    "from Neural_Decoding.decoders import LSTMDecoder\n",
    "from Neural_Decoding.decoders import XGBoostDecoder\n",
    "from Neural_Decoding.decoders import SVRDecoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def get_sses_pred(y_test,y_test_pred):\n",
    "    sse=np.sum((y_test_pred-y_test)**2,axis=0)\n",
    "    return sse\n",
    "\n",
    "def get_sses_mean(y_test):\n",
    "    y_mean=np.mean(y_test,axis=0)\n",
    "    sse_mean=np.sum((y_test-y_mean)**2,axis=0)\n",
    "    return sse_mean\n",
    "\n",
    "def nans(shape, dtype=float):\n",
    "    a = np.empty(shape, dtype)\n",
    "    a.fill(np.nan)\n",
    "    return a\n",
    "\n",
    "def vector_reject(u,v):\n",
    "    #project u on v, subtract u1 from u\n",
    "    P = np.outer(v,(v.T))/(v@(v.T))\n",
    "    u_sub = u - P@u\n",
    "#     another calculation, to double-check\n",
    "#     v_norm = np.sqrt(sum(v**2))    \n",
    "#     proj_u_on_v = (np.dot(u, v)/v_norm**2)*v\n",
    "#     u_sub = u - proj_u_on_v\n",
    "    return u_sub\n",
    "\n",
    "def calc_proj_matrix(A):\n",
    "    return A@np.linalg.inv(A.T@A)@A.T\n",
    "def calc_proj(b, A):\n",
    "    P = calc_proj_matrix(A)\n",
    "    return P@b.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dca024",
   "metadata": {},
   "source": [
    "# Single Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dc8cc31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "foldername = \"~/area2_population_analysis/s1-kinematics/actpas_NWB/\"\n",
    "monkey = \"Han_20171207\"\n",
    "filename = foldername + monkey + \"_COactpas_TD.nwb\"\n",
    "\n",
    "dataset_5ms = NWBDataset(filename, split_heldout=False)\n",
    "\n",
    "xy_vel = dataset_5ms.data['hand_vel'].to_numpy()\n",
    "xy_acc = np.diff(xy_vel, axis = 0, prepend=[xy_vel[0]])\n",
    "dataset_5ms.add_continuous_data(xy_acc,'hand_acc',chan_names = ['x','y'])\n",
    "\n",
    "dataset_5ms.resample(5)\n",
    "dataset_5ms.smooth_spk(40, name='smth_40')\n",
    "# dataset_5ms.smooth_spk(20, name='smth_20')\n",
    "bin_width = dataset_5ms.bin_width\n",
    "print(bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfaa4b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_5ms.smooth_spk(20, name='smth_20')\n",
    "# all_data = np.array(dataset_5ms.data.spikes_smth_20)\n",
    "# print(all_data.shape)\n",
    "# data_for_pca = all_data[~np.isnan(all_data).any(axis=1)]\n",
    "# print(data_for_pca.shape)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(data_for_pca)\n",
    "# pca = PCA(n_components=n_dims)\n",
    "# X = pca.fit(X)\n",
    "\n",
    "# PCA_data = nans([all_data.shape[0],n_dims])\n",
    "# idx = 0\n",
    "# for dp in all_data:\n",
    "#     dp = dp.reshape((1, -1))\n",
    "#     if np.isnan(dp).any():\n",
    "#         dp_pca = nans([1,n_dims])\n",
    "#     else:\n",
    "#         dp_pca = pca.transform(scaler.transform(dp))\n",
    "#     PCA_data[idx,:] = dp_pca\n",
    "#     idx+=1\n",
    "# print(PCA_data.shape)\n",
    "# dataset_5ms.add_continuous_data(PCA_data,'PCA_20')\n",
    "# print('PCA total var explained:',sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b3102a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218 trials\n",
      "153 neurons\n",
      "(558262, 153)\n",
      "(558262, 153)\n",
      "(558262, 20)\n",
      "PCA total var explained: 0.3873818396730201\n"
     ]
    }
   ],
   "source": [
    "n_dims = 20 # for PCA\n",
    "\n",
    "passive_mask = (dataset_5ms.trial_info.ctr_hold_bump) & (dataset_5ms.trial_info.split != 'none')\n",
    "\n",
    "\n",
    "trial_mask = passive_mask\n",
    "n_trials = dataset_5ms.trial_info.loc[trial_mask].shape[0]\n",
    "print(n_trials,'trials')\n",
    "n_neurons = dataset_5ms.data.spikes.shape[1]\n",
    "print(n_neurons,'neurons')\n",
    "\n",
    "all_data = np.array(dataset_5ms.data.spikes_smth_40)\n",
    "print(all_data.shape)\n",
    "data_for_pca = all_data[~np.isnan(all_data).any(axis=1)]\n",
    "print(data_for_pca.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data_for_pca)\n",
    "pca = PCA(n_components=n_dims)\n",
    "X = pca.fit(X)\n",
    "\n",
    "PCA_data = nans([all_data.shape[0],n_dims])\n",
    "idx = 0\n",
    "for dp in all_data:\n",
    "    dp = dp.reshape((1, -1))\n",
    "    if np.isnan(dp).any():\n",
    "        dp_pca = nans([1,n_dims])\n",
    "    else:\n",
    "        dp_pca = pca.transform(scaler.transform(dp))\n",
    "    PCA_data[idx,:] = dp_pca\n",
    "    idx+=1\n",
    "print(PCA_data.shape)\n",
    "dataset_5ms.add_continuous_data(PCA_data,'PCA')\n",
    "print('PCA total var explained:',sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fb1fa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_test(X,y,training_set,test_set):\n",
    "    X_train = X[training_set,:,:]\n",
    "    X_test = X[test_set,:,:]\n",
    "    y_train = y[training_set,:,:]\n",
    "    y_test = y[test_set,:,:]\n",
    "\n",
    "    #flat by trials\n",
    "    X_flat_train = X_train.reshape((X_train.shape[0]*X_train.shape[1]),X_train.shape[2])\n",
    "    X_flat_test = X_test.reshape((X_test.shape[0]*X_test.shape[1]),X_test.shape[2])\n",
    "    y_train=y_train.reshape((y_train.shape[0]*y_train.shape[1]),y_train.shape[2])\n",
    "    y_test=y_test.reshape((y_test.shape[0]*y_test.shape[1]),y_test.shape[2])\n",
    "    \n",
    "    X_flat_train_mean=np.nanmean(X_flat_train,axis=0)\n",
    "    X_flat_train_std=np.nanstd(X_flat_train,axis=0)   \n",
    "    #array with only 0 will have 0 std and cause errors\n",
    "    X_flat_train_std[X_flat_train_std==0] = 1\n",
    "    \n",
    "    X_flat_train=(X_flat_train-X_flat_train_mean)/X_flat_train_std\n",
    "    X_flat_test=(X_flat_test-X_flat_train_mean)/X_flat_train_std\n",
    "    y_train_mean=np.mean(y_train,axis=0)\n",
    "    y_train=y_train-y_train_mean\n",
    "    y_test=y_test-y_train_mean    \n",
    "    \n",
    "    return X_flat_train,X_flat_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9f0762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict(dataset, trial_mask, align_field, align_range, lag, x_field, y_field):\n",
    "    \"\"\"Extracts spiking and kinematic data from selected trials and fits linear decoder\"\"\"\n",
    "    # Extract rate data from selected trials\n",
    "    vel_df = dataset.make_trial_data(align_field=align_field, align_range=align_range, ignored_trials=~trial_mask)\n",
    "    # Lag alignment for kinematics and extract kinematics data from selected trials\n",
    "    lag_align_range = (align_range[0] + lag, align_range[1] + lag)\n",
    "    rates_df = dataset.make_trial_data(align_field=align_field, align_range=lag_align_range, ignored_trials=~trial_mask)\n",
    "    \n",
    "    n_trials = rates_df['trial_id'].nunique()\n",
    "    n_timepoints = int((align_range[1] - align_range[0])/dataset.bin_width)\n",
    "    n_neurons = rates_df[x_field].shape[1]\n",
    "    \n",
    "    lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)})\n",
    "    rates_array = rates_df[x_field].to_numpy()\n",
    "    vel_array = vel_df[y_field].to_numpy()\n",
    "    lr_all.fit(rates_array, vel_array)\n",
    "    pred_vel = lr_all.predict(rates_array)\n",
    "    vel_df = pd.concat([vel_df, pd.DataFrame(pred_vel, columns=dataset._make_midx('pred_vel', ['x', 'y'], 2))], axis=1)\n",
    "     \n",
    "    rates_array = rates_array.reshape(n_trials, n_timepoints, n_neurons)\n",
    "    vel_array = vel_array.reshape(n_trials, n_timepoints, 2)\n",
    "    \n",
    "    kf = KFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "    true_concat = nans([n_trials*n_timepoints,2])\n",
    "    pred_concat = nans([n_trials*n_timepoints,2])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in kf.split(range(0,n_trials)):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test, y_train, y_test = process_train_test(rates_array,vel_array,training_set,test_set)\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)}) \n",
    "        lr.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "        \n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "        trial_save_idx += n\n",
    "    \n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    print('R2:',R2) \n",
    "    return R2, lr_all.best_estimator_.coef_, vel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "561028f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_and_predict_weighted(dataset, trial_mask, align_field, align_range, lag, x_field, y_field):\n",
    "#     \"\"\"Extracts spiking and kinematic data from selected trials and fits linear decoder\"\"\"\n",
    "#     # Extract rate data from selected trials\n",
    "#     vel_df = dataset.make_trial_data(align_field=align_field, align_range=align_range, ignored_trials=~trial_mask)\n",
    "#     # Lag alignment for kinematics and extract kinematics data from selected trials\n",
    "#     lag_align_range = (align_range[0] + lag, align_range[1] + lag)\n",
    "#     rates_df = dataset.make_trial_data(align_field=align_field, align_range=lag_align_range, ignored_trials=~trial_mask)\n",
    "    \n",
    "#     n_trials = rates_df['trial_id'].nunique()\n",
    "#     n_timepoints = int((align_range[1] - align_range[0])/dataset.bin_width)\n",
    "#     n_neurons = rates_df[x_field].shape[1]\n",
    "    \n",
    "#     lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)})\n",
    "#     rates_array = rates_df[x_field].to_numpy()\n",
    "#     vel_array = vel_df[y_field].to_numpy()\n",
    "    \n",
    "#     vel_array_reshaped = vel_array.reshape(n_trials, n_timepoints, 2)\n",
    "#     sw = 1/((np.std(vel_array_reshaped[:,:,0],axis = 0) + np.std(vel_array_reshaped[:,:,1],axis = 0))/2)\n",
    "    \n",
    "#     lr_all.fit(rates_array, vel_array,sample_weight = np.tile(sw,n_trials))\n",
    "#     pred_vel = lr_all.predict(rates_array)\n",
    "#     vel_df = pd.concat([vel_df, pd.DataFrame(pred_vel, columns=dataset._make_midx('pred_vel', ['x', 'y'], 2))], axis=1)\n",
    "# #     print(lr_all.best_params_['alpha'])\n",
    "    \n",
    "#     rates_array = rates_array.reshape(n_trials, n_timepoints, n_neurons)\n",
    "#     vel_array = vel_array_reshaped\n",
    "    \n",
    "#     kf = KFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "#     true_concat = nans([n_trials*n_timepoints,2])\n",
    "#     pred_concat = nans([n_trials*n_timepoints,2])\n",
    "#     trial_save_idx = 0\n",
    "#     for training_set, test_set in kf.split(range(0,n_trials)):\n",
    "#         #split training and testing by trials\n",
    "#         X_train, X_test, y_train, y_test = process_train_test(rates_array,vel_array,training_set,test_set)\n",
    "#         lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)}) \n",
    "#         lr.fit(X_train, y_train,sample_weight = np.tile(sw,training_set.shape[0]))\n",
    "#         y_test_predicted = lr.predict(X_test)\n",
    "        \n",
    "#         n = y_test_predicted.shape[0]\n",
    "#         true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "#         pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "#         trial_save_idx += n\n",
    "    \n",
    "#     sses =get_sses_pred(true_concat,pred_concat)\n",
    "#     sses_mean=get_sses_mean(true_concat)\n",
    "#     R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "#     print('R2:',R2) \n",
    "    \n",
    "#     return R2, lr_all.best_estimator_.coef_, vel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29b5abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_and_predict_DNN(dataset, trial_mask, align_field, align_range, lag, x_field, y_field):\n",
    "#     \"\"\"Extracts spiking and kinematic data from selected trials and fits linear decoder\"\"\"\n",
    "#     # Extract rate data from selected trials\n",
    "#     vel_df = dataset.make_trial_data(align_field=align_field, align_range=align_range, ignored_trials=~trial_mask)\n",
    "#     # Lag alignment for kinematics and extract kinematics data from selected trials\n",
    "#     lag_align_range = (align_range[0] + lag, align_range[1] + lag)\n",
    "#     rates_df = dataset.make_trial_data(align_field=align_field, align_range=lag_align_range, ignored_trials=~trial_mask)\n",
    "    \n",
    "#     n_trials = rates_df['trial_id'].nunique()\n",
    "#     n_timepoints = int((align_range[1] - align_range[0])/dataset.bin_width)\n",
    "#     n_neurons = rates_df[x_field].shape[1]\n",
    "    \n",
    "#     dnn_all = DenseNNDecoder(units=400,dropout=0.25,num_epochs=10)\n",
    "#     rates_array = rates_df[x_field].to_numpy()\n",
    "#     vel_array = vel_df[y_field].to_numpy()\n",
    "#     dnn_all.fit(rates_array, vel_array)\n",
    "#     pred_vel = dnn_all.predict(rates_array)\n",
    "#     vel_df = pd.concat([vel_df, pd.DataFrame(pred_vel, columns=dataset._make_midx('pred_vel', ['x', 'y'], 2))], axis=1)\n",
    "    \n",
    "#     rates_array = rates_array.reshape(n_trials, n_timepoints, n_neurons)\n",
    "#     vel_array = vel_array.reshape(n_trials, n_timepoints, 2)\n",
    "    \n",
    "#     kf = KFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "#     true_concat = nans([n_trials*n_timepoints,2])\n",
    "#     pred_concat = nans([n_trials*n_timepoints,2])\n",
    "#     trial_save_idx = 0\n",
    "#     for training_set, test_set in kf.split(range(0,n_trials)):\n",
    "#         #split training and testing by trials\n",
    "#         X_train, X_test, y_train, y_test = process_train_test(rates_array,vel_array,training_set,test_set)\n",
    "# #         lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)}) \n",
    "# #         lr.fit(X_train, y_train)\n",
    "#         dnn = DenseNNDecoder(units=400,dropout=0.25,num_epochs=10)\n",
    "#         dnn.fit(X_train, y_train)\n",
    "#         y_test_predicted = dnn.predict(X_test)\n",
    "        \n",
    "#         n = y_test_predicted.shape[0]\n",
    "#         true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "#         pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "#         trial_save_idx += n\n",
    "    \n",
    "#     sses =get_sses_pred(true_concat,pred_concat)\n",
    "#     sses_mean=get_sses_mean(true_concat)\n",
    "#     R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "#     print('R2:',R2) \n",
    "#     return R2, vel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb0e7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub_and_predict(dataset, trial_mask, align_field, align_range, lag, x_field, y_field, weights):\n",
    "    \"\"\"Extracts spiking and kinematic data from selected trials and fits linear decoder\"\"\"\n",
    "    # Extract rate data from selected trials\n",
    "    vel_df = dataset.make_trial_data(align_field=align_field, align_range=align_range, ignored_trials=~trial_mask)\n",
    "    # Lag alignment for kinematics and extract kinematics data from selected trials\n",
    "    lag_align_range = (align_range[0] + lag, align_range[1] + lag)\n",
    "    rates_df = dataset.make_trial_data(align_field=align_field, align_range=lag_align_range, ignored_trials=~trial_mask)\n",
    "    \n",
    "    n_trials = rates_df['trial_id'].nunique()\n",
    "    n_timepoints = int((align_range[1] - align_range[0])/dataset.bin_width)\n",
    "    n_neurons = rates_df[x_field].shape[1]\n",
    "\n",
    "    rates_array = rates_df[x_field].to_numpy() - calc_proj(rates_df[x_field].to_numpy(),weights.T).T\n",
    "    vel_array = vel_df[y_field].to_numpy()\n",
    "    \n",
    "    lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)})\n",
    "    lr_all.fit(rates_array, vel_array)\n",
    "    pred_vel = lr_all.predict(rates_array)\n",
    "    vel_df = pd.concat([vel_df, pd.DataFrame(pred_vel, columns=dataset._make_midx('pred_vel', ['x', 'y'], 2))], axis=1)\n",
    "         \n",
    "    rates_array = rates_array.reshape(n_trials, n_timepoints, n_neurons)\n",
    "    vel_array = vel_array.reshape(n_trials, n_timepoints, 2)\n",
    "    \n",
    "    kf = KFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "    true_concat = nans([n_trials*n_timepoints,2])\n",
    "    pred_concat = nans([n_trials*n_timepoints,2])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in kf.split(range(0,n_trials)):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test, y_train, y_test = process_train_test(rates_array,vel_array,training_set,test_set)\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 1, 6)}) \n",
    "        lr.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "        \n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "        trial_save_idx += n\n",
    "    \n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    print('R2:',R2) \n",
    "    return R2, lr_all.best_estimator_.coef_, vel_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257bacfe",
   "metadata": {},
   "source": [
    "## with Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "106dc233",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_axis = np.arange(-300,300,20)\n",
    "x_field = 'spikes_smth_40'\n",
    "y_field ='hand_acc'\n",
    "trial_mask = passive_mask\n",
    "\n",
    "# Prepare for plotting\n",
    "plot_dir = [0.0, 90.0, 180.0, 270.0] # limit plot directions to reduce cluttering\n",
    "plot_dim = 'x' # plot x velocity\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/neurons/pas/\"\n",
    "dim = n_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f64b9c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.8898638295068193\n",
      "R2: -0.8522369802251266\n",
      "R2: -0.8115975471472179\n",
      "R2: -0.7554997755283628\n",
      "R2: -0.7434737854485292\n",
      "R2: -0.8007964321957166\n",
      "R2: -0.8487756045048165\n",
      "R2: -0.8657643564906503\n",
      "R2: -0.7593342565978145\n",
      "R2: -0.5684445507811888\n",
      "R2: -0.4060243678998967\n",
      "R2: -0.2863172540047627\n",
      "R2: -0.15810479577832992\n",
      "R2: 0.033515227502269984\n",
      "R2: 0.29157565582409484\n",
      "R2: 0.5066640559547004\n",
      "R2: 0.6477902366082235\n",
      "R2: 0.7305828697513406\n",
      "R2: 0.7583910064013076\n",
      "R2: 0.7467042880296995\n",
      "R2: 0.7199564239940925\n",
      "R2: 0.7054028626006914\n",
      "R2: 0.6795660585386087\n",
      "R2: 0.6564142441251788\n",
      "R2: 0.6455568915750696\n",
      "R2: 0.6538849706436916\n",
      "R2: 0.6662209084230863\n",
      "R2: 0.6686396634423555\n",
      "R2: 0.657763232808591\n",
      "R2: 0.6361977508709402\n",
      "R2: 0.7583910064013076\n",
      "R2: -0.9448132497141755\n",
      "R2: -0.8619628464745701\n",
      "R2: -0.7970334097899336\n",
      "R2: -0.7396899696486097\n",
      "R2: -0.7270371935971573\n",
      "R2: -0.7730857557574966\n",
      "R2: -0.8191079451883296\n",
      "R2: -0.8351801823971765\n",
      "R2: -0.7448177505344904\n",
      "R2: -0.5621837290654956\n",
      "R2: -0.4060072491913673\n",
      "R2: -0.27893796009074245\n",
      "R2: -0.13176360366869333\n",
      "R2: 0.054798306169646205\n",
      "R2: 0.27562760273176046\n",
      "R2: 0.4492193341040186\n",
      "R2: 0.5526075191921163\n",
      "R2: 0.5966081515057657\n",
      "R2: 0.6064028628437783\n",
      "R2: 0.6155178617438728\n",
      "R2: 0.6300861117798882\n",
      "R2: 0.6739318451828007\n",
      "R2: 0.6730759962421704\n",
      "R2: 0.6495223500953804\n",
      "R2: 0.635095430280129\n",
      "R2: 0.6471330960820225\n",
      "R2: 0.6620897753867897\n",
      "R2: 0.66596504430443\n",
      "R2: 0.6580156167731538\n",
      "R2: 0.6350627403592115\n",
      "R2: 0.6739318451828007\n",
      "R2: -0.9225027584825838\n",
      "R2: -0.8482276565461475\n",
      "R2: -0.8004716233728335\n",
      "R2: -0.7640285352191865\n",
      "R2: -0.7546908034007587\n",
      "R2: -0.7800272274922571\n",
      "R2: -0.8059124619205187\n",
      "R2: -0.8005937453436187\n",
      "R2: -0.7137057278100736\n",
      "R2: -0.5378339257520601\n",
      "R2: -0.38052205189758004\n",
      "R2: -0.25897363004683593\n",
      "R2: -0.12397804529133638\n",
      "R2: 0.050961305545783264\n",
      "R2: 0.2641965675170541\n",
      "R2: 0.441184403418993\n",
      "R2: 0.5557930528549782\n",
      "R2: 0.6042733348521754\n",
      "R2: 0.5860696144234872\n",
      "R2: 0.5287652990277286\n",
      "R2: 0.43120037758495633\n",
      "R2: 0.33904048088005023\n",
      "R2: 0.3591677219152267\n",
      "R2: 0.4465534140677534\n",
      "R2: 0.5428935399918619\n",
      "R2: 0.6182772851771996\n",
      "R2: 0.6574446888129423\n",
      "R2: 0.6691589847746051\n",
      "R2: 0.6601911409203088\n",
      "R2: 0.6294153215564389\n",
      "R2: 0.6691589847746051\n",
      "R2: -0.9395811557716749\n",
      "R2: -0.840696572649732\n",
      "R2: -0.7714840034794974\n",
      "R2: -0.7382647191896627\n",
      "R2: -0.7386967609385995\n",
      "R2: -0.7582086330386779\n",
      "R2: -0.7895342152444045\n",
      "R2: -0.7836659056814994\n",
      "R2: -0.6991707538918395\n",
      "R2: -0.5372073396682866\n",
      "R2: -0.379881138846764\n",
      "R2: -0.24395610805505474\n",
      "R2: -0.09328095553574411\n",
      "R2: 0.07213999465404353\n",
      "R2: 0.26398722677059705\n",
      "R2: 0.44467990148277303\n",
      "R2: 0.5603888526958747\n",
      "R2: 0.6070723662671156\n",
      "R2: 0.5911121954427969\n",
      "R2: 0.5292493817829944\n",
      "R2: 0.40909049806437947\n",
      "R2: 0.3163553951120295\n",
      "R2: 0.32419234954798304\n",
      "R2: 0.36252617819955124\n",
      "R2: 0.37643003023545707\n",
      "R2: 0.32798429876898605\n",
      "R2: 0.24196541696639007\n",
      "R2: 0.21634065799147983\n",
      "R2: 0.3107407929653795\n",
      "R2: 0.4154612956923778\n",
      "R2: 0.6070723662671156\n",
      "R2: -0.4748225655303764\n",
      "R2: -0.4670257628767194\n",
      "R2: -0.449614072817039\n",
      "R2: -0.443725617497166\n",
      "R2: -0.4425549215908753\n",
      "R2: -0.43102134772714074\n",
      "R2: -0.40423947349325684\n",
      "R2: -0.3736624407005378\n",
      "R2: -0.3473155184959842\n",
      "R2: -0.30341075358383796\n",
      "R2: -0.2137848780037077\n",
      "R2: -0.0855906331077223\n",
      "R2: 0.05987202684304038\n",
      "R2: 0.22514198894888948\n",
      "R2: 0.4081533403404436\n",
      "R2: 0.5572731909375283\n",
      "R2: 0.6388978775378388\n",
      "R2: 0.6614767082464682\n",
      "R2: 0.6483307066027983\n",
      "R2: 0.6247343534541321\n",
      "R2: 0.6020799664949149\n",
      "R2: 0.5869951515373006\n",
      "R2: 0.5788567036224455\n",
      "R2: 0.5681738204847923\n",
      "R2: 0.5528254088663882\n",
      "R2: 0.5360596026307872\n",
      "R2: 0.5243721636590839\n",
      "R2: 0.5186222166995589\n",
      "R2: 0.5129921084504049\n",
      "R2: 0.49535122643500396\n",
      "R2: 0.6614767082464682\n",
      "R2: -0.4705367752043168\n",
      "R2: -0.45492514848243193\n",
      "R2: -0.4378136490195159\n",
      "R2: -0.4331970889594843\n",
      "R2: -0.43136267469549305\n",
      "R2: -0.4188670305800495\n",
      "R2: -0.39280552793078294\n",
      "R2: -0.3641256975662164\n",
      "R2: -0.33988969438982064\n",
      "R2: -0.29730396036004536\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(lag_axis)):\n\u001b[1;32m     54\u001b[0m     lag \u001b[38;5;241m=\u001b[39m lag_axis[i]\n\u001b[0;32m---> 55\u001b[0m     r2, coef,_ \u001b[38;5;241m=\u001b[39m \u001b[43msub_and_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_5ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmove_onset_time\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_range\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlag\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx_field\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_field\u001b[49m\u001b[43m,\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     sub_r2_array[i] \u001b[38;5;241m=\u001b[39m r2\n\u001b[1;32m     57\u001b[0m     sub_coef_array[i,:,:] \u001b[38;5;241m=\u001b[39m coef\n",
      "Cell \u001b[0;32mIn [8], line 32\u001b[0m, in \u001b[0;36msub_and_predict\u001b[0;34m(dataset, trial_mask, align_field, align_range, lag, x_field, y_field, weights)\u001b[0m\n\u001b[1;32m     30\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m process_train_test(rates_array,vel_array,training_set,test_set)\n\u001b[1;32m     31\u001b[0m lr \u001b[38;5;241m=\u001b[39m GridSearchCV(Ridge(), {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m: np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m6\u001b[39m)}) \n\u001b[0;32m---> 32\u001b[0m \u001b[43mlr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m y_test_predicted \u001b[38;5;241m=\u001b[39m lr\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     35\u001b[0m n \u001b[38;5;241m=\u001b[39m y_test_predicted\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[38;5;241m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:841\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    835\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    836\u001b[0m         all_candidate_params, n_splits, all_out,\n\u001b[1;32m    837\u001b[0m         all_more_results)\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 841\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    845\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1288\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1288\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:795\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    791\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    792\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    793\u001b[0m               n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits))\n\u001b[0;32m--> 795\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m                                       \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m                   \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    813\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    814\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:1044\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1044\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1048\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:859\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 859\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:777\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    776\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 777\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    779\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py:222\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 222\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:593\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    591\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 593\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:762\u001b[0m, in \u001b[0;36mRidge.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit Ridge regression model.\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \n\u001b[1;32m    746\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[38;5;124;03m    self : returns an instance of self.\u001b[39;00m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:593\u001b[0m, in \u001b[0;36m_BaseRidge.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    590\u001b[0m         \u001b[38;5;66;03m# for dense matrices or when intercept is set to 0\u001b[39;00m\n\u001b[1;32m    591\u001b[0m         params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 593\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43m_ridge_regression\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_intercept(X_offset, y_offset, X_scale)\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:471\u001b[0m, in \u001b[0;36m_ridge_regression\u001b[0;34m(X, y, alpha, sample_weight, solver, max_iter, tol, verbose, random_state, return_n_iter, return_intercept, X_scale, X_offset, check_input)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 471\u001b[0m         coef \u001b[38;5;241m=\u001b[39m \u001b[43m_solve_cholesky\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m linalg\u001b[38;5;241m.\u001b[39mLinAlgError:\n\u001b[1;32m    473\u001b[0m         \u001b[38;5;66;03m# use SVD solver if matrix is singular\u001b[39;00m\n\u001b[1;32m    474\u001b[0m         solver \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvd\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py:140\u001b[0m, in \u001b[0;36m_solve_cholesky\u001b[0;34m(X, y, alpha)\u001b[0m\n\u001b[1;32m    137\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    138\u001b[0m n_targets \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 140\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m Xy \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X\u001b[38;5;241m.\u001b[39mT, y, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    143\u001b[0m one_alpha \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray_equal(alpha, \u001b[38;5;28mlen\u001b[39m(alpha) \u001b[38;5;241m*\u001b[39m [alpha[\u001b[38;5;241m0\u001b[39m]])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[38;5;241m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/extmath.py:152\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    150\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (sparse\u001b[38;5;241m.\u001b[39missparse(a) \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m dense_output \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ranges = [(0,120),(-100,120)]\n",
    "labels = ['_early_acc_','_long_acc_']\n",
    "\n",
    "for pred_range, label in zip(ranges, labels):\n",
    "    x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "    curr_r2_array = nans([len(lag_axis)])\n",
    "    curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "        curr_r2_array[i] = r2\n",
    "        curr_coef_array[i,:,:] = coef\n",
    "\n",
    "    idx_max = np.argmax(curr_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    _, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial[y_field][plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel(plot_dim + '_' + y_field)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + 'true.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel(plot_dim + '_' + y_field)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(lag_axis, curr_r2_array)\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.title('R2 score predicting ' + y_field + ' ' + str(pred_range))\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    weights = curr_coef_array[idx_max,:,:]\n",
    "    for iter in range(0,3):  \n",
    "        #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "        sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "        sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "        for i in range(len(lag_axis)):\n",
    "            lag = lag_axis[i]\n",
    "            r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "            sub_r2_array[i] = r2\n",
    "            sub_coef_array[i,:,:] = coef\n",
    "\n",
    "        plt.plot(lag_axis,sub_r2_array)\n",
    "        plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "        idx_max = np.argmax(sub_r2_array)\n",
    "        time_max = lag_axis[idx_max]\n",
    "        plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "        plt.legend()\n",
    "        plt.xlabel('Time lag (ms)')\n",
    "        plt.ylabel('R2')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "        plt.close()\n",
    "\n",
    "        _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "        for trial_dir, color in zip(plot_dir, colors):\n",
    "            cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "            for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "                plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "        plt.xlabel('Time (ms)')\n",
    "        plt.ylabel(plot_dim + '_' + y_field)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "        plt.close()\n",
    "        \n",
    "        #stack the decoding dimensions to be projected out\n",
    "        weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f030f4",
   "metadata": {},
   "source": [
    "## with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56d6d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_field = 'PCA'\n",
    "y_field ='hand_acc'\n",
    "lag_axis = np.arange(-300,300,20)\n",
    "\n",
    "# Prepare for plotting\n",
    "plot_dir = [0.0, 90.0, 180.0, 270.0] # limit plot directions to reduce cluttering\n",
    "plot_dim = 'x' # plot x velocity\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/PCA/pas/\"\n",
    "dim = n_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "629b2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_range = (-100, 120)\n",
    "# vel_df = dataset_5ms.make_trial_data(align_field='move_onset_time', align_range=plot_range, ignored_trials=~passive_mask)\n",
    "\n",
    "# x_axis = np.arange(plot_range[0], plot_range[1], dataset_5ms.bin_width)\n",
    "# plot_dims = 10\n",
    "# fig,ax=plt.subplots(plot_dims,1,figsize=(10,20))\n",
    "\n",
    "# for i in range(plot_dims):\n",
    "#     for _, trial in vel_df.groupby('trial_id'):\n",
    "#         ax[i].plot(x_axis,trial.PCA.to_numpy()[:,i], color = 'k',linewidth = 0.5)\n",
    "#         ax[i].axvline(0,color ='k',ls = '--')\n",
    "#         if i<plot_dims-1:\n",
    "#             ax[i].set_xticks([])\n",
    "#         else:\n",
    "#             ax[i].set_xlabel('Time (ms)')\n",
    "#         ax[i].set_ylabel('Dim. '+str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f37ed90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: -0.08185084354804384\n",
      "R2: -0.08503156752719776\n",
      "R2: -0.099260865743386\n",
      "R2: -0.12084635139438826\n",
      "R2: -0.14382787417843979\n",
      "R2: -0.15946896021294288\n",
      "R2: -0.16126559041643618\n",
      "R2: -0.15096345037490355\n",
      "R2: -0.13301125416968285\n",
      "R2: -0.09687321215897726\n",
      "R2: -0.014779485043502794\n",
      "R2: 0.09435603376549107\n",
      "R2: 0.21251853814519528\n",
      "R2: 0.34892591393214245\n",
      "R2: 0.5010501081903735\n",
      "R2: 0.6389287255461553\n",
      "R2: 0.7322283702930646\n",
      "R2: 0.779981000658927\n",
      "R2: 0.7963802455990409\n",
      "R2: 0.7918502448396385\n",
      "R2: 0.7736296944859244\n",
      "R2: 0.7499037208940389\n",
      "R2: 0.728608537302551\n",
      "R2: 0.7135885381151439\n",
      "R2: 0.7056044782599517\n",
      "R2: 0.7024800859209658\n",
      "R2: 0.6992154087210349\n",
      "R2: 0.6939409233683762\n",
      "R2: 0.6876517972457852\n",
      "R2: 0.6776900518848417\n",
      "R2: 0.7963802455990409\n",
      "R2: -0.07522485916783506\n",
      "R2: -0.07428959317880635\n",
      "R2: -0.08273633159362936\n",
      "R2: -0.10245193397270858\n",
      "R2: -0.1286173890851745\n",
      "R2: -0.1492752517310909\n",
      "R2: -0.15530121197682223\n",
      "R2: -0.14631835712185404\n",
      "R2: -0.12644146442369397\n",
      "R2: -0.09227227599987664\n",
      "R2: -0.027664051337445983\n",
      "R2: 0.06900144895074423\n",
      "R2: 0.1807891337365367\n",
      "R2: 0.3055323595410723\n",
      "R2: 0.43981008309604885\n",
      "R2: 0.5561576566474629\n",
      "R2: 0.620936267476762\n",
      "R2: 0.6361387972645867\n",
      "R2: 0.6380998028255578\n",
      "R2: 0.6506847864932502\n",
      "R2: 0.6719573579079057\n",
      "R2: 0.6908838350327429\n",
      "R2: 0.6985804471567484\n",
      "R2: 0.6918046146373402\n",
      "R2: 0.6779472561285342\n",
      "R2: 0.6688325159657007\n",
      "R2: 0.6646325371330065\n",
      "R2: 0.6575686900664499\n",
      "R2: 0.642708959665906\n",
      "R2: 0.6176452335725036\n",
      "R2: 0.6985804471567484\n",
      "R2: -0.0506142614789582\n",
      "R2: -0.053475672049910994\n",
      "R2: -0.06416052573938202\n",
      "R2: -0.083022424661094\n",
      "R2: -0.10603802455783096\n",
      "R2: -0.12264766513366432\n",
      "R2: -0.12607651210985593\n",
      "R2: -0.11725813096656235\n",
      "R2: -0.09857716768512237\n",
      "R2: -0.06527520765105455\n",
      "R2: -0.0047785220306435505\n",
      "R2: 0.08305100575924651\n",
      "R2: 0.18647428580016046\n",
      "R2: 0.3042688954442897\n",
      "R2: 0.43284066183640346\n",
      "R2: 0.5468142679289394\n",
      "R2: 0.6081473729255996\n",
      "R2: 0.5931784460043207\n",
      "R2: 0.5065830416880608\n",
      "R2: 0.39058804862235064\n",
      "R2: 0.31634441095511057\n",
      "R2: 0.32256232387649153\n",
      "R2: 0.3926230045606437\n",
      "R2: 0.4806176680824391\n",
      "R2: 0.5528976882679316\n",
      "R2: 0.6005172372188002\n",
      "R2: 0.6255595002660683\n",
      "R2: 0.6335939508483225\n",
      "R2: 0.6292386841924055\n",
      "R2: 0.6121068468737166\n",
      "R2: 0.6335939508483225\n",
      "R2: -0.03926289015975848\n",
      "R2: -0.04636996538817706\n",
      "R2: -0.06011348378672543\n",
      "R2: -0.07784030924701124\n",
      "R2: -0.09576070171809592\n",
      "R2: -0.10639754156571213\n",
      "R2: -0.10577532516227173\n",
      "R2: -0.09613651950721414\n",
      "R2: -0.07947187721513482\n",
      "R2: -0.05239560079532346\n",
      "R2: -0.0034157894547948153\n",
      "R2: 0.07154963147895721\n",
      "R2: 0.166295209092702\n",
      "R2: 0.2794457219926072\n",
      "R2: 0.3990972840187863\n",
      "R2: 0.49095060263403123\n",
      "R2: 0.5208556647235403\n",
      "R2: 0.4886942256387621\n",
      "R2: 0.41827895881781907\n",
      "R2: 0.3375822170759899\n",
      "R2: 0.2833899493091965\n",
      "R2: 0.279452542132711\n",
      "R2: 0.309370097375014\n",
      "R2: 0.32929802847901946\n",
      "R2: 0.3145340729798616\n",
      "R2: 0.2732539140271393\n",
      "R2: 0.22921739870977254\n",
      "R2: 0.20381001305204882\n",
      "R2: 0.2044903813878478\n",
      "R2: 0.22285424862783043\n",
      "R2: 0.5208556647235403\n",
      "R2: -0.04709948607100434\n",
      "R2: -0.04999496765406075\n",
      "R2: -0.058585314414455025\n",
      "R2: -0.07004134351127211\n",
      "R2: -0.08123040224916145\n",
      "R2: -0.08856944820517332\n",
      "R2: -0.08873362102534088\n",
      "R2: -0.08088928059167655\n",
      "R2: -0.06820114950103529\n",
      "R2: -0.04952780641880006\n",
      "R2: -0.0035881413167071496\n",
      "R2: 0.0808787244751451\n",
      "R2: 0.19034230989364176\n",
      "R2: 0.32177402526104926\n",
      "R2: 0.46777076117894034\n",
      "R2: 0.5966926348464048\n",
      "R2: 0.6710714357151173\n",
      "R2: 0.6820296829211585\n",
      "R2: 0.6521774008575119\n",
      "R2: 0.6130461708838232\n",
      "R2: 0.5857297935436048\n",
      "R2: 0.5754724418484289\n",
      "R2: 0.5743031658174733\n",
      "R2: 0.5697756648989353\n",
      "R2: 0.5557957728024672\n",
      "R2: 0.5343959548362878\n",
      "R2: 0.5119428782453337\n",
      "R2: 0.49506910941542137\n",
      "R2: 0.4850465117350504\n",
      "R2: 0.4747984763863333\n",
      "R2: 0.6820296829211585\n",
      "R2: -0.041818013837960466\n",
      "R2: -0.044654119068780807\n",
      "R2: -0.052010289533281906\n",
      "R2: -0.06215486136406634\n",
      "R2: -0.07333775075096538\n",
      "R2: -0.08199923236633255\n",
      "R2: -0.0837981274343782\n",
      "R2: -0.07723434242527794\n",
      "R2: -0.06504073150426093\n",
      "R2: -0.048719079581174274\n",
      "R2: -0.018077992190481895\n",
      "R2: 0.043117853238041404\n",
      "R2: 0.1364072642282339\n",
      "R2: 0.2529408435002103\n",
      "R2: 0.37581711013321795\n",
      "R2: 0.4691044998207189\n",
      "R2: 0.4985075916689542\n",
      "R2: 0.4773193707193999\n",
      "R2: 0.45945546737553833\n",
      "R2: 0.4714291261042448\n",
      "R2: 0.4990991347695636\n",
      "R2: 0.5246579947200025\n",
      "R2: 0.5412482907833942\n",
      "R2: 0.5457040986813113\n",
      "R2: 0.5354500005169043\n",
      "R2: 0.5126115174437527\n",
      "R2: 0.48380508680679957\n",
      "R2: 0.45425431369123326\n",
      "R2: 0.4229485896049977\n",
      "R2: 0.3831079431504074\n",
      "R2: 0.5457040986813113\n",
      "R2: -0.02937205379400387\n",
      "R2: -0.03232483796321861\n",
      "R2: -0.039664857995213465\n",
      "R2: -0.05006344903966875\n",
      "R2: -0.06147737220097338\n",
      "R2: -0.07021384658221641\n",
      "R2: -0.07276098218762317\n",
      "R2: -0.06826057804065333\n",
      "R2: -0.05916275979139307\n",
      "R2: -0.04686328344190094\n",
      "R2: -0.022444175402059674\n",
      "R2: 0.030180019283875814\n",
      "R2: 0.11554241520024022\n",
      "R2: 0.22507691485589287\n",
      "R2: 0.34171179800981855\n",
      "R2: 0.43537095341377074\n",
      "R2: 0.47902846273369004\n",
      "R2: 0.4723843186300831\n",
      "R2: 0.43575860069915595\n",
      "R2: 0.3845889331351068\n",
      "R2: 0.3228570285581214\n",
      "R2: 0.25711731742984856\n",
      "R2: 0.20417737729639962\n",
      "R2: 0.180645143441591\n",
      "R2: 0.18936517749917414\n",
      "R2: 0.22037390307398963\n",
      "R2: 0.2613491520303515\n",
      "R2: 0.30217488927480696\n",
      "R2: 0.33046939556791\n",
      "R2: 0.3325859437087427\n",
      "R2: 0.47902846273369004\n",
      "R2: -0.02802973834851552\n",
      "R2: -0.03037663897193288\n",
      "R2: -0.03501375025124687\n",
      "R2: -0.041036325197335355\n",
      "R2: -0.04785253397959366\n",
      "R2: -0.05373589505968179\n",
      "R2: -0.05635035055755844\n",
      "R2: -0.054353287440982445\n",
      "R2: -0.04902843039632532\n",
      "R2: -0.0432972677943988\n",
      "R2: -0.03789120888863673\n",
      "R2: -0.03038462141667919\n",
      "R2: -0.017282874927631697\n",
      "R2: 0.005724284032013305\n",
      "R2: 0.042672009340409045\n",
      "R2: 0.0932790536918634\n",
      "R2: 0.15080855491618161\n",
      "R2: 0.2053327573111372\n",
      "R2: 0.24571227935597928\n",
      "R2: 0.260604470371268\n",
      "R2: 0.24547078713377002\n",
      "R2: 0.2091982443119984\n",
      "R2: 0.1733704387254581\n",
      "R2: 0.16076471145700988\n",
      "R2: 0.17871409704664132\n",
      "R2: 0.21731764006956522\n",
      "R2: 0.2621674566594625\n",
      "R2: 0.3028027499358973\n",
      "R2: 0.3281063493829871\n",
      "R2: 0.3269963557785459\n",
      "R2: 0.3281063493829871\n"
     ]
    }
   ],
   "source": [
    "ranges = [(0,120),(-100,120)]\n",
    "labels = ['_early_acc_','_long_acc_']\n",
    "\n",
    "for pred_range, label in zip(ranges, labels):\n",
    "    x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "    curr_r2_array = nans([len(lag_axis)])\n",
    "    curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "        curr_r2_array[i] = r2\n",
    "        curr_coef_array[i,:,:] = coef\n",
    "\n",
    "    idx_max = np.argmax(curr_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    _, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial[y_field][plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel(plot_dim + '_' + y_field)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + 'true.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel(plot_dim + '_' + y_field)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(lag_axis, curr_r2_array)\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.title('R2 score predicting ' + y_field + ' ' + str(pred_range))\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    weights = curr_coef_array[idx_max,:,:]\n",
    "    for iter in range(0,3):  \n",
    "        #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "        sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "        sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "        for i in range(len(lag_axis)):\n",
    "            lag = lag_axis[i]\n",
    "            r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "            sub_r2_array[i] = r2\n",
    "            sub_coef_array[i,:,:] = coef\n",
    "\n",
    "        plt.plot(lag_axis,sub_r2_array)\n",
    "        plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "        idx_max = np.argmax(sub_r2_array)\n",
    "        time_max = lag_axis[idx_max]\n",
    "        plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "        plt.legend()\n",
    "        plt.xlabel('Time lag (ms)')\n",
    "        plt.ylabel('R2')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "        plt.close()\n",
    "\n",
    "        _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "        for trial_dir, color in zip(plot_dir, colors):\n",
    "            cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "            for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "                plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "        plt.xlabel('Time (ms)')\n",
    "        plt.ylabel(plot_dim + '_' + y_field)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "        plt.close()\n",
    "        \n",
    "        #stack the decoding dimensions to be projected out\n",
    "        weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bf152a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e99868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80e66b89",
   "metadata": {},
   "source": [
    "# Multi Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8649848a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "dataset_50ms = NWBDataset(filename, split_heldout=False)\n",
    "xy_vel = dataset_50ms.data['hand_vel'].to_numpy()\n",
    "xy_acc = np.diff(xy_vel, axis = 0, prepend=[xy_vel[0]])\n",
    "dataset_50ms.add_continuous_data(xy_acc,'hand_acc',chan_names = ['x','y'])\n",
    "\n",
    "dataset_50ms.resample(50)\n",
    "print(dataset_50ms.bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fda3bfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218 trials\n",
      "153 neurons\n",
      "(55827, 153)\n",
      "(55827, 153)\n",
      "(55827, 20)\n",
      "PCA total var explained: 0.29862936918522437\n"
     ]
    }
   ],
   "source": [
    "n_dims = 20 # for PCA\n",
    "\n",
    "passive_mask = (dataset_50ms.trial_info.ctr_hold_bump) & (dataset_50ms.trial_info.split != 'none')\n",
    "\n",
    "trial_mask = passive_mask\n",
    "n_trials = dataset_50ms.trial_info.loc[trial_mask].shape[0]\n",
    "print(n_trials,'trials')\n",
    "n_neurons = dataset_50ms.data.spikes.shape[1]\n",
    "print(n_neurons,'neurons')\n",
    "\n",
    "all_data = np.array(dataset_50ms.data.spikes)\n",
    "print(all_data.shape)\n",
    "data_for_pca = all_data[~np.isnan(all_data).any(axis=1)]\n",
    "print(data_for_pca.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data_for_pca)\n",
    "pca = PCA(n_components=n_dims)\n",
    "X = pca.fit(X)\n",
    "\n",
    "PCA_data = nans([all_data.shape[0],n_dims])\n",
    "idx = 0\n",
    "for dp in all_data:\n",
    "    dp = dp.reshape((1, -1))\n",
    "    if np.isnan(dp).any():\n",
    "        dp_pca = nans([1,n_dims])\n",
    "    else:\n",
    "        dp_pca = pca.transform(scaler.transform(dp))\n",
    "    PCA_data[idx,:] = dp_pca\n",
    "    idx+=1\n",
    "print(PCA_data.shape)\n",
    "dataset_50ms.add_continuous_data(PCA_data,'PCA')\n",
    "print('PCA total var explained:',sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a348315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 time bins\n",
      "(218, 22, 153)\n",
      "(218, 22, 2)\n",
      "(218, 22, 2)\n",
      "(218, 22, 20)\n"
     ]
    }
   ],
   "source": [
    "passive_data = dataset_50ms.make_trial_data(align_field='move_onset_time', align_range=(-400, 700), ignored_trials=~trial_mask)\n",
    "for idx, trial in passive_data.groupby('trial_id'):\n",
    "    n_timepoints = trial.shape[0]\n",
    "    break\n",
    "print(n_timepoints,'time bins')\n",
    "\n",
    "passive_trials_neuron = nans([n_trials,n_timepoints,n_neurons])\n",
    "passive_trials_vel = nans([n_trials,n_timepoints,2])\n",
    "passive_trials_acc = nans([n_trials,n_timepoints,2])\n",
    "passive_trials_pca = nans([n_trials,n_timepoints,n_dims])\n",
    "i = 0\n",
    "for idx, trial in passive_data.groupby('trial_id'):\n",
    "    passive_trials_neuron[i,:,:]=trial.spikes.to_numpy()\n",
    "    passive_trials_vel[i,:,:]=trial.hand_vel.to_numpy()\n",
    "    passive_trials_acc[i,:,:]=trial.hand_acc.to_numpy()\n",
    "    passive_trials_pca[i,:,:]=trial.PCA.to_numpy()\n",
    "    i+=1\n",
    "print(passive_trials_neuron.shape)\n",
    "print(passive_trials_vel.shape)\n",
    "print(passive_trials_acc.shape)\n",
    "print(passive_trials_pca.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef332cd6",
   "metadata": {},
   "source": [
    "## with Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5500a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_range = [-400,700]\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/neurons/pas/\"\n",
    "passive_x = passive_trials_neuron\n",
    "passive_y = passive_trials_acc\n",
    "y_type = 'acceleration'\n",
    "\n",
    "ranges = [(0,120),(-100,120)]\n",
    "labels = ['early_acc','long_acc']\n",
    "\n",
    "dim = n_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c8378b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with 0 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.805239900695789\n",
      "Predicting with 0 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.868496336807755\n",
      "Predicting with 0 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8926474318137211\n",
      "Predicting with 0 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.9030208987855227\n",
      "Predicting with 0 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.9052965666073302\n",
      "Predicting with 0 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.9118100753678338\n",
      "Predicting with 0 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.9164170928322575\n",
      "Predicting with 0 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.9176492448579978\n",
      "Predicting with 0 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.9187437646802838\n",
      "Predicting with 0 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.9180105858015866\n",
      "Predicting with 0 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.9164616042911174\n",
      "Predicting with -50 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7795034028320339\n",
      "Predicting with -50 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.871847081813525\n",
      "Predicting with -50 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8915432679729756\n",
      "Predicting with -50 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.9036739335415866\n",
      "Predicting with -50 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.9092318229033587\n",
      "Predicting with -50 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.9171934866530186\n",
      "Predicting with -50 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.9204299954521877\n",
      "Predicting with -50 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.9215776275219365\n",
      "Predicting with -50 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.9215600356083107\n",
      "Predicting with -50 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.9206407463579022\n",
      "Predicting with -50 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.9196361798169579\n",
      "Predicting with -100 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7821160933607705\n",
      "Predicting with -100 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8749819622397651\n",
      "Predicting with -100 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8976775190330119\n",
      "Predicting with -100 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.9098960812973761\n",
      "Predicting with -100 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.9128738986843022\n",
      "Predicting with -100 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.9208203127120238\n",
      "Predicting with -100 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.9233711488715914\n",
      "Predicting with -100 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.9223741752369813\n",
      "Predicting with -100 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.9215836480485557\n",
      "Predicting with -100 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.9208114793323307\n",
      "Predicting with -100 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.9202910856345309\n",
      "Predicting with -150 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7704693336736552\n",
      "Predicting with -150 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8674295720805553\n",
      "Predicting with -150 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8981608180738079\n",
      "Predicting with -150 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.9082936144942216\n",
      "Predicting with -150 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.9124578897419013\n",
      "Predicting with -150 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.9192658900663588\n",
      "Predicting with -150 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.9208239480853869\n",
      "Predicting with -150 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.9208139103601884\n",
      "Predicting with -150 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.9196208583587298\n",
      "Predicting with -150 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.9197639660829245\n",
      "Predicting with -150 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.9194413914496818\n",
      "Predicting with -200 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7499137628756178\n",
      "Predicting with -200 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8636278761489395\n",
      "Predicting with -200 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.893551141500156\n",
      "Predicting with -200 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.904544196737779\n",
      "Predicting with -200 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.9110264828311838\n",
      "Predicting with -200 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.9186674662340254\n",
      "Predicting with -200 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.9223657730523337\n",
      "Predicting with -200 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.9220828728684215\n",
      "Predicting with -200 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.9211365231901844\n",
      "Predicting with -200 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.921249759607019\n",
      "Predicting with -200 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.9209381525651587\n",
      "Predicting with -250 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7660807343625053\n",
      "Predicting with -250 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8685877709442238\n",
      "Predicting with -250 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8937781907658975\n",
      "Predicting with -250 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.9038783813446601\n",
      "Predicting with -250 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.9088018285743862\n",
      "Predicting with -250 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.9159089629634765\n",
      "Predicting with -250 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.9194834160024061\n",
      "Predicting with -250 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.9194097523422855\n",
      "Predicting with -250 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.9184749860302974\n",
      "Predicting with -250 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.9190778745686752\n",
      "Predicting with -250 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.9186793491869198\n",
      "Predicting with -300 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7721731141841344\n",
      "Predicting with -300 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8682829646802983\n",
      "Predicting with -300 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8918172504908353\n",
      "Predicting with -300 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.9036798593501286\n",
      "Predicting with -300 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.908534616354721\n",
      "Predicting with -300 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.9156810008409948\n",
      "Predicting with -300 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.9188921425800307\n",
      "Predicting with -300 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.9198076673436971\n",
      "Predicting with -300 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.9193092519168236\n",
      "Predicting with -300 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.9187744980644241\n",
      "Predicting with -300 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.9183161701708726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/3p5f6szx247fkf6ftdgp147w0000gn/T/ipykernel_6110/2373499165.py:82: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with 0 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7606016722516974\n",
      "Predicting with 0 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8366244148232961\n",
      "Predicting with 0 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8547987086625825\n",
      "Predicting with 0 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8650211708095374\n",
      "Predicting with 0 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8682003247484064\n",
      "Predicting with 0 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8715165115673208\n",
      "Predicting with 0 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8741721034121513\n",
      "Predicting with 0 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8708049144830092\n",
      "Predicting with 0 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8688116949017466\n",
      "Predicting with 0 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8689309882741179\n",
      "Predicting with 0 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8669939847624489\n",
      "Predicting with -50 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7658868226088662\n",
      "Predicting with -50 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8403682954594863\n",
      "Predicting with -50 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8570062014633169\n",
      "Predicting with -50 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.866518725738413\n",
      "Predicting with -50 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8692271229863695\n",
      "Predicting with -50 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8723470321917499\n",
      "Predicting with -50 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8754319169501753\n",
      "Predicting with -50 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8721865152820281\n",
      "Predicting with -50 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8703781347079959\n",
      "Predicting with -50 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8709978923066355\n",
      "Predicting with -50 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8641065696209831\n",
      "Predicting with -100 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7633820222982364\n",
      "Predicting with -100 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8388910527133062\n",
      "Predicting with -100 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8563448979393368\n",
      "Predicting with -100 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.866381726784829\n",
      "Predicting with -100 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8688570633422081\n",
      "Predicting with -100 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8725387866039983\n",
      "Predicting with -100 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8750289116093959\n",
      "Predicting with -100 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8717379310696166\n",
      "Predicting with -100 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8698581624779016\n",
      "Predicting with -100 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8663596372086035\n",
      "Predicting with -100 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8646833757938048\n",
      "Predicting with -150 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.751936507021101\n",
      "Predicting with -150 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8322143895559956\n",
      "Predicting with -150 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8507550062292574\n",
      "Predicting with -150 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8613152981067091\n",
      "Predicting with -150 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8639653331515005\n",
      "Predicting with -150 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8675078827338761\n",
      "Predicting with -150 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8702805221317932\n",
      "Predicting with -150 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8676280960088669\n",
      "Predicting with -150 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8608834876448913\n",
      "Predicting with -150 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8632748641132914\n",
      "Predicting with -150 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8617905158456325\n",
      "Predicting with -200 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7397491201280555\n",
      "Predicting with -200 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8285673118249964\n",
      "Predicting with -200 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8480870337194371\n",
      "Predicting with -200 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8585909393613868\n",
      "Predicting with -200 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8613898783297872\n",
      "Predicting with -200 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.865161912435539\n",
      "Predicting with -200 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8683959690028742\n",
      "Predicting with -200 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8561669495740496\n",
      "Predicting with -200 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8562020181774194\n",
      "Predicting with -200 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8601087305750724\n",
      "Predicting with -200 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8580891234372109\n",
      "Predicting with -250 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7288343197479108\n",
      "Predicting with -250 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8239656228632262\n",
      "Predicting with -250 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8444443138931437\n",
      "Predicting with -250 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8554325964434052\n",
      "Predicting with -250 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8531932629998287\n",
      "Predicting with -250 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8565420287482062\n",
      "Predicting with -250 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8570021284490115\n",
      "Predicting with -250 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8545753343932476\n",
      "Predicting with -250 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8545646981957817\n",
      "Predicting with -250 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8556779200827596\n",
      "Predicting with -250 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8557760072082738\n",
      "Predicting with -300 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.724356108645213\n",
      "Predicting with -300 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.822508242569358\n",
      "Predicting with -300 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8435521838709764\n",
      "Predicting with -300 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.851768569162037\n",
      "Predicting with -300 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8545028410214688\n",
      "Predicting with -300 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8578170568287451\n",
      "Predicting with -300 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8593188641753479\n",
      "Predicting with -300 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8572256382894492\n",
      "Predicting with -300 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8572154804536061\n",
      "Predicting with -300 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8589761151651241\n",
      "Predicting with -300 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8579803861253888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/3p5f6szx247fkf6ftdgp147w0000gn/T/ipykernel_6110/2373499165.py:82: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "for pred_range, label in zip(ranges, labels):\n",
    "\n",
    "    idx1 = int((pred_range[0] - data_range[0])/dataset_50ms.bin_width)\n",
    "    idx2 = int(n_timepoints - (data_range[1]-pred_range[1])/dataset_50ms.bin_width)\n",
    "\n",
    "    t_before_range = range(0,301,50);\n",
    "    t_after_range = range(0,501,50);\n",
    "\n",
    "    multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "    multi_coefs = []\n",
    "    j,k=0,0\n",
    "    for time_before in t_before_range:\n",
    "        coef_arr = []\n",
    "        for time_after in t_after_range:\n",
    "            print('Predicting with',-time_before, 'to', time_after,'ms neural data')\n",
    "\n",
    "            bins_before= int(time_before/dataset_50ms.bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "            bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "            bins_after= int(time_after/dataset_50ms.bin_width) #How many bins of neural data after the output are used for decoding\n",
    "\n",
    "            n_total_bins = bins_before + bins_current + bins_after\n",
    "\n",
    "            X =  nans([n_trials,idx2-idx1,n_total_bins*dim])\n",
    "            i = 0\n",
    "            for trial_data in passive_x:\n",
    "                trial_hist=get_spikes_with_history(trial_data,bins_before,bins_after,bins_current)\n",
    "                trial_hist = trial_hist[idx1:idx2,:,:]\n",
    "                trial_hist_flat=trial_hist.reshape(trial_hist.shape[0],(trial_hist.shape[1]*trial_hist.shape[2]))\n",
    "                X[i,:,:] = trial_hist_flat\n",
    "                i+=1\n",
    "            y = passive_y[:,idx1:idx2,:]\n",
    "\n",
    "            lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)})\n",
    "            X_reshaped = X.reshape((X.shape[0]*X.shape[1]),X.shape[2])\n",
    "            y_reshaped = y.reshape((y.shape[0]*y.shape[1]),y.shape[2])\n",
    "            lr_all.fit(X_reshaped, y_reshaped)\n",
    "            print(lr_all.best_params_['alpha'])\n",
    "\n",
    "            kf = KFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "            true_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "            pred_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "            trial_save_idx = 0\n",
    "            for training_set, test_set in kf.split(range(0,n_trials)):\n",
    "                #split training and testing by trials\n",
    "                X_train, X_test, y_train, y_test = process_train_test(X,y,training_set,test_set)\n",
    "                lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)}) \n",
    "                lr.fit(X_train, y_train)\n",
    "                y_test_predicted = lr.predict(X_test)\n",
    "                n = y_test_predicted.shape[0]\n",
    "                true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "                pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "                trial_save_idx += n\n",
    "\n",
    "            sses =get_sses_pred(true_concat,pred_concat)\n",
    "            sses_mean=get_sses_mean(true_concat)\n",
    "            multi_R2s[j,k] =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "            print('R2:',multi_R2s[j,k])\n",
    "            coef_arr.append(lr_all.best_estimator_.coef_)\n",
    "            k += 1\n",
    "        j += 1\n",
    "        k = 0\n",
    "        multi_coefs.append(coef_arr)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(multi_R2s)\n",
    "    ax.set_xlabel('Length of lagging info')\n",
    "    ax.set_ylabel('Length of leading info')\n",
    "\n",
    "    ax.set_xticks(np.arange(len(t_after_range)))\n",
    "    ax.set_yticks(np.arange(len(t_before_range)))\n",
    "    ax.set_xticklabels(labels=t_after_range)\n",
    "    ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "    ax.set_title('R2 predicting ' + str(pred_range) + ' ' + y_type +'\\nwith different lagging/leading info')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for i in range(len(t_before_range)):\n",
    "        for j in range(len(t_after_range)):\n",
    "            text = ax.text(j, i, str(int(multi_R2s[i, j]*1000)/1000),\n",
    "                           ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + '_multi_' + label + '.png', dpi = 'figure')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8958e911",
   "metadata": {},
   "source": [
    "## with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7170769",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_range = [-400,700]\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/PCA/pas/\"\n",
    "passive_x = passive_trials_pca\n",
    "passive_y = passive_trials_acc\n",
    "y_type = 'acceleration'\n",
    "\n",
    "ranges = [(0,120),(-100,120)]\n",
    "labels = ['early_acc','long_acc']\n",
    "\n",
    "dim = n_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6616acf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with 0 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.8203380562513611\n",
      "Predicting with 0 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8858475964674932\n",
      "Predicting with 0 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8996250362901388\n",
      "Predicting with 0 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.9088683259322539\n",
      "Predicting with 0 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.9087965951979173\n",
      "Predicting with 0 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.9129067451739092\n",
      "Predicting with 0 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.9103922051970267\n",
      "Predicting with 0 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.9078526741472736\n",
      "Predicting with 0 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.9060868831313249\n",
      "Predicting with 0 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.9038948361614509\n",
      "Predicting with 0 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.9040248525214972\n",
      "Predicting with -50 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.8227071406957723\n",
      "Predicting with -50 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8916823327421969\n",
      "Predicting with -50 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.9056289161895521\n",
      "Predicting with -50 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.9148132011290707\n",
      "Predicting with -50 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.9143962907974326\n",
      "Predicting with -50 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.9169839157867964\n",
      "Predicting with -50 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.9150483233590458\n",
      "Predicting with -50 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.913588137808089\n",
      "Predicting with -50 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.9116100939270575\n",
      "Predicting with -50 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.9091355672036788\n",
      "Predicting with -50 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.9109205241933169\n",
      "Predicting with -100 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.8134177734948351\n",
      "Predicting with -100 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8876257223569227\n",
      "Predicting with -100 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.9039137918968712\n",
      "Predicting with -100 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.913149553369321\n",
      "Predicting with -100 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.9137374366184607\n",
      "Predicting with -100 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.9160673857511167\n",
      "Predicting with -100 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.9134156066321538\n",
      "Predicting with -100 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.9121597041257629\n",
      "Predicting with -100 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.9099406897207769\n",
      "Predicting with -100 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.9073354016295234\n",
      "Predicting with -100 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.909085011776309\n",
      "Predicting with -150 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.8014836202848361\n",
      "Predicting with -150 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8851881404496039\n",
      "Predicting with -150 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.9010203939514696\n",
      "Predicting with -150 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.9116765915093277\n",
      "Predicting with -150 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.9127844731779068\n",
      "Predicting with -150 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.9157435216432632\n",
      "Predicting with -150 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.9140426265256689\n",
      "Predicting with -150 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.9123373462708925\n",
      "Predicting with -150 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.9102253188232189\n",
      "Predicting with -150 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.9081343526544763\n",
      "Predicting with -150 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.9097249604469217\n",
      "Predicting with -200 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7949497218431693\n",
      "Predicting with -200 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8824000255244967\n",
      "Predicting with -200 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8981168884390391\n",
      "Predicting with -200 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.9101242190725201\n",
      "Predicting with -200 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.9117419774159005\n",
      "Predicting with -200 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.9154776360865063\n",
      "Predicting with -200 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.9144045285311037\n",
      "Predicting with -200 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.9125610289478567\n",
      "Predicting with -200 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.9103856256336738\n",
      "Predicting with -200 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.9087294949155345\n",
      "Predicting with -200 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.9096995426306445\n",
      "Predicting with -250 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7890255331829296\n",
      "Predicting with -250 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8816546190204694\n",
      "Predicting with -250 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.9001359195943588\n",
      "Predicting with -250 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.9111474837589244\n",
      "Predicting with -250 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.9114773687215375\n",
      "Predicting with -250 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.9149562924667844\n",
      "Predicting with -250 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.9143262151187888\n",
      "Predicting with -250 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.9130005422406904\n",
      "Predicting with -250 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.9108524212798716\n",
      "Predicting with -250 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.9087057200820401\n",
      "Predicting with -250 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.9102940270286893\n",
      "Predicting with -300 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7751777244281286\n",
      "Predicting with -300 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8724887536829218\n",
      "Predicting with -300 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8959145800820738\n",
      "Predicting with -300 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.9087874639977281\n",
      "Predicting with -300 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.9084807833541857\n",
      "Predicting with -300 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.9115052259852936\n",
      "Predicting with -300 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.9107240351955128\n",
      "Predicting with -300 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.9096774874717282\n",
      "Predicting with -300 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.9077228675698111\n",
      "Predicting with -300 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.9055801236851789\n",
      "Predicting with -300 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.9074311778993913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/3p5f6szx247fkf6ftdgp147w0000gn/T/ipykernel_6110/3449919790.py:82: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with 0 to 0 ms neural data\n",
      "100.0\n",
      "R2: 0.7723273288822291\n",
      "Predicting with 0 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8323046488817147\n",
      "Predicting with 0 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8443339097238964\n",
      "Predicting with 0 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8564905330080382\n",
      "Predicting with 0 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8581311832869774\n",
      "Predicting with 0 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8610481760805787\n",
      "Predicting with 0 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8606102018942241\n",
      "Predicting with 0 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8576305667218663\n",
      "Predicting with 0 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8547165721480676\n",
      "Predicting with 0 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8526656341241657\n",
      "Predicting with 0 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8525135292489442\n",
      "Predicting with -50 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7805135568467356\n",
      "Predicting with -50 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8388530530127014\n",
      "Predicting with -50 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8501969588130162\n",
      "Predicting with -50 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8609919489848514\n",
      "Predicting with -50 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8619374141199505\n",
      "Predicting with -50 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8645294443141693\n",
      "Predicting with -50 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8637191000051669\n",
      "Predicting with -50 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8611609953258872\n",
      "Predicting with -50 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8597335976794053\n",
      "Predicting with -50 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8585121677628704\n",
      "Predicting with -50 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8585761502890104\n",
      "Predicting with -100 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7780226247168656\n",
      "Predicting with -100 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8387561922340347\n",
      "Predicting with -100 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8499517890359553\n",
      "Predicting with -100 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8603789369262107\n",
      "Predicting with -100 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8623706116345808\n",
      "Predicting with -100 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8655563706849828\n",
      "Predicting with -100 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.864991918703707\n",
      "Predicting with -100 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8622068748380489\n",
      "Predicting with -100 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8613070791185737\n",
      "Predicting with -100 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8607329865800266\n",
      "Predicting with -100 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8604001789684884\n",
      "Predicting with -150 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7720871484847729\n",
      "Predicting with -150 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8358622966927632\n",
      "Predicting with -150 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8465778833895712\n",
      "Predicting with -150 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8577898170851992\n",
      "Predicting with -150 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8599065131251493\n",
      "Predicting with -150 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8630616037185725\n",
      "Predicting with -150 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8618889915014751\n",
      "Predicting with -150 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.858985328718378\n",
      "Predicting with -150 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8585750202825219\n",
      "Predicting with -150 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8577568179392638\n",
      "Predicting with -150 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8576903927699546\n",
      "Predicting with -200 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7669306884606836\n",
      "Predicting with -200 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8323503113566447\n",
      "Predicting with -200 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.843495398364035\n",
      "Predicting with -200 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8558577152578722\n",
      "Predicting with -200 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8587206351028044\n",
      "Predicting with -200 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8622417253024592\n",
      "Predicting with -200 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8616308806103588\n",
      "Predicting with -200 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8589459900249483\n",
      "Predicting with -200 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8582645137545712\n",
      "Predicting with -200 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8581857294400623\n",
      "Predicting with -200 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8580707511904458\n",
      "Predicting with -250 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7602486101317385\n",
      "Predicting with -250 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8283101675768509\n",
      "Predicting with -250 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.840303900202291\n",
      "Predicting with -250 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8528423276288726\n",
      "Predicting with -250 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8569930415959286\n",
      "Predicting with -250 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.860280695067843\n",
      "Predicting with -250 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8601390071096757\n",
      "Predicting with -250 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.857523887349937\n",
      "Predicting with -250 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8567159807679653\n",
      "Predicting with -250 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8566774119529699\n",
      "Predicting with -250 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8568907366739672\n",
      "Predicting with -300 to 0 ms neural data\n",
      "1000.0\n",
      "R2: 0.7552920054480735\n",
      "Predicting with -300 to 50 ms neural data\n",
      "1000.0\n",
      "R2: 0.8248118897177162\n",
      "Predicting with -300 to 100 ms neural data\n",
      "1000.0\n",
      "R2: 0.8390003376210995\n",
      "Predicting with -300 to 150 ms neural data\n",
      "1000.0\n",
      "R2: 0.8524749551951274\n",
      "Predicting with -300 to 200 ms neural data\n",
      "1000.0\n",
      "R2: 0.8568712389870872\n",
      "Predicting with -300 to 250 ms neural data\n",
      "1000.0\n",
      "R2: 0.8596175759798881\n",
      "Predicting with -300 to 300 ms neural data\n",
      "1000.0\n",
      "R2: 0.8594060075115098\n",
      "Predicting with -300 to 350 ms neural data\n",
      "1000.0\n",
      "R2: 0.8564592015597823\n",
      "Predicting with -300 to 400 ms neural data\n",
      "1000.0\n",
      "R2: 0.8551947134213325\n",
      "Predicting with -300 to 450 ms neural data\n",
      "1000.0\n",
      "R2: 0.8552249067615393\n",
      "Predicting with -300 to 500 ms neural data\n",
      "1000.0\n",
      "R2: 0.8554373458436915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/3p5f6szx247fkf6ftdgp147w0000gn/T/ipykernel_6110/3449919790.py:82: UserWarning: The figure layout has changed to tight\n",
      "  plt.tight_layout()\n"
     ]
    }
   ],
   "source": [
    "for pred_range, label in zip(ranges, labels):\n",
    "\n",
    "    idx1 = int((pred_range[0] - data_range[0])/dataset_50ms.bin_width)\n",
    "    idx2 = int(n_timepoints - (data_range[1]-pred_range[1])/dataset_50ms.bin_width)\n",
    "\n",
    "    t_before_range = range(0,301,50);\n",
    "    t_after_range = range(0,501,50);\n",
    "\n",
    "    multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "    multi_coefs = []\n",
    "    j,k=0,0\n",
    "    for time_before in t_before_range:\n",
    "        coef_arr = []\n",
    "        for time_after in t_after_range:\n",
    "            print('Predicting with',-time_before, 'to', time_after,'ms neural data')\n",
    "\n",
    "            bins_before= int(time_before/dataset_50ms.bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "            bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "            bins_after= int(time_after/dataset_50ms.bin_width) #How many bins of neural data after the output are used for decoding\n",
    "\n",
    "            n_total_bins = bins_before + bins_current + bins_after\n",
    "\n",
    "            X =  nans([n_trials,idx2-idx1,n_total_bins*dim])\n",
    "            i = 0\n",
    "            for trial_data in passive_x:\n",
    "                trial_hist=get_spikes_with_history(trial_data,bins_before,bins_after,bins_current)\n",
    "                trial_hist = trial_hist[idx1:idx2,:,:]\n",
    "                trial_hist_flat=trial_hist.reshape(trial_hist.shape[0],(trial_hist.shape[1]*trial_hist.shape[2]))\n",
    "                X[i,:,:] = trial_hist_flat\n",
    "                i+=1\n",
    "            y = passive_y[:,idx1:idx2,:]\n",
    "\n",
    "            lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)})\n",
    "            X_reshaped = X.reshape((X.shape[0]*X.shape[1]),X.shape[2])\n",
    "            y_reshaped = y.reshape((y.shape[0]*y.shape[1]),y.shape[2])\n",
    "            lr_all.fit(X_reshaped, y_reshaped)\n",
    "            print(lr_all.best_params_['alpha'])\n",
    "\n",
    "            kf = KFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "            true_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "            pred_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "            trial_save_idx = 0\n",
    "            for training_set, test_set in kf.split(range(0,n_trials)):\n",
    "                #split training and testing by trials\n",
    "                X_train, X_test, y_train, y_test = process_train_test(X,y,training_set,test_set)\n",
    "                lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)}) \n",
    "                lr.fit(X_train, y_train)\n",
    "                y_test_predicted = lr.predict(X_test)\n",
    "                n = y_test_predicted.shape[0]\n",
    "                true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "                pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "                trial_save_idx += n\n",
    "\n",
    "            sses =get_sses_pred(true_concat,pred_concat)\n",
    "            sses_mean=get_sses_mean(true_concat)\n",
    "            multi_R2s[j,k] =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "            print('R2:',multi_R2s[j,k])\n",
    "            coef_arr.append(lr_all.best_estimator_.coef_)\n",
    "            k += 1\n",
    "        j += 1\n",
    "        k = 0\n",
    "        multi_coefs.append(coef_arr)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(multi_R2s)\n",
    "    ax.set_xlabel('Length of lagging info')\n",
    "    ax.set_ylabel('Length of leading info')\n",
    "\n",
    "    ax.set_xticks(np.arange(len(t_after_range)))\n",
    "    ax.set_yticks(np.arange(len(t_before_range)))\n",
    "    ax.set_xticklabels(labels=t_after_range)\n",
    "    ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "    ax.set_title('R2 predicting ' + str(pred_range) + ' ' + y_type +'\\nwith different lagging/leading info')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for i in range(len(t_before_range)):\n",
    "        for j in range(len(t_after_range)):\n",
    "            text = ax.text(j, i, str(int(multi_R2s[i, j]*1000)/1000),\n",
    "                           ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + '_multi_' + label + '.png', dpi = 'figure')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2160891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
