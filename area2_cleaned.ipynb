{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlb_tools.nwb_interface import NWBDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "from sklearn.linear_model import Ridge, LinearRegression, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import math\n",
    "import multiprocessing as mp\n",
    "from scipy.linalg import orth\n",
    "import scipy.stats\n",
    "\n",
    "from Neural_Decoding.preprocessing_funcs import get_spikes_with_history\n",
    "from Area2_analysis.lr_funcs import process_train_test, gaussian_filter1d_oneside, comp_cc, xcorr, r2_score\n",
    "from Area2_analysis.lr_funcs import get_sses_pred, get_sses_mean, nans\n",
    "from Area2_analysis.lr_funcs import fit_and_predict, sub_and_predict, pred_with_new_weights\n",
    "from Area2_analysis.lr_funcs import fit_and_predict_lasso, sub_and_predict_lasso\n",
    "from Area2_analysis.lr_funcs import calc_proj, principal_angles, angle_between\n",
    "\n",
    "matplotlib.rc('font', size=18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import Area2_analysis.lr_funcs\n",
    "importlib.reload(Area2_analysis.lr_funcs)\n",
    "from Area2_analysis.lr_funcs import fit_and_predict_DNN, fit_and_predict_weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "figDir = '/Users/sherryan/area2_population_analysis/sfn/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = \"~/area2_population_analysis/s1-kinematics/actpas_NWB/\"\n",
    "# monkey = \"Han_20171207\"\n",
    "# filename = foldername + monkey + \"_COactpas_TD_offset2.nwb\"\n",
    "\n",
    "# monkey = \"Chips_20170913\"\n",
    "# filename = foldername + monkey + \"_COactpas_TD.nwb\"\n",
    "\n",
    "monkey = 'Duncan_20190710'\n",
    "filename = foldername + monkey + \"_COactpas_offset2.nwb\"\n",
    "\n",
    "dataset_10ms = NWBDataset(filename, split_heldout=False)\n",
    "\n",
    "dataset_10ms.resample(10) #in 10-ms bin, has to resample first for Duncan\n",
    "bin_width = dataset_10ms.bin_width\n",
    "print(bin_width)\n",
    "\n",
    "\n",
    "# xyz_force = np.array([dataset_5ms.data['force']['x'].to_numpy(), dataset_5ms.data['force']['y'].to_numpy(), dataset_5ms.data['force']['z'].to_numpy()]).T\n",
    "# dataset_10ms.add_continuous_data(xyz_force,'manip_force',chan_names = ['x','y','z'])\n",
    "\n",
    "# dataset_10ms.smooth_spk(40, name='smth_40')\n",
    "# dataset_10ms.smooth_spk(20, name='smth_20')\n",
    "\n",
    "# gaussian_kernel_width = 150 #in ms\n",
    "# sigma = int(gaussian_kernel_width/bin_width)\n",
    "# data_smoothed = gaussian_filter1d_oneside(dataset_10ms.data.spikes.to_numpy().astype(np.float64),sigma,axis=0)\n",
    "# dataset_10ms.add_continuous_data(data_smoothed,'spikes_smth_150_oneside')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_vel = dataset_10ms.data['hand_vel'].to_numpy()\n",
    "xy_acc = np.diff(xy_vel, axis = 0, prepend=[xy_vel[0]])\n",
    "dataset_10ms.add_continuous_data(xy_acc,'hand_acc',chan_names = ['x','y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/Users/sherryan/area2_population_analysis/s1-kinematics/'+monkey+'_COactpas_with_emg_TD.mat'\n",
    "import scipy.io\n",
    "mat = scipy.io.loadmat(filename)\n",
    "EMG = mat['trial_data']['emg'][0,0]\n",
    "dataset_10ms.add_continuous_data(EMG,'EMG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat['trial_data']['emg_names'][0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = dataset_10ms.data['EMG'].to_numpy()\n",
    "print(all_data.shape)\n",
    "data_for_pca = all_data[~np.isnan(all_data).any(axis=1)]\n",
    "print(data_for_pca.shape)\n",
    "explained_var = []\n",
    "for n in range(20):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(data_for_pca)\n",
    "    pca = PCA(n_components=n)\n",
    "    X = pca.fit(X)\n",
    "    explained_var.append(np.sum(pca.explained_variance_ratio_))\n",
    "plt.plot(range(20),explained_var)\n",
    "print(explained_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = dataset_10ms.data['EMG'].to_numpy()\n",
    "print(all_data.shape)\n",
    "data_for_pca = all_data[~np.isnan(all_data).any(axis=1)]\n",
    "print(data_for_pca.shape)\n",
    "n_dims = 10\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data_for_pca)\n",
    "pca = PCA(n_components=n_dims,random_state = 42)\n",
    "X = pca.fit(X)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data_for_pca)\n",
    "pca = PCA(n_components=n_dims,random_state = 42)\n",
    "X = pca.fit(X)\n",
    "    \n",
    "PCA_data = nans([all_data.shape[0],n_dims])\n",
    "idx = 0\n",
    "for dp in all_data:\n",
    "    dp = dp.reshape((1, -1))\n",
    "    if np.isnan(dp).any():\n",
    "        dp_pca = nans([1,n_dims])\n",
    "    else:\n",
    "        dp_pca = pca.transform(scaler.transform(dp))\n",
    "    PCA_data[idx,:] = dp_pca\n",
    "    idx+=1\n",
    "print(PCA_data.shape)\n",
    "dataset_10ms.add_continuous_data(PCA_data,'EMG_PCA')\n",
    "print('PCA total var explained:',sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "muscle_len = dataset_10ms.data['muscle_len'].to_numpy()\n",
    "muscle_vel = dataset_10ms.data['muscle_vel'].to_numpy()\n",
    "joint_ang = dataset_10ms.data['joint_ang'].to_numpy()\n",
    "joint_vel = dataset_10ms.data['joint_vel'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.hstack([muscle_len,muscle_vel])\n",
    "print(all_data.shape)\n",
    "data_for_pca = all_data[~np.isnan(all_data).any(axis=1)]\n",
    "print(data_for_pca.shape)\n",
    "explained_var = []\n",
    "for n in range(20):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(data_for_pca)\n",
    "    pca = PCA(n_components=n)\n",
    "    X = pca.fit(X)\n",
    "    explained_var.append(np.sum(pca.explained_variance_ratio_))\n",
    "plt.plot(range(20),explained_var)\n",
    "plt.title('muscle len+vel')\n",
    "print(explained_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.hstack([joint_ang,joint_vel])\n",
    "print(all_data.shape)\n",
    "data_for_pca = all_data[~np.isnan(all_data).any(axis=1)]\n",
    "print(data_for_pca.shape)\n",
    "explained_var = []\n",
    "for n in range(14):\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(data_for_pca)\n",
    "    pca = PCA(n_components=n)\n",
    "    X = pca.fit(X)\n",
    "    explained_var.append(np.sum(pca.explained_variance_ratio_))\n",
    "plt.plot(range(14),explained_var)\n",
    "plt.title('joint ang+vel')\n",
    "print(explained_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.hstack([muscle_len,muscle_vel])\n",
    "print(all_data.shape)\n",
    "data_for_pca = all_data[~np.isnan(all_data).any(axis=1)]\n",
    "print(data_for_pca.shape)\n",
    "n_dims = 10\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data_for_pca)\n",
    "pca = PCA(n_components=n_dims,random_state = 42)\n",
    "X = pca.fit(X)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data_for_pca)\n",
    "pca = PCA(n_components=n_dims,random_state = 42)\n",
    "X = pca.fit(X)\n",
    "    \n",
    "PCA_data = nans([all_data.shape[0],n_dims])\n",
    "idx = 0\n",
    "for dp in all_data:\n",
    "    dp = dp.reshape((1, -1))\n",
    "    if np.isnan(dp).any():\n",
    "        dp_pca = nans([1,n_dims])\n",
    "    else:\n",
    "        dp_pca = pca.transform(scaler.transform(dp))\n",
    "    PCA_data[idx,:] = dp_pca\n",
    "    idx+=1\n",
    "print(PCA_data.shape)\n",
    "dataset_10ms.add_continuous_data(PCA_data,'muscle_PCA')\n",
    "print('PCA total var explained:',sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = np.hstack([joint_ang,joint_vel])\n",
    "print(all_data.shape)\n",
    "data_for_pca = all_data[~np.isnan(all_data).any(axis=1)]\n",
    "print(data_for_pca.shape)\n",
    "n_dims = 10\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data_for_pca)\n",
    "pca = PCA(n_components=n_dims,random_state = 42)\n",
    "X = pca.fit(X)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data_for_pca)\n",
    "pca = PCA(n_components=n_dims,random_state = 42)\n",
    "X = pca.fit(X)\n",
    "    \n",
    "PCA_data = nans([all_data.shape[0],n_dims])\n",
    "idx = 0\n",
    "for dp in all_data:\n",
    "    dp = dp.reshape((1, -1))\n",
    "    if np.isnan(dp).any():\n",
    "        dp_pca = nans([1,n_dims])\n",
    "    else:\n",
    "        dp_pca = pca.transform(scaler.transform(dp))\n",
    "    PCA_data[idx,:] = dp_pca\n",
    "    idx+=1\n",
    "print(PCA_data.shape)\n",
    "dataset_10ms.add_continuous_data(PCA_data,'joint_PCA')\n",
    "print('PCA total var explained:',sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dims = 20 # for PCA\n",
    "\n",
    "# trial_mask = active_mask\n",
    "n_trials = dataset_10ms.trial_info.shape[0]\n",
    "print(n_trials,'total trials')\n",
    "n_neurons = dataset_10ms.data.spikes.shape[1]\n",
    "print(n_neurons,'neurons')\n",
    "\n",
    "\n",
    "all_data = np.array(dataset_10ms.data.spikes_smth_40)\n",
    "print(all_data.shape)\n",
    "if not np.isnan(all_data).any():\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(all_data)\n",
    "    pca = PCA(n_components=n_dims,random_state = 42)\n",
    "    PCA_data = pca.fit_transform(X)\n",
    "print(PCA_data.shape)\n",
    "dataset_10ms.add_continuous_data(X,'spikes_smth_40_zscored')\n",
    "dataset_10ms.add_continuous_data(PCA_data,'PCA_40')\n",
    "print('PCA total var explained:',sum(pca.explained_variance_ratio_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dictionary for trial condition (reaching directions) for Stratified CV\n",
    "dataset = dataset_10ms\n",
    "active_mask = (dataset.trial_info.ctr_hold_bump==0) & (dataset.trial_info['split'] != 'none')\n",
    "passive_mask = (dataset.trial_info.ctr_hold_bump==1) & (dataset.trial_info['split'] != 'none')\n",
    "nan_mask = (np.isnan(dataset.trial_info.ctr_hold_bump)) & (dataset.trial_info['split'] != 'none')\n",
    "all_mask = (dataset.trial_info['split'] != 'none')\n",
    "\n",
    "trial_mask = all_mask\n",
    "valid_n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "print(valid_n_trials,'valid trials')\n",
    "\n",
    "trial_mask = active_mask\n",
    "active_trials_idx = np.array(dataset.trial_info.loc[trial_mask]['trial_id'])\n",
    "active_n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "print(active_n_trials,'active trials')\n",
    "\n",
    "trial_mask = passive_mask\n",
    "passive_trials_idx = np.array(dataset.trial_info.loc[trial_mask]['trial_id'])\n",
    "passive_n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "print(passive_n_trials,'passive trials')\n",
    "\n",
    "trial_mask = nan_mask\n",
    "nan_trials_idx = np.array(dataset.trial_info.loc[trial_mask]['trial_id'])\n",
    "nan_n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "print(nan_n_trials,'reach bump trials')\n",
    "\n",
    "active_cond_dir_idx = []\n",
    "passive_cond_dir_idx = []\n",
    "nan_cond_dir_idx = []\n",
    "nan_bump_cond_dir_idx = []\n",
    "for direction in [0,45,90,135,180,225,270,315]:\n",
    "# for direction in [0,90,180,270]:\n",
    "    active_cond_dir_idx.append(np.where((dataset.trial_info['cond_dir']%360 == direction) & (dataset.trial_info['ctr_hold_bump'] == 0) & \\\n",
    "           (dataset.trial_info['split'] != 'none'))[0])\n",
    "    passive_cond_dir_idx.append(np.where((dataset.trial_info['cond_dir']%360 == direction) & (dataset.trial_info['ctr_hold_bump'] == 1) & \\\n",
    "           (dataset.trial_info['split'] != 'none'))[0])\n",
    "    nan_cond_dir_idx.append(np.where((dataset.trial_info['cond_dir']%360 == direction) & (np.isnan(dataset.trial_info.ctr_hold_bump)) & \\\n",
    "           (dataset.trial_info['split'] != 'none'))[0])\n",
    "    nan_bump_cond_dir_idx.append(np.where((dataset.trial_info['bump_dir']%360 == direction) & (np.isnan(dataset.trial_info.ctr_hold_bump)) & \\\n",
    "           (dataset.trial_info['split'] != 'none'))[0])\n",
    "\n",
    "active_cond_dict = nans([active_n_trials])\n",
    "i = 0\n",
    "for idx in active_trials_idx:\n",
    "    for cond in range(0,len(active_cond_dir_idx)):\n",
    "        if idx in active_cond_dir_idx[cond]:\n",
    "            active_cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(active_cond_dict)\n",
    "print(len(active_cond_dict))\n",
    "\n",
    "passive_cond_dict = nans([passive_n_trials])\n",
    "i = 0\n",
    "for idx in passive_trials_idx:\n",
    "    for cond in range(0,len(passive_cond_dir_idx)):\n",
    "        if idx in passive_cond_dir_idx[cond]:\n",
    "            passive_cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(passive_cond_dict)\n",
    "print(len(passive_cond_dict))\n",
    "\n",
    "nan_cond_dict = nans([nan_n_trials])\n",
    "i = 0\n",
    "for idx in nan_trials_idx:\n",
    "    for cond in range(0,len(nan_cond_dir_idx)):\n",
    "        if idx in nan_cond_dir_idx[cond]:\n",
    "            nan_cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(nan_cond_dict)\n",
    "print(len(nan_cond_dict))\n",
    "\n",
    "nan_bump_cond_dict = nans([nan_n_trials])\n",
    "i = 0\n",
    "for idx in nan_trials_idx:\n",
    "    for cond in range(0,len(nan_bump_cond_dir_idx)):\n",
    "        if idx in nan_bump_cond_dir_idx[cond]:\n",
    "            nan_bump_cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(nan_bump_cond_dict)\n",
    "print(len(nan_bump_cond_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_df = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range = (-100,100), ignored_trials = ~passive_mask)\n",
    "set(passive_trials_idx) - set(passive_df['trial_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_df = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range = (-100,100), ignored_trials = ~active_mask)\n",
    "del_indices = list(set(active_trials_idx) - set(active_df['trial_id'].unique()))\n",
    "print('was',active_n_trials,'active trials')\n",
    "active_n_trials = active_n_trials - len(list(set(active_trials_idx) - set(active_df['trial_id'].unique())))\n",
    "active_cond_dict = np.delete(active_cond_dict,np.argwhere(active_trials_idx==del_indices)[0])\n",
    "print('now',active_n_trials,'active trials')\n",
    "print(len(active_cond_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sca.models import SCA\n",
    "align_range = (-100, 1000)\n",
    "active_trial_data = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range=align_range, ignored_trials=~active_mask)\n",
    "active_trial_spsm = np.array(active_trial_data.spikes_smth_40)\n",
    "target_n_trials = active_trial_data['trial_id'].nunique()\n",
    "n_timepoints = int((align_range[1]-align_range[0])/bin_width)\n",
    "active_sample_weights= np.ones((target_n_trials, n_timepoints))\n",
    "# active_sample_weights[:,:int(100/dataset_10ms.bin_width)] = 10\n",
    "active_sample_weights = active_sample_weights.flatten()\n",
    "print(active_sample_weights.shape)\n",
    "\n",
    "align_range = (-100, 500)\n",
    "passive_trial_data = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range=align_range, ignored_trials=~passive_mask)\n",
    "passive_trial_spsm = np.array(passive_trial_data.spikes_smth_40)\n",
    "target_n_trials = passive_trial_data['trial_id'].nunique()\n",
    "n_timepoints = int((align_range[1]-align_range[0])/bin_width)\n",
    "passive_sample_weights= np.ones((target_n_trials, n_timepoints))\n",
    "passive_sample_weights = passive_sample_weights.flatten()\n",
    "print(passive_sample_weights.shape)\n",
    "\n",
    "sample_weights = np.hstack((active_sample_weights, passive_sample_weights))\n",
    "print(sample_weights.shape)\n",
    "all_trial_spsm = np.concatenate((active_trial_spsm, passive_trial_spsm),axis=0)\n",
    "print(all_trial_spsm.shape)\n",
    "\n",
    "all_data = np.array(dataset_10ms.data.spikes_smth_40)\n",
    "print(all_data.shape)\n",
    "if not np.isnan(all_trial_spsm).any():\n",
    "    scaler = StandardScaler()\n",
    "    X_trial = scaler.fit_transform(all_trial_spsm,sample_weight=sample_weights)\n",
    "    sca = SCA(n_components=n_dims)\n",
    "    sca.fit(X_trial) # scaler and sca fit to trial data\n",
    "    X_all = scaler.transform(all_data) #scaler and sca transform all data\n",
    "    SCA_data = sca.transform(X_all)\n",
    "print(SCA_data.shape)\n",
    "dataset_10ms.add_continuous_data(SCA_data,'SCA_40')\n",
    "print('SCA_40 var explained:',sca.r2_score)\n",
    "\n",
    "ssa_order_smth40 = np.argsort(-np.array(sca.explained_squared_activity))\n",
    "print('SCA_40 activity explained:',sca.explained_squared_activity[ssa_order_smth40])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_range = [-100, 1000]\n",
    "lag_range = [-300, 300]\n",
    "kin_range = [trial_range[0] + lag_range[0] + (-200), trial_range[1] + lag_range[1] + (+200)]                                \n",
    "lag_axis = np.arange(lag_range[0], lag_range[1]+1, 10)\n",
    "nrn_axis = np.arange(trial_range[0]+lag_range[0], trial_range[1]+lag_range[1]+1, 10)\n",
    "# To predict trial_range, we need wider neural_range, which requires wider kin_range\n",
    "\n",
    "df = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range=kin_range, ignored_trials=~active_mask, allow_overlap=True)\n",
    "n_trials = df['trial_id'].nunique()\n",
    "# acc_array = df['hand_acc'].to_numpy().reshape(active_n_trials, -1, 2)\n",
    "vel_array = df['hand_vel'].to_numpy().reshape(active_n_trials, -1, 2)\n",
    "\n",
    "kin_axis = np.arange(kin_range[0], kin_range[1]+1, dataset_10ms.bin_width)\n",
    "print('neural axis',nrn_axis[0], nrn_axis[-1])\n",
    "print('kinematics axis',kin_axis[0], kin_axis[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = 50\n",
    "ang_runs = nans([n_runs])\n",
    "r2_runs = nans([n_runs, len(lag_axis)])\n",
    "cd_r2_arr = nans([n_runs, len(lag_axis)])\n",
    "fb_r2_arr = nans([n_runs, len(lag_axis)])\n",
    "cd_lag = -50\n",
    "fb_lag = 50\n",
    "noise_level = 15\n",
    "\n",
    "for b in range(n_runs):\n",
    "    mu, sigma = 0,1\n",
    "    n_nrn = 50\n",
    "\n",
    "    # Random We and Wa\n",
    "    nrn_weight_0 = np.random.normal(mu, sigma, size = (n_nrn,1)) \n",
    "    nrn_weight_1 = np.random.normal(mu, sigma, size = (n_nrn,1))\n",
    "    # nrn_weight = np.concatenate([nrn_weight_0, nrn_weight_1], axis = 1)\n",
    "    nrn_weight = orth(np.concatenate([nrn_weight_0, nrn_weight_1], axis = 1))\n",
    "\n",
    "    # Random We = Wa\n",
    "    # nrn_weight_0 = np.random.normal(mu, sigma, size = (n_nrn,1))\n",
    "    # nrn_weight = np.tile(nrn_weight_0,(1,2)) \n",
    "\n",
    "    # Random We = -Wa\n",
    "    # nrn_weight_0 = np.random.normal(mu, sigma, size = (n_nrn,1))\n",
    "    # nrn_weight = np.concatenate([nrn_weight_0, -nrn_weight_0], axis = 1) \n",
    "    \n",
    "    n_bins = len(nrn_axis)\n",
    "    nrn_activity = nans([n_trials, n_bins, n_nrn])\n",
    "    cd_nrn_activity = nans([n_trials, n_bins, n_nrn])\n",
    "    fb_nrn_activity = nans([n_trials, n_bins, n_nrn])\n",
    "    for i in range(n_bins):\n",
    "        cd_signal = np.outer(vel_array[:, i+np.argwhere(kin_axis==nrn_axis[0]+(-cd_lag))[0,0], 1], nrn_weight[:,0])\n",
    "        fb_signal = np.outer(vel_array[:, i+np.argwhere(kin_axis==nrn_axis[0]+(-fb_lag))[0,0], 1], nrn_weight[:,1])\n",
    "        cd_nrn_activity[:,i,:] = cd_signal\n",
    "        fb_nrn_activity[:,i,:] = fb_signal\n",
    "        nrn_activity[:,i,:] = cd_signal+fb_signal\n",
    "    \n",
    "    # nrn_activity_flat = nrn_activity_flat.reshape(-1,n_nrn)\n",
    "    # cd_nrn_activity_flat = cd_nrn_activity.reshape(-1,n_nrn)\n",
    "    # cd_sig_noise = np.zeros((n_nrn,n_nrn))\n",
    "    # np.fill_diagonal(cd_sig_noise, np.std(cd_nrn_activity_flat,axis=0))\n",
    "    # cd_noise = np.random.multivariate_normal(np.zeros(n_nrn), cd_sig_noise, cd_nrn_activity_flat.shape[0]) * noise_percentage\n",
    "    # fb_nrn_activity_flat = fb_nrn_activity.reshape(-1,n_nrn)\n",
    "    # fb_sig_noise = np.zeros((n_nrn,n_nrn))\n",
    "    # np.fill_diagonal(fb_sig_noise, np.std(fb_nrn_activity_flat,axis=0))\n",
    "    # fb_noise = np.random.multivariate_normal(np.zeros(n_nrn), fb_sig_noise, fb_nrn_activity_flat.shape[0]) * noise_percentage\n",
    "    # noisy_nrn_activity = (nrn_activity_flat+cd_noise+fb_noise).reshape(nrn_activity.shape)\n",
    "\n",
    "    nrn_activity_flat = nrn_activity.reshape(-1,n_nrn)\n",
    "    sig_noise = np.zeros((n_nrn,n_nrn))\n",
    "    np.fill_diagonal(sig_noise,1)\n",
    "    noise = np.random.multivariate_normal(np.zeros(n_nrn), sig_noise, nrn_activity_flat.shape[0]) * noise_level\n",
    "    noisy_nrn_activity = (nrn_activity_flat+noise).reshape(nrn_activity.shape)\n",
    "\n",
    "    cd_nrn_activity_flat = cd_nrn_activity.reshape(-1,n_nrn)\n",
    "    noisy_cd_nrn_activity = (cd_nrn_activity_flat+noise).reshape(cd_nrn_activity.shape)\n",
    "\n",
    "    fb_nrn_activity_flat = fb_nrn_activity.reshape(-1,n_nrn)\n",
    "    noisy_fb_nrn_activity = (fb_nrn_activity_flat+noise).reshape(fb_nrn_activity.shape)    \n",
    "\n",
    "    coefs_arr = nans([len(lag_axis), n_nrn])\n",
    "    r2_arr = nans([len(lag_axis)]); \n",
    "    cd_r2 = nans([len(lag_axis)]); fb_r2 = nans([len(lag_axis)])\n",
    "    y = vel_array[:,np.argwhere(kin_axis==trial_range[0])[0,0]:np.argwhere(kin_axis==trial_range[1])[0,0],1]\n",
    "    y_reshaped = y.reshape(-1,1)\n",
    "    for j in range(len(lag_axis)):\n",
    "        start, end = int(0+j), int(y.shape[1]+j)\n",
    "        \n",
    "        X = noisy_cd_nrn_activity[:,start:end,:]\n",
    "        X = X.reshape((X.shape[0]* X.shape[1]),X.shape[2])\n",
    "        lr =  LinearRegression().fit(X, y_reshaped)\n",
    "        cd_r2[j] = lr.score(X, y_reshaped)\n",
    "\n",
    "        X = noisy_fb_nrn_activity[:,start:end,:]\n",
    "        X = X.reshape((X.shape[0]* X.shape[1]),X.shape[2])\n",
    "        lr =  LinearRegression().fit(X, y_reshaped)\n",
    "        fb_r2[j] = lr.score(X, y_reshaped)\n",
    "\n",
    "        X = noisy_nrn_activity[:,start:end,:]\n",
    "        X = X.reshape((X.shape[0]* X.shape[1]),X.shape[2])\n",
    "        lr =  LinearRegression().fit(X, y_reshaped)\n",
    "        coefs_arr[j] = lr.coef_\n",
    "        r2_arr[j] = lr.score(X, y_reshaped)\n",
    "\n",
    "    ang_runs[b] = math.degrees(angle_between(coefs_arr[np.argwhere(lag_axis==cd_lag)[0,0],:],coefs_arr[np.argwhere(lag_axis==fb_lag)[0,0],:])) \n",
    "    r2_runs[b,:] = r2_arr; \n",
    "    cd_r2_arr[b,:] = cd_r2; fb_r2_arr[b,:] = fb_r2\n",
    "print(r2_runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "tr_idx = 0\n",
    "nrn_idx = 12\n",
    "\n",
    "plt.plot(nrn_axis,cd_nrn_activity[tr_idx,:,nrn_idx],color = 'green',label = 'cd signal')\n",
    "plt.plot(nrn_axis,fb_nrn_activity[tr_idx,:,nrn_idx],color = 'magenta',label = 'fb signal')\n",
    "plt.plot(nrn_axis,nrn_activity[tr_idx,:,nrn_idx],color = 'brown',label = 'sum signal')\n",
    "plt.plot(nrn_axis,noisy_nrn_activity[tr_idx,:,nrn_idx],color = 'gray',alpha=0.8,label = 'noisy signal')\n",
    "plt.legend(fontsize=8)\n",
    "plt.axvline(0,color = 'k', linestyle='--')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey+'_example_nrn_low_noise.pdf',dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(r2_runs))\n",
    "fig, ax = plt.subplots(figsize=(4,3))\n",
    "\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.plot(lag_axis, np.mean(r2_runs,axis=0), color = 'brown')\n",
    "plt.plot(lag_axis, np.mean(cd_r2_arr,axis=0), color = 'green')\n",
    "plt.plot(lag_axis, np.mean(fb_r2_arr,axis=0), color = 'magenta')\n",
    "plt.axvline(cd_lag, color = 'k', linestyle='--')\n",
    "plt.axvline(fb_lag, color = 'k', linestyle='--')\n",
    "plt.xlabel(\"Time lag (ms)\")\n",
    "plt.ylabel('R2')\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_sim_r2_low_noise.pdf', dpi = 'figure')\n",
    "plt.show()\n",
    "plt.hist(ang_runs)\n",
    "plt.xlabel(\"Angle (deg)\")\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ac2_CD_proj_spikes_smth_40_oneside'].to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_c_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(-300, 300, 10)[np.argmax(avg_c_x1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross-correlation\n",
    "df = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range = (-100,1000), ignored_trials = ~active_mask)\n",
    "n_trials = df['trial_id'].nunique()\n",
    "\n",
    "cd_array = df['ac2_CD_proj_spikes_smth_40_oneside'].to_numpy().reshape(n_trials, -1, 3)\n",
    "\n",
    "# pos_array = df['hand_pos'].to_numpy().reshape(n_trials, -1, 2)\n",
    "# acc_array = df['hand_acc'].to_numpy().reshape(n_trials, -1, 2)\n",
    "vel_array = df['hand_vel'].to_numpy().reshape(n_trials, -1, 2)\n",
    "maxlags = 30 # times binsize is in ms (300ms for best display)\n",
    "X = cd_array\n",
    "Y = vel_array\n",
    "\n",
    "print(X.shape)\n",
    "cc_arr = nans([n_trials, maxlags*2+1])\n",
    "for i in range(n_trials):\n",
    "    x = X[i,:,0]\n",
    "    y = Y[i,:,0]\n",
    "    lags, c = xcorr(x, y, maxlags)\n",
    "    cc_arr[i,:] = c\n",
    "avg_c_x = np.mean(cc_arr, axis=0)\n",
    "\n",
    "cc_arr = nans([n_trials, maxlags*2+1])\n",
    "for i in range(n_trials):\n",
    "    x = X[i,:,1]\n",
    "    y = Y[i,:,0]\n",
    "    lags, c = xcorr(x, y, maxlags)\n",
    "    cc_arr[i,:] = c\n",
    "avg_c_x1 = np.mean(cc_arr, axis=0)\n",
    "\n",
    "\n",
    "cc_arr = nans([n_trials, maxlags*2+1])\n",
    "for i in range(n_trials):\n",
    "    x = X[i,:,2]\n",
    "    y = Y[i,:,1]\n",
    "    lags, c = xcorr(x, y, maxlags)\n",
    "    cc_arr[i,:] = c\n",
    "avg_c_y = np.mean(cc_arr, axis=0)\n",
    "\n",
    "x_axis = lags*dataset_10ms.bin_width\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x_axis, avg_c_x, color = 'green', label = 'x1')\n",
    "ax.plot(x_axis, avg_c_x1, color = 'green', label = 'x2')\n",
    "\n",
    "ax.plot(x_axis, avg_c_y, color = 'blue', label = 'y')\n",
    "tmax = x_axis[int(np.mean((np.argmax(abs(avg_c_x)),np.argmax(abs(avg_c_y)))))]\n",
    "# ax.axvline(tmax, color = 'k',linestyle = '--')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "print(tmax)\n",
    "plt.legend()\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('Normalized cross-corr')\n",
    "plt.title('CD dims vs. hand vel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Autocorrelation\n",
    "df = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range = (-100,1000), ignored_trials = ~active_mask)\n",
    "n_trials = df['trial_id'].nunique()\n",
    "\n",
    "vel_array = df['hand_vel'].to_numpy().reshape(n_trials, -1, 2)\n",
    "maxTimeLag = 500 #in ms\n",
    "X = vel_array\n",
    "\n",
    "print(X.shape)\n",
    "binSize = dataset_10ms.bin_width\n",
    "numBin = X.shape[1]\n",
    "x1 = X[:,:,0]\n",
    "x2 = X[:,:,0]\n",
    "ac_x = comp_cc(x1,x2,maxTimeLag,binSize,numBin)\n",
    "\n",
    "x1 = X[:,:,1]\n",
    "x2 = X[:,:,1]\n",
    "ac_y = comp_cc(x1,x2,maxTimeLag,binSize,numBin)\n",
    "\n",
    "time_axis = np.arange(0, maxTimeLag, binSize)\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.plot(time_axis,ac_x/ac_x[0],color = 'green', label = 'x')\n",
    "ax.plot(time_axis,ac_y/ac_y[0],color = 'blue', label = 'y')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Time lag (ms)\")\n",
    "plt.ylabel(\"Normalized autocorrelation\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_autocorrelation_vel.pdf',dpi = 'figure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = np.array([0,45,90,135,180,225,270,315]) \n",
    "directions = np.array([0,45,90,135,180,225,270,315])\n",
    "\n",
    "# plot_dir = np.array([0,90,180,270]) \n",
    "# directions = np.array([0,90,180,270])\n",
    "\n",
    "cmap = plt.get_cmap('coolwarm',len(plot_dir))\n",
    "custom_palette = [mpl.colors.rgb2hex(cmap(i)) for i in range(len(plot_dir))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA projections over trial, for different reaching directions\n",
    "plot_field = 'SCA_40'\n",
    "n_dims = dataset.data[plot_field].shape[1]\n",
    "# order = np.arange(n_dims)\n",
    "order = ssa_order_smth40\n",
    "\n",
    "pred_range = (-100, 1000)\n",
    "trial_mask = active_mask\n",
    "cond_dict = active_cond_dict\n",
    "n_timepoints = int((pred_range[1] - pred_range[0])/dataset_10ms.bin_width)\n",
    "data = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range=pred_range, ignored_trials=~trial_mask)\n",
    "n_trials = data['trial_id'].nunique()\n",
    "trials_pca = nans([n_trials,n_timepoints,n_dims])\n",
    "i = 0\n",
    "for idx, trial in data.groupby('trial_id'):\n",
    "    trials_pca[i,:,:]=trial[plot_field].to_numpy()\n",
    "    i+=1\n",
    "print(trials_pca.shape)\n",
    "\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_10ms.bin_width)\n",
    "# define some useful time points\n",
    "move_idx=0\n",
    "ret_idx = 500\n",
    "\n",
    "plot_dims = 10\n",
    "\n",
    "fig,ax=plt.subplots(plot_dims,1,figsize=(10,15))\n",
    "for i in range(plot_dims):\n",
    "    for j in range(len(plot_dir)):\n",
    "        color = custom_palette[j]\n",
    "        dir_idx = np.argwhere(directions == plot_dir[j])[0]\n",
    "        cond_mean_proj = np.mean(trials_pca[np.argwhere(cond_dict==dir_idx).flatten(),:,:], axis = 0)[:,order[i]] \n",
    "        pca_mean = np.mean(data[plot_field].to_numpy(),axis = 0)[order[i]] \n",
    "        ax[i].plot(x_axis,cond_mean_proj - pca_mean,linewidth=2.25,color = color,label = plot_dir[j])\n",
    "        \n",
    "        ax[i].axvline(move_idx, color='k',linewidth = .5)\n",
    "        ax[i].axvline(ret_idx, color='k',linewidth = .5)\n",
    "        ax[i].set_xlim([-100,1000])\n",
    "        # ax[i].set_ylim([-15, 15])\n",
    "        ax[i].axhline(0,color ='k',ls = '--')\n",
    "        if i<plot_dims-1:\n",
    "            ax[i].set_xticks([])\n",
    "        else:\n",
    "            ax[i].set_xlabel('Time after movement onset (ms)')\n",
    "            \n",
    "        # ax[i].set_yticks([])\n",
    "        ax[i].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "    ax[0].set_title('Active trials ' + plot_field)\n",
    "    \n",
    "plt.legend(bbox_to_anchor = (1, 1), loc = 'upper left')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_PCA_active.pdf',dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA projections over trial, for different reaching directions\n",
    "order = np.arange(n_dims)\n",
    "# order = ssa_order_smth40\n",
    "\n",
    "pred_range = (-100, 500)\n",
    "trial_mask = passive_mask\n",
    "cond_dict = passive_cond_dict\n",
    "n_timepoints = int((pred_range[1] - pred_range[0])/dataset_10ms.bin_width)\n",
    "# n_trials = dataset_10ms.trial_info.loc[trial_mask].shape[0]\n",
    "data = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range=pred_range, ignored_trials=~trial_mask)\n",
    "n_trials = data['trial_id'].nunique()\n",
    "trials_pca = nans([n_trials,n_timepoints,n_dims])\n",
    "i = 0\n",
    "for idx, trial in data.groupby('trial_id'):\n",
    "    trials_pca[i,:,:]=trial[plot_field].to_numpy()\n",
    "    i+=1\n",
    "print(trials_pca.shape)\n",
    "\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_10ms.bin_width)\n",
    "# define some useful time points\n",
    "move_idx=0\n",
    "ret_idx = 200\n",
    "\n",
    "plot_dims = 10\n",
    "\n",
    "fig,ax=plt.subplots(plot_dims,1,figsize=(10,15))\n",
    "for i in range(plot_dims):\n",
    "    for j in range(len(plot_dir)):\n",
    "        color = custom_palette[j]\n",
    "        dir_idx = np.argwhere(directions == plot_dir[j])[0]\n",
    "        cond_mean_proj = np.mean(trials_pca[np.argwhere(cond_dict==dir_idx).flatten(),:,:], axis = 0)[:,order[i]] \n",
    "        pca_mean = np.mean(data[plot_field].to_numpy(),axis = 0)[order[i]]\n",
    "        ax[i].plot(x_axis,cond_mean_proj - pca_mean,linewidth=2.25,color = color,label = plot_dir[j])\n",
    "        \n",
    "        ax[i].axvline(move_idx, color='k',linewidth = .5)\n",
    "        ax[i].axvline(ret_idx, color='k',linewidth = .5)\n",
    "        ax[i].set_xlim([-100,500])\n",
    "        # ax[i].set_ylim([-15, 15])\n",
    "        ax[i].axhline(0,color ='k',ls = '--')\n",
    "        if i<plot_dims-1:\n",
    "            ax[i].set_xticks([])\n",
    "        else:\n",
    "            ax[i].set_xlabel('Time after movement onset (ms)')\n",
    "            \n",
    "        # ax[i].set_yticks([])\n",
    "        ax[i].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "    ax[0].set_title('Passive trials ' + plot_field)\n",
    "    \n",
    "plt.legend(bbox_to_anchor = (1, 1), loc = 'upper left')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_PCA_passive.pdf',dpi = 'figure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Get a specific neuron's original index from GLM results to plot\n",
    "# with np.load(monkey+'_hf_neuron_filter.npz') as data:\n",
    "#     neuron_filter = data['neuron_filter']\n",
    "# fr_filtered_idx = np.argwhere(neuron_filter==1).flatten()\n",
    "# index_in_glm = [18, 27, 34, 35, 42, 48]\n",
    "\n",
    "# index_original = fr_filtered_idx[index_in_glm]\n",
    "# print(index_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = np.array([0,45,90,135,180,225,270,315]) \n",
    "directions = np.array([0,45,90,135,180,225,270,315])\n",
    "\n",
    "# plot_dir = np.array([0,90,180,270]) \n",
    "# directions = np.array([0,90,180,270])\n",
    "\n",
    "cmap = plt.get_cmap('coolwarm',len(plot_dir))\n",
    "custom_palette = [mpl.colors.rgb2hex(cmap(i)) for i in range(len(plot_dir))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot single neuron activity over trial, for different reaching directions\n",
    "dataset = dataset_10ms\n",
    "nrn_idx = 89\n",
    "pred_range = (-300, 1000)\n",
    "trial_mask = active_mask\n",
    "cond_dict = active_cond_dict\n",
    "n_timepoints = int((pred_range[1] - pred_range[0])/dataset.bin_width)\n",
    "n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "data = dataset.make_trial_data(align_field='move_onset_time', align_range=pred_range, ignored_trials=~trial_mask)\n",
    "trials_activity = nans([n_trials,n_timepoints])\n",
    "i = 0\n",
    "for idx, trial in data.groupby('trial_id'):\n",
    "    trials_activity[i,:]=trial.spikes_smth_40.to_numpy()[:,nrn_idx]\n",
    "    i+=1\n",
    "print(trials_activity.shape)\n",
    "\n",
    "plot_dir = np.array([0,45,90,135,180,225,270,315]) \n",
    "directions = np.array([0,45,90,135,180,225,270,315])\n",
    "# plot_dir = np.array([0,90,180,270]) \n",
    "# directions = np.array([0,90,180,270]) \n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset.bin_width)\n",
    "\n",
    "# define some useful time points\n",
    "move_idx=0\n",
    "ret_idx = 500\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(8,2))\n",
    "for j in range(len(plot_dir)):\n",
    "    color = custom_palette[j]\n",
    "    dir_idx = np.argwhere(directions == plot_dir[j])[0]\n",
    "    cond_mean_proj = np.mean(trials_activity[np.argwhere(cond_dict==dir_idx).flatten(),:], axis = 0)\n",
    "    ax.plot(x_axis,cond_mean_proj/dataset.bin_width*1000,linewidth=2.25,color = color,label = plot_dir[j])\n",
    "\n",
    "ax.axvline(move_idx,color='k')\n",
    "ax.axvline(ret_idx,color='k')\n",
    "\n",
    "ax.set_xlabel('Time after movement onset (ms)')\n",
    "ax.set_ylabel('Firing rate')\n",
    "ax.set_title('Active trials')\n",
    "\n",
    "plt.legend(bbox_to_anchor = (1, 1), loc = 'upper left')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_example_mix_nrn_active.pdf',dpi = 'figure')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot single neuron activity over trial, for different reaching directions\n",
    "dataset = dataset_10ms\n",
    "pred_range = (-100, 500)\n",
    "trial_mask = passive_mask\n",
    "cond_dict = passive_cond_dict\n",
    "n_timepoints = int((pred_range[1] - pred_range[0])/dataset.bin_width)\n",
    "n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "data = dataset.make_trial_data(align_field='move_onset_time', align_range=pred_range, ignored_trials=~trial_mask)\n",
    "trials_activity = nans([n_trials,n_timepoints])\n",
    "i = 0\n",
    "for idx, trial in data.groupby('trial_id'):\n",
    "    trials_activity[i,:]=trial.spikes_smth_40.to_numpy()[:,nrn_idx]\n",
    "    i+=1\n",
    "print(trials_activity.shape)\n",
    "\n",
    "plot_dir = np.array([0,45,90,135,180,225,270,315]) \n",
    "directions = np.array([0,45,90,135,180,225,270,315])\n",
    "# plot_dir = np.array([0,90,180,270]) \n",
    "# directions = np.array([0,90,180,270]) \n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset.bin_width)\n",
    "\n",
    "# define some useful time points\n",
    "move_idx=0\n",
    "ret_idx = 200\n",
    "\n",
    "fig,ax=plt.subplots(1,1,figsize=(8,2))\n",
    "for j in range(len(plot_dir)):\n",
    "    color = custom_palette[j]\n",
    "    dir_idx = np.argwhere(directions == plot_dir[j])[0]\n",
    "    cond_mean_proj = np.mean(trials_activity[np.argwhere(cond_dict==dir_idx).flatten(),:], axis = 0)\n",
    "    ax.plot(x_axis,cond_mean_proj/dataset.bin_width*1000,linewidth=2.25,color = color,label = plot_dir[j])\n",
    "\n",
    "ax.axvline(move_idx,color='k')\n",
    "ax.axvline(ret_idx,color='k')\n",
    "\n",
    "ax.set_xlabel('Time after movement onset (ms)')\n",
    "ax.set_ylabel('Firing rate')\n",
    "ax.set_title('Passive trials')\n",
    "\n",
    "plt.legend(bbox_to_anchor = (1, 1), loc = 'upper left')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_example_mix_nrn_passive.pdf',dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_range = (-100,1000)\n",
    "x_axis = np.arange(plot_range[0], plot_range[1], dataset_10ms.bin_width)\n",
    "active_df = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range=plot_range, ignored_trials=~active_mask, allow_overlap=True)\n",
    "# passive_df = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range=plot_range, ignored_trials=~passive_mask, allow_overlap=True)\n",
    "# nan_df = dataset_10ms.make_trial_data(align_field='bump_time', align_range=plot_range, ignored_trials=~nan_mask, allow_overlap=True)\n",
    "\n",
    "# speed = np.sqrt(np.sum(dataset_10ms.data['hand_vel'][:].T**2,axis=0)).to_numpy().reshape((-1,1))\n",
    "# dataset_10ms.add_continuous_data(speed,'speed')\n",
    "# acceleration = np.diff(speed, axis = 0, prepend=[speed[0]])\n",
    "# dataset_10ms.add_continuous_data(acceleration,'acceleration') #technically change of speed, for timing plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = active_df\n",
    "var = 'hand_vel'\n",
    "plot_dir = [0.0, 90.0, 180.0, 270.0] \n",
    "# plot_dir = [45.0, 135.0, 225.0, 315.0] \n",
    "plot_dim = 'x' # plot x velocity\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "fig, ax = plt.subplots(figsize=(10,2))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset.trial_info[dataset.trial_info.cond_dir%360 == trial_dir].trial_id\n",
    "    for _, trial in df[np.isin(df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial[var][plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlim([-100, 1000])\n",
    "plt.xlabel('Time after movement offset (ms)')\n",
    "plt.ylabel('Hand velocity (cm/s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = [0.0, 90.0, 180.0, 270.0] # limit plot directions to reduce cluttering\n",
    "# plot_dir = [45.0, 135.0, 225.0, 315.0] \n",
    "plot_dim = 'y' # plot x velocity\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "fig, ax = plt.subplots(figsize=(10,2))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset.trial_info[dataset.trial_info.cond_dir%360 == trial_dir].trial_id\n",
    "    for _, trial in df[np.isin(df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial[var][plot_dim], color=color, linewidth=0.5)\n",
    "plt.xlim([-100, 1000])\n",
    "plt.xlabel('Time after movement offset (ms)')\n",
    "plt.ylabel('Hand velocity (cm/s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.trial_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trial length\n",
    "dt = (dataset.trial_info.go_cue_time - dataset.trial_info.start_time).dt.total_seconds()*1000\n",
    "dt[active_mask]\n",
    "plt.hist(dt[active_mask])\n",
    "# plt.xlim([-100, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PSTH\n",
    "active_trials_spikes = []\n",
    "for _, trial in active_df.groupby('trial_id'):\n",
    "    active_trials_spikes.append(np.sum(trial.spikes,axis=1))\n",
    "passive_trials_spikes = []\n",
    "for _, trial in passive_df.groupby('trial_id'):\n",
    "    passive_trials_spikes.append(np.sum(trial.spikes,axis=1))\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.plot(x_axis,np.sum(active_trials_spikes,axis = 0)/dataset_10ms.bin_width*1000/len(active_trials_spikes)/n_neurons,\"-o\",markersize=5, color = 'k',label = 'Active')\n",
    "ax.plot(x_axis,np.sum(passive_trials_spikes,axis = 0)/dataset_10ms.bin_width*1000/len(passive_trials_spikes)/n_neurons,\"-o\",markersize=5, color = 'red',label = 'Passive')\n",
    "# plt.title('Peristimulus aligned to move_onset')\n",
    "plt.legend()\n",
    "ax.set_ylabel('Average Firing Rate (sp/s)')\n",
    "plt.xlabel('Time after movement onset (ms)')\n",
    "plt.axvline(0, color = 'k',linestyle = '--')    \n",
    "\n",
    "# active_trials_EMG = []\n",
    "# for _, trial in active_df.groupby('trial_id'):\n",
    "#     active_trials_EMG.append(np.sum(trial.EMG,axis=1))\n",
    "# passive_trials_EMG = []\n",
    "# for _, trial in passive_df.groupby('trial_id'):\n",
    "#     passive_trials_EMG.append(np.sum(trial.EMG,axis=1))\n",
    "# n_muscles = dataset_10ms.data.EMG.shape[1]\n",
    "# ax1 = ax.twinx()\n",
    "# ax1.spines['right'].set_visible(False)\n",
    "# ax1.spines['top'].set_visible(False)\n",
    "# ax1.plot(x_axis,np.sum(active_trials_EMG,axis = 0)/len(active_trials_EMG)/n_muscles,\"--o\",markersize=5, color = 'k',alpha = 0.5)\n",
    "# ax1.plot(x_axis,np.sum(passive_trials_EMG,axis = 0)/len(passive_trials_EMG)/n_muscles,\"--o\",markersize=5, color = 'red',alpha = 0.5)\n",
    "# ax1.set_ylabel('Average Muscle Activity')\n",
    "\n",
    "plt.xlabel('Time after move onset (ms)')\n",
    "plt.axvline(0, color = 'k',linestyle = '--')    \n",
    "plt.xlim([-200, 600])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_psth.pdf',dpi = 'figure')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PSTH\n",
    "active_trials_spikes = []\n",
    "for _, trial in active_df.groupby('trial_id'):\n",
    "    active_trials_spikes.append(np.sum(trial.spikes,axis=1))\n",
    "passive_trials_spikes = []\n",
    "for _, trial in passive_df.groupby('trial_id'):\n",
    "    passive_trials_spikes.append(np.sum(trial.spikes,axis=1))\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.plot(x_axis,np.sum(active_trials_spikes,axis = 0)/dataset_10ms.bin_width*1000/len(active_trials_spikes)/n_neurons,\"-o\",markersize=5, color = 'k',label = 'Active')\n",
    "ax.plot(x_axis,np.sum(passive_trials_spikes,axis = 0)/dataset_10ms.bin_width*1000/len(passive_trials_spikes)/n_neurons,\"-o\",markersize=5, color = 'red',label = 'Passive')\n",
    "# plt.title('Peristimulus aligned to move_onset')\n",
    "plt.legend()\n",
    "ax.set_ylabel('Average Firing Rate (sp/s)')\n",
    "plt.xlabel('Time after movement onset (ms)')\n",
    "plt.axvline(0, color = 'k',linestyle = '--')    \n",
    "\n",
    "active_trials_EMG = []\n",
    "for _, trial in active_df.groupby('trial_id'):\n",
    "    active_trials_EMG.append(np.sum(trial['joint_ang'],axis=1))\n",
    "passive_trials_EMG = []\n",
    "for _, trial in passive_df.groupby('trial_id'):\n",
    "    passive_trials_EMG.append(np.sum(trial['joint_ang'],axis=1))\n",
    "n_muscles = dataset_10ms.data['joint_ang'].shape[1]\n",
    "ax1 = ax.twinx()\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.plot(x_axis,np.sum(active_trials_EMG,axis = 0)/len(active_trials_EMG)/n_muscles,\"--o\",markersize=5, color = 'k',alpha = 0.5)\n",
    "ax1.plot(x_axis,np.sum(passive_trials_EMG,axis = 0)/len(passive_trials_EMG)/n_muscles,\"--o\",markersize=5, color = 'red',alpha = 0.5)\n",
    "ax1.set_ylabel('Average Joint Angle')\n",
    "\n",
    "plt.xlabel('Time after movement onset (ms)')\n",
    "plt.axvline(0, color = 'k',linestyle = '--')    \n",
    "plt.xlim([-200, 600])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_psth.pdf',dpi = 'figure')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kinematics\n",
    "var = 'speed'\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "count = 0\n",
    "for _, trial in active_df.groupby('trial_id'):\n",
    "    if len(trial[var]) == len(x_axis):\n",
    "        plt.plot(x_axis,trial[var], color='k', linewidth=0.5)\n",
    "        count+=1\n",
    "print(count,'active trials')\n",
    "# count = 0\n",
    "# for _, trial in passive_df.groupby('trial_id'):\n",
    "#     if len(trial[var]) == len(x_axis):\n",
    "#         plt.plot(x_axis, trial[var], color='red', linewidth=0.5)\n",
    "#         count+=1\n",
    "# print(count,'passive trials')\n",
    "\n",
    "plt.xlabel('Time after movement onset (ms)')\n",
    "plt.ylabel('Hand speed (cm/s)')\n",
    "plt.axvline(0, color = 'k',linestyle = '--')\n",
    "# plt.title('Speed aligned to move_onset')\n",
    "# plt.axvline(120, color = 'k',linestyle = '--')\n",
    "plt.xlim([-2000,500])\n",
    "# plt.ylim([-3,100])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_speed_whole.pdf',dpi = 'figure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CD/FB subspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_10ms\n",
    "# x_field = 'PCA_40'\n",
    "x_field = 'spikes'\n",
    "# x_field = 'proj_out'\n",
    "dim = dataset.data[x_field].shape[1]\n",
    "\n",
    "# align_range = (-200, 1500)\n",
    "# align_field = 'move_onset_time'\n",
    "# mask = active_mask\n",
    "# active_df = dataset.make_trial_data(align_field=align_field, align_range=align_range, ignored_trials=~mask)\n",
    "# n_trials = active_n_trials\n",
    "# X = active_df[x_field].to_numpy().reshape((-1, dim))\n",
    "# print(X.shape)\n",
    "# mean = np.nanmean(X,axis=0)\n",
    "# std = np.nanstd(X,axis=0)\n",
    "# mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find CD axes\n",
    "align_range = (-100,0)\n",
    "align_field = 'move_onset_time'\n",
    "\n",
    "mask = active_mask\n",
    "active_df = dataset.make_trial_data(align_field=align_field, align_range=align_range, ignored_trials=~mask)\n",
    "cond_dict = active_cond_dict\n",
    "n_trials = active_n_trials\n",
    "X = active_df[x_field].to_numpy().reshape((-1, dim))\n",
    "# X = (X - mean)/std\n",
    "act_trial_spikes = X.reshape((n_trials, -1, dim))\n",
    "print(act_trial_spikes.shape)\n",
    "act_trial_mean_activity = np.mean(act_trial_spikes, axis=1)\n",
    "\n",
    "dirs = [dataset.trial_info[dataset.trial_info.trial_id == i]['cond_dir'] for i in active_df.trial_id]\n",
    "cos_x = np.array([round(math.cos(math.radians(i)),3) for i in dirs])\n",
    "sin_y = np.array([round(math.sin(math.radians(i)),3) for i in dirs])\n",
    "cos_sin = np.array([cos_x, sin_y]).T\n",
    "print(cos_sin.shape)\n",
    "\n",
    "# dirs = [dataset.trial_info[dataset.trial_info.trial_id == i]['cond_dir'] for i in active_df.trial_id]\n",
    "# filter = np.array([x%90==0 for x in dirs])\n",
    "# n_trials = len(filter)\n",
    "# act_trial_mean_activity = act_trial_mean_activity[filter[0::act_trial_spikes.shape[1]].squeeze(),:]\n",
    "# print(act_trial_mean_activity.shape)\n",
    "\n",
    "# cos_x = np.array([round(math.cos(math.radians(i)),3) for i in dirs])[filter.squeeze()]\n",
    "# sin_y = np.array([round(math.sin(math.radians(i)),3) for i in dirs])[filter.squeeze()]\n",
    "# cos_sin = np.array([cos_x, sin_y]).T\n",
    "# print(cos_sin.shape)\n",
    "\n",
    "# n_trials = act_trial_mean_activity.shape[0]\n",
    "# cond_dict = cond_dict[filter[0::act_trial_spikes.shape[1]].squeeze()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calc_proj_matrix_sparse(A,reg=1e-10):\n",
    "#     if A.ndim == 1:\n",
    "#         A = A.reshape(-1, 1)\n",
    "#     return A @ np.linalg.pinv(A.T @ A + reg * np.eye(A.shape[1])) @ A.T\n",
    "# def calc_proj_sparse(R, w,reg=1e-10):\n",
    "#     \"\"\" Returns projection of R(ates) onto the space defined by w \"\"\"\n",
    "#     P = calc_proj_matrix_sparse(w,reg=reg)\n",
    "#     return P@R.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "X = act_trial_mean_activity\n",
    "\n",
    "y=np.array(cos_x).reshape((n_trials,-1,1))[:,0,:]\n",
    "X_proc = X\n",
    "axes_list_x = nans([N,y.shape[1],dim])\n",
    "r2_cv_list_x = nans([N])\n",
    "r2_list_x = nans([N])\n",
    "for i in range(N):\n",
    "    reg = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)}).fit(X_proc, y)\n",
    "    # reg = GridSearchCV(Lasso(), {'alpha': np.logspace(-3, 3, 7)}).fit(X_proc, y)\n",
    "    axes_list_x[i,:,:] = reg.best_estimator_.coef_\n",
    "    r2_list_x[i] = reg.best_estimator_.score(X_proc, y)\n",
    "    weights = reg.best_estimator_.coef_\n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "    true_concat = nans([n_trials,1])\n",
    "    pred_concat = nans([n_trials,1])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test = X_proc[training_set,:],X_proc[test_set,:]\n",
    "        y_train, y_test = y[training_set],y[test_set]\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)})\n",
    "        # lr = GridSearchCV(Lasso(), {'alpha': np.logspace(-3, 3, 7)})\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "\n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n] = y_test_predicted.reshape(len(y_test_predicted),1)\n",
    "        trial_save_idx += n\n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)   \n",
    "    r2_cv_list_x[i] = R2\n",
    "    X_proc = X_proc - calc_proj(X_proc,weights.T).T\n",
    "    # X_proc = X_proc - calc_proj_sparse(X_proc,weights.T).T\n",
    "\n",
    "X_proc = X\n",
    "y = np.array(sin_y).reshape((n_trials,-1,1))[:,0,:]\n",
    "axes_list_y = nans([N,y.shape[1],dim])\n",
    "r2_cv_list_y = nans([N])\n",
    "r2_list_y = nans([N])\n",
    "for i in range(N):\n",
    "    reg = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)}).fit(X_proc, y)\n",
    "    # reg = GridSearchCV(Lasso(), {'alpha': np.logspace(-3, 3, 7)}).fit(X_proc, y)\n",
    "    axes_list_y[i,:,:] = reg.best_estimator_.coef_\n",
    "    r2_list_y[i] = reg.best_estimator_.score(X_proc, y)\n",
    "    weights = reg.best_estimator_.coef_\n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "    true_concat = nans([n_trials,1])\n",
    "    pred_concat = nans([n_trials,1])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test = X_proc[training_set,:],X_proc[test_set,:]\n",
    "        y_train, y_test = y[training_set],y[test_set]\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)})\n",
    "        # lr = GridSearchCV(Lasso(), {'alpha': np.logspace(-3, 3, 7)})\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "\n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n] = y_test_predicted.reshape(len(y_test_predicted),1)\n",
    "        trial_save_idx += n\n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)   \n",
    "    r2_cv_list_y[i] = R2\n",
    "    X_proc = X_proc - calc_proj(X_proc,weights.T).T\n",
    "    # X_proc = X_proc - calc_proj_sparse(X_proc,weights.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(N)+1,r2_cv_list_x)\n",
    "plt.xlabel('N')\n",
    "plt.title('x-dir')\n",
    "plt.ylabel('R2')\n",
    "print(r2_cv_list_x)\n",
    "plt.show()\n",
    "plt.plot(np.arange(N)+1,r2_cv_list_y)\n",
    "plt.xlabel('N')\n",
    "plt.title('y-dir')\n",
    "plt.ylabel('R2')\n",
    "print(r2_cv_list_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.0\n",
    "print(axes_list_x.squeeze()[r2_cv_list_x>thresh,:].shape)\n",
    "print(axes_list_y.squeeze()[r2_cv_list_y>thresh,:].shape)\n",
    "CD_axes = np.vstack((axes_list_x.squeeze()[r2_cv_list_x>thresh,:],axes_list_y.squeeze()[r2_cv_list_y>thresh,:]))\n",
    "CD_axes.shape\n",
    "\n",
    "all_data = dataset_10ms.data[x_field].to_numpy()\n",
    "proj_data = all_data @ CD_axes.T\n",
    "print(proj_data.shape)\n",
    "\n",
    "dataset_10ms.add_continuous_data(proj_data,'unsmoothed100_CD_proj_'+x_field)\n",
    "\n",
    "# reg = 'Lasso'\n",
    "# dataset_10ms.add_continuous_data(proj_data,'CD_proj_'+x_field+reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find FB axes\n",
    "proj_out_CD = True\n",
    "align_range = (200, 400)\n",
    "align_field = 'move_onset_time'\n",
    "\n",
    "mask = active_mask\n",
    "active_df = dataset.make_trial_data(align_field=align_field, align_range=align_range, ignored_trials=~mask)\n",
    "cond_dict = active_cond_dict\n",
    "n_trials = active_df['trial_id'].nunique()\n",
    "X = active_df[x_field].to_numpy().reshape((-1, dim))\n",
    "# X = (X - mean)/std\n",
    "act_trial_spikes = X.reshape((n_trials, -1, dim))\n",
    "print(act_trial_spikes.shape)\n",
    "act_trial_mean_activity = np.mean(act_trial_spikes, axis=1)\n",
    "\n",
    "dirs = [dataset.trial_info[dataset.trial_info.trial_id == i]['cond_dir'] for i in active_df.trial_id]\n",
    "cos_x = [round(math.cos(math.radians(i)),3) for i in dirs]\n",
    "sin_y = [round(math.sin(math.radians(i)),3) for i in dirs]\n",
    "cos_sin = np.array([cos_x, sin_y]).T\n",
    "print(cos_sin.shape)\n",
    "\n",
    "# dirs = [dataset.trial_info[dataset.trial_info.trial_id == i]['cond_dir'] for i in active_df.trial_id]\n",
    "# filter = np.array([x%90==0 for x in dirs])\n",
    "# n_trials = len(filter)\n",
    "# act_trial_mean_activity = act_trial_mean_activity[filter[0::act_trial_spikes.shape[1]].squeeze(),:]\n",
    "# print(act_trial_mean_activity.shape)\n",
    "\n",
    "# cos_x = np.array([round(math.cos(math.radians(i)),3) for i in dirs])[filter.squeeze()]\n",
    "# sin_y = np.array([round(math.sin(math.radians(i)),3) for i in dirs])[filter.squeeze()]\n",
    "# cos_sin = np.array([cos_x, sin_y]).T\n",
    "# print(cos_sin.shape)\n",
    "\n",
    "# n_trials = act_trial_mean_activity.shape[0]\n",
    "# cond_dict = cond_dict[filter[0::act_trial_spikes.shape[1]].squeeze()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "X = act_trial_mean_activity\n",
    "if proj_out_CD:\n",
    "    X =  X - calc_proj(X,CD_axes.T).T\n",
    "\n",
    "y=np.array(cos_x).reshape((n_trials,-1,1))[:,0,:]\n",
    "X_proc = X\n",
    "axes_list_x = nans([N,y.shape[1],dim])\n",
    "r2_cv_list_x = nans([N])\n",
    "r2_list_x = nans([N])\n",
    "for i in range(N):\n",
    "    reg = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)}).fit(X_proc, y)\n",
    "    # reg = GridSearchCV(Lasso(), {'alpha': np.logspace(-3, 3, 7)}).fit(X_proc, y)\n",
    "    axes_list_x[i,:,:] = reg.best_estimator_.coef_\n",
    "    r2_list_x[i] = reg.best_estimator_.score(X_proc, y)\n",
    "    weights = reg.best_estimator_.coef_\n",
    "    kf = KFold(n_splits=3,shuffle=True,random_state = 42)   \n",
    "    true_concat = nans([n_trials,1])\n",
    "    pred_concat = nans([n_trials,1])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in kf.split(range(0,n_trials)):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test = X_proc[training_set,:],X_proc[test_set,:]\n",
    "        y_train, y_test = y[training_set],y[test_set]\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)})\n",
    "        # lr = GridSearchCV(Lasso(), {'alpha': np.logspace(-3, 3, 7)})\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "\n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n] = y_test_predicted.reshape(len(y_test_predicted),1)\n",
    "        trial_save_idx += n\n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)   \n",
    "    r2_cv_list_x[i] = R2\n",
    "    X_proc = X_proc - calc_proj(X_proc,weights.T).T\n",
    "\n",
    "X_proc = X\n",
    "y = np.array(sin_y).reshape((n_trials,-1,1))[:,0,:]\n",
    "axes_list_y = nans([N,y.shape[1],dim])\n",
    "r2_cv_list_y = nans([N])\n",
    "r2_list_y = nans([N])\n",
    "for i in range(N):\n",
    "    reg = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)}).fit(X_proc, y)\n",
    "    # reg = GridSearchCV(Lasso(), {'alpha': np.logspace(-3, 3, 7)}).fit(X_proc, y)\n",
    "    axes_list_y[i,:,:] = reg.best_estimator_.coef_\n",
    "    r2_list_y[i] = reg.best_estimator_.score(X_proc, y)\n",
    "    weights = reg.best_estimator_.coef_\n",
    "    kf = KFold(n_splits=3,shuffle=True,random_state = 42)   \n",
    "    true_concat = nans([n_trials,1])\n",
    "    pred_concat = nans([n_trials,1])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in kf.split(range(0,n_trials)):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test = X_proc[training_set,:],X_proc[test_set,:]\n",
    "        y_train, y_test = y[training_set],y[test_set]\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)})\n",
    "        # lr = GridSearchCV(Lasso(), {'alpha': np.logspace(-3, 3, 7)})\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "\n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n] = y_test_predicted.reshape(len(y_test_predicted),1)\n",
    "        trial_save_idx += n\n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)   \n",
    "    r2_cv_list_y[i] = R2\n",
    "    X_proc = X_proc - calc_proj(X_proc,weights.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(N)+1,r2_cv_list_x)\n",
    "plt.xlabel('N')\n",
    "plt.title('x-dir')\n",
    "plt.ylabel('R2')\n",
    "print(r2_cv_list_x)\n",
    "plt.show()\n",
    "plt.plot(np.arange(N)+1,r2_cv_list_y)\n",
    "plt.xlabel('N')\n",
    "plt.title('y-dir')\n",
    "plt.ylabel('R2')\n",
    "print(r2_cv_list_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.0\n",
    "print(axes_list_x.squeeze()[r2_cv_list_x>thresh,:].shape)\n",
    "print(axes_list_y.squeeze()[r2_cv_list_y>thresh,:].shape)\n",
    "FB_axes = np.vstack((axes_list_x.squeeze()[r2_cv_list_x>thresh,:],axes_list_y.squeeze()[r2_cv_list_y>thresh,:]))\n",
    "FB_axes.shape\n",
    "\n",
    "# # thresh = 0.08\n",
    "# # print(axes_list_x.squeeze()[r2_list_x>thresh,:].shape)\n",
    "# # print(axes_list_y.squeeze()[r2_list_y>thresh,:].shape)\n",
    "# # FB_axes_alt = np.vstack((axes_list_x.squeeze()[r2_list_x>thresh,:],axes_list_y.squeeze()[r2_list_y>thresh,:]))\n",
    "# # FB_axes_alt.shape\n",
    "\n",
    "all_data = dataset_10ms.data[x_field].to_numpy()\n",
    "proj_data = all_data @ FB_axes.T\n",
    "print(proj_data.shape)\n",
    "\n",
    "dataset_10ms.add_continuous_data(proj_data,'unsmoothed100_FB_proj_'+x_field)\n",
    "\n",
    "# reg='Lasso'\n",
    "# dataset_10ms.add_continuous_data(proj_data,'FB_proj_'+x_field+reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.data.keys().unique(0))\n",
    "CD_proj = np.array(dataset_10ms.data['unsmoothed100_CD_proj_'+x_field])\n",
    "print(CD_proj.shape)\n",
    "FB_proj = np.array(dataset_10ms.data['unsmoothed100_FB_proj_'+x_field])\n",
    "print(FB_proj.shape)\n",
    "CD_FB_proj  = np.hstack([CD_proj,FB_proj])\n",
    "print(CD_FB_proj.shape)\n",
    "dataset_10ms.add_continuous_data(CD_FB_proj,'unsmoothed100_CD_FB_proj_'+x_field)\n",
    "\n",
    "# # all_data = dataset_10ms.data[x_field].to_numpy()\n",
    "# # CD_proj_out_data = all_data - calc_proj(all_data,CD_axes.T).T\n",
    "# # print(CD_proj_out_data.shape)\n",
    "# # dataset_10ms.add_continuous_data(CD_proj_out_data,'CD_proj_out_'+x_field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CD_axes_Lasso = CD_axes\n",
    "# FB_axes_Lasso = FB_axes\n",
    "\n",
    "# CD_axes_Ridge = CD_axes\n",
    "# FB_axes_Ridge = FB_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(monkey+'_unsmoothed100_cdfb_weights_'+x_field, CD_axes = CD_axes, FB_axes = FB_axes) \n",
    "np.savez(monkey+'_unsmoothed100_cdfb_data_'+x_field, \\\n",
    "        CD_FB_proj = dataset.data['unsmoothed100_CD_FB_proj_'+x_field].to_numpy(), \\\n",
    "        FB_proj = dataset.data['unsmoothed100_FB_proj_'+x_field].to_numpy(),\n",
    "        CD_proj = dataset.data['unsmoothed100_CD_proj_'+x_field].to_numpy())\n",
    "\n",
    "# np.savez(monkey+'_cdfb_weights_'+x_field, CD_axes_Lasso = CD_axes_Lasso, FB_axes_Lasso = FB_axes_Lasso,\\\n",
    "#          CD_axes_Ridge = CD_axes_Ridge, FB_axes_Ridge = FB_axes_Ridge) \n",
    "# np.savez(monkey+'_cdfb_data_'+x_field, \\\n",
    "#         CD_FB_proj_Lasso = dataset.data['CD_FB_proj_'+x_field+'Lasso'].to_numpy(), \\\n",
    "#         FB_proj_Lasso = dataset.data['FB_proj_'+x_field+'Lasso'].to_numpy(),\\\n",
    "#         CD_proj_Lasso = dataset.data['CD_proj_'+x_field+'Lasso'].to_numpy(),\\\n",
    "#         CD_FB_proj_Ridge = dataset.data['CD_FB_proj_'+x_field+'Ridge'].to_numpy(), \\\n",
    "#         FB_proj_Ridge = dataset.data['FB_proj_'+x_field+'Ridge'].to_numpy(),\n",
    "#         CD_proj_Ridge = dataset.data['CD_proj_'+x_field+'Ridge'].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = CD_axes.T\n",
    "Y = FB_axes.T\n",
    "angles = principal_angles(X, Y)\n",
    "print(\"Principal angles\", np.degrees(angles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FB_axes_plot = FB_axes\n",
    "angDist_array = nans([len(CD_axes),len(FB_axes_plot)])\n",
    "for i in range(len(CD_axes)):\n",
    "    for j in range(len(FB_axes_plot)):\n",
    "        angDist_array[i,j] = math.degrees(angle_between(CD_axes[i,:],FB_axes_plot[j,:]))\n",
    "fig, ax = plt.subplots(figsize=(4, 4))\n",
    "im = ax.imshow(angDist_array)\n",
    "ax.set_xlabel('Feedback axes')\n",
    "ax.set_ylabel('CD axes')\n",
    "ax.set_xticks(np.arange(len(FB_axes_plot)))\n",
    "ax.set_yticks(np.arange(len(CD_axes)))\n",
    "\n",
    "for i in range(len(CD_axes)):\n",
    "    for j in range(len(FB_axes_plot)):\n",
    "        text = ax.text(j, i, str(int(angDist_array[i, j])),\n",
    "                        ha=\"center\", va=\"center\", color=\"w\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_cdfb_degrees_pc.pdf',dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FB_axes_plot = FB_axes\n",
    "# angDist_array = nans([len(FB_axes_plot),len(FB_axes_plot)])\n",
    "# for i in range(len(FB_axes_plot)):\n",
    "#     for j in range(len(FB_axes_plot)):\n",
    "#         angDist_array[i,j] = math.degrees(angle_between(FB_axes_plot[i,:],FB_axes_plot[j,:]))\n",
    "# fig, ax = plt.subplots(figsize=(6, 6))\n",
    "# im = ax.imshow(angDist_array)\n",
    "# ax.set_xlabel('FB axes')\n",
    "# ax.set_ylabel('FB axes')\n",
    "# ax.set_xticks(np.arange(len(FB_axes_plot)))\n",
    "# ax.set_yticks(np.arange(len(FB_axes_plot)))\n",
    "# for i in range(len(FB_axes_plot)):\n",
    "#     for j in range(len(FB_axes_plot)):\n",
    "#         text = ax.text(j, i, str(int(angDist_array[i, j])),\n",
    "#                         ha=\"center\", va=\"center\", color=\"w\", fontsize=14)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# angDist_array = nans([len(CD_axes),len(CD_axes)])\n",
    "# for i in range(len(CD_axes)):\n",
    "#     for j in range(len(CD_axes)):\n",
    "#         angDist_array[i,j] = math.degrees(angle_between(CD_axes[i,:],CD_axes[j,:]))\n",
    "# fig, ax = plt.subplots(figsize=(4, 4))\n",
    "# im = ax.imshow(angDist_array)\n",
    "# ax.set_xlabel('CD axes')\n",
    "# ax.set_ylabel('CD axes')\n",
    "# ax.set_xticks(np.arange(len(CD_axes)))\n",
    "# ax.set_yticks(np.arange(len(CD_axes)))\n",
    "# for i in range(len(CD_axes)):\n",
    "#     for j in range(len(CD_axes)):\n",
    "#         text = ax.text(j, i, str(int(angDist_array[i, j])),\n",
    "#                         ha=\"center\", va=\"center\", color=\"w\", fontsize=14)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA projections over trial, for different reaching directions\n",
    "plot_dir = np.array([0,45,90,135,180,225,270,315]) \n",
    "directions = np.array([0,45,90,135,180,225,270,315])\n",
    "# plot_dir = np.array([0,90,180,270]) \n",
    "# directions = np.array([0,90,180,270])\n",
    "cmap = plt.get_cmap('coolwarm',len(plot_dir))\n",
    "custom_palette = [mpl.colors.rgb2hex(cmap(i)) for i in range(len(plot_dir))]\n",
    "plot_field = 'unsmoothed100_CD_FB_proj_'+x_field\n",
    "N = dataset.data[plot_field].shape[1]\n",
    "order = range(N)\n",
    "\n",
    "pred_range = (-100, 1100)\n",
    "trial_mask = active_mask\n",
    "cond_dict = active_cond_dict\n",
    "n_timepoints = int((pred_range[1] - pred_range[0])/dataset_10ms.bin_width)\n",
    "data = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range=pred_range, ignored_trials=~trial_mask, allow_overlap=True)\n",
    "n_trials = data['trial_id'].nunique()\n",
    "trials_pca = nans([n_trials,n_timepoints,N])\n",
    "i = 0\n",
    "for idx, trial in data.groupby('trial_id'):\n",
    "    trials_pca[i,:,:]=trial[plot_field].to_numpy()\n",
    "    i+=1\n",
    "print(trials_pca.shape)\n",
    "\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_10ms.bin_width)\n",
    "\n",
    "# define some useful time points\n",
    "move_idx=0\n",
    "ret_idx = 500\n",
    "\n",
    "plot_dims = N\n",
    "\n",
    "fig,ax=plt.subplots(plot_dims,1,figsize=(10,N+4))\n",
    "for i in range(plot_dims):\n",
    "    for j in range(len(plot_dir)):\n",
    "        color = custom_palette[j]\n",
    "        dir_idx = np.argwhere(directions == plot_dir[j])[0]\n",
    "        cond_mean_proj = np.mean(trials_pca[np.argwhere(cond_dict==dir_idx).flatten(),:,:], axis = 0)[:,order[i]] \n",
    "        pca_mean = np.mean(data[plot_field].to_numpy(),axis = 0)[order[i]] \n",
    "        ax[i].plot(x_axis,cond_mean_proj - pca_mean,linewidth=2.25,color = color,label = plot_dir[j])\n",
    "        \n",
    "        ax[i].axvline(move_idx, color='k',linewidth = .5)\n",
    "        ax[i].axvline(ret_idx, color='k',linewidth = .5)\n",
    "        ax[i].set_xlim([-100,1000])\n",
    "        # ax[i].set_ylim([-15, 15])\n",
    "        ax[i].axhline(0,color ='k',ls = '--')\n",
    "        if i<plot_dims-1:\n",
    "            ax[i].set_xticks([])\n",
    "        else:\n",
    "            ax[i].set_xlabel('Time after movement onset (ms)')\n",
    "            \n",
    "        ax[i].set_yticks([])\n",
    "        ax[i].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "    ax[0].set_title('Active trials ' + plot_field)\n",
    "     \n",
    "plt.legend(bbox_to_anchor = (1, 1), loc = 'upper left')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_cdfb_active_pc.pdf',dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA projections over trial, for different reaching directions\n",
    "pred_range = (-100, 600)\n",
    "trial_mask = passive_mask\n",
    "cond_dict = passive_cond_dict\n",
    "n_timepoints = int((pred_range[1] - pred_range[0])/dataset_10ms.bin_width)\n",
    "data = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range=pred_range, ignored_trials=~trial_mask, allow_overlap=True)\n",
    "n_trials = data['trial_id'].nunique()\n",
    "trials_pca = nans([n_trials,n_timepoints,N])\n",
    "i = 0\n",
    "for idx, trial in data.groupby('trial_id'):\n",
    "    trials_pca[i,:,:]=trial[plot_field].to_numpy()\n",
    "    i+=1\n",
    "print(trials_pca.shape)\n",
    "\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_10ms.bin_width)\n",
    "\n",
    "# define some useful time points\n",
    "move_idx=0\n",
    "ret_idx = 200\n",
    "\n",
    "plot_dims = N\n",
    "\n",
    "fig,ax=plt.subplots(plot_dims,1,figsize=(10,N+4))\n",
    "for i in range(plot_dims):\n",
    "    for j in range(len(plot_dir)):\n",
    "        color = custom_palette[j]\n",
    "        dir_idx = np.argwhere(directions == plot_dir[j])[0]\n",
    "        cond_mean_proj = np.mean(trials_pca[np.argwhere(cond_dict==dir_idx).flatten(),:,:], axis = 0)[:,order[i]] \n",
    "        pca_mean = np.mean(data[plot_field].to_numpy(),axis = 0)[order[i]]\n",
    "        ax[i].plot(x_axis,cond_mean_proj - pca_mean,linewidth=2.25,color = color,label = plot_dir[j])\n",
    "        \n",
    "        ax[i].axvline(move_idx, color='k',linewidth = .5)\n",
    "        ax[i].axvline(ret_idx, color='k',linewidth = .5)\n",
    "        ax[i].set_xlim([-100,500])\n",
    "        # ax[i].set_ylim([-15, 15])\n",
    "        ax[i].axhline(0,color ='k',ls = '--')\n",
    "        if i<plot_dims-1:\n",
    "            ax[i].set_xticks([])\n",
    "        else:\n",
    "            ax[i].set_xlabel('Time after movement onset (ms)')\n",
    "            \n",
    "        ax[i].set_yticks([])\n",
    "        ax[i].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "    ax[0].set_title('Passive trials ' + plot_field)\n",
    "    \n",
    "plt.legend(bbox_to_anchor = (1, 1), loc = 'upper left')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_cdfb_passive_pc.pdf',dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA projections over trial, for different reaching directions\n",
    "pred_range = (-100, 1100)\n",
    "trial_mask = nan_mask\n",
    "# cond_dict = nan_bump_cond_dict\n",
    "cond_dict = nan_cond_dict\n",
    "n_timepoints = int((pred_range[1] - pred_range[0])/dataset_10ms.bin_width)\n",
    "data = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range=pred_range, ignored_trials=~trial_mask, allow_overlap=True)\n",
    "n_trials = data['trial_id'].nunique()\n",
    "trials_pca = nans([n_trials,n_timepoints,N])\n",
    "i = 0\n",
    "for idx, trial in data.groupby('trial_id'):\n",
    "    trials_pca[i,:,:]=trial[plot_field].to_numpy()\n",
    "    i+=1\n",
    "print(trials_pca.shape)\n",
    "\n",
    "x_axis = np.arange(pred_range[0], pred_range[1], dataset_10ms.bin_width)\n",
    "\n",
    "# define some useful time points\n",
    "move_idx=0\n",
    "ret_idx = 200\n",
    "\n",
    "plot_dims = N\n",
    "\n",
    "fig,ax=plt.subplots(plot_dims,1,figsize=(10,N+4))\n",
    "for i in range(plot_dims):\n",
    "    for j in range(len(plot_dir)):\n",
    "        color = custom_palette[j]\n",
    "        dir_idx = np.argwhere(directions == plot_dir[j])[0]\n",
    "        cond_mean_proj = np.mean(trials_pca[np.argwhere(cond_dict==dir_idx).flatten(),:,:], axis = 0)[:,order[i]] \n",
    "        pca_mean = np.mean(data[plot_field].to_numpy(),axis = 0)[order[i]]\n",
    "        ax[i].plot(x_axis,cond_mean_proj - pca_mean,linewidth=2.25,color = color,label = plot_dir[j])\n",
    "        \n",
    "        ax[i].axvline(move_idx, color='k',linewidth = .5)\n",
    "        ax[i].axvline(ret_idx, color='k',linewidth = .5)\n",
    "        ax[i].set_xlim([-100,1000])\n",
    "        # ax[i].set_ylim([-15, 15])\n",
    "        ax[i].axhline(0,color ='k',ls = '--')\n",
    "        if i<plot_dims-1:\n",
    "            ax[i].set_xticks([])\n",
    "        else:\n",
    "            ax[i].set_xlabel('Time after movement onset (ms)')\n",
    "            \n",
    "        ax[i].set_yticks([])\n",
    "        ax[i].set_ylabel('Dim. '+str(i+1))\n",
    "\n",
    "    ax[0].set_title('Active-bump trials ' + plot_field)\n",
    "    \n",
    "plt.legend(bbox_to_anchor = (1, 1), loc = 'upper left')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_cdfb_passive_pc.pdf',dpi = 'figure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_field = 'CD_proj_'+x_field\n",
    "x_name = '0000'\n",
    "y_name = '0001'\n",
    "\n",
    "# Active, 2D plot\n",
    "unique_conditions = [(False, 0.0), (False, 45.0), (False, 90.0), (False, 135.0),\n",
    "                     (False, 180.0), (False, 225.0), (False, 270.0), (False, 315.0)]\n",
    "# unique_conditions = [(False, 0.0),  (False, 90.0), (False, 180.0), (False, 270.0)]\n",
    "\n",
    "# Initialize figure\n",
    "fig = plt.figure(figsize=(20, 4))\n",
    "ax_0 = fig.add_subplot(1,5,1)\n",
    "ax_1 = fig.add_subplot(1, 5,2)\n",
    "ax_2 = fig.add_subplot(1, 5,3)\n",
    "ax_3 = fig.add_subplot(1, 5,4)\n",
    "ax_4 = fig.add_subplot(1, 5,5)\n",
    "# xlim = [-1.5, 1.5]\n",
    "# ylim = [-1.5, 1.5]\n",
    "\n",
    "for cond in unique_conditions:\n",
    "    # Filter out invalid trials (labeled 'none') and trials in other conditions\n",
    "    cond_mask = (dataset.trial_info['ctr_hold_bump']==cond[0]) & \\\n",
    "                (dataset.trial_info['cond_dir']%360==cond[1]) & \\\n",
    "                (dataset.trial_info.split != 'none')\n",
    "# cond_mask = (np.isnan(dataset.trial_info['ctr_hold_bump'])) & \\\n",
    "\n",
    "    # Extract relevant portion of selected trials\n",
    "    cond_data = dataset.make_trial_data(align_field='move_onset_time', align_range=(-200, 0), ignored_trials=~cond_mask)\n",
    "    ax_0.plot(cond_data.groupby('align_time').mean()[plot_field][x_name].to_numpy(),cond_data.groupby('align_time').mean()[plot_field][y_name].to_numpy(),color=plt.cm.hsv(cond[1] / 360))\n",
    "    # for idx, trial in cond_data.groupby('trial_id'):\n",
    "    #     ax_0.plot(trial[plot_field][x_name], trial[plot_field][y_name], color=plt.cm.hsv(cond[1] / 360), linewidth=0.5)\n",
    "        # ax_0.set_xlim(xlim)\n",
    "        # ax_0.set_ylim(ylim)\n",
    "\n",
    "    cond_data = dataset.make_trial_data(align_field='move_onset_time', align_range=(0, 500), ignored_trials=~cond_mask)\n",
    "    ax_1.plot(cond_data.groupby('align_time').mean()[plot_field][x_name].to_numpy(),cond_data.groupby('align_time').mean()[plot_field][y_name].to_numpy(),color=plt.cm.hsv(cond[1] / 360))\n",
    "    # for idx, trial in cond_data.groupby('trial_id'):\n",
    "    #     ax_1.plot(trial[plot_field][x_name], trial[plot_field][y_name], color=plt.cm.hsv(cond[1] / 360), linewidth=0.5)\n",
    "        # ax_1.set_xlim(xlim)\n",
    "        # ax_1.set_ylim(ylim)\n",
    "    \n",
    "    cond_data = dataset.make_trial_data(align_field='move_onset_time', align_range=(500, 1000), ignored_trials=~cond_mask)\n",
    "    ax_2.plot(cond_data.groupby('align_time').mean()[plot_field][x_name].to_numpy(),cond_data.groupby('align_time').mean()[plot_field][y_name].to_numpy(),color=plt.cm.hsv(cond[1] / 360))\n",
    "    # for idx, trial in cond_data.groupby('trial_id'):\n",
    "    #     ax_2.plot(trial[plot_field][x_name], trial[plot_field][y_name], color=plt.cm.hsv(cond[1] / 360), linewidth=0.5)\n",
    "        # ax_2.set_xlim(xlim)\n",
    "        # ax_2.set_ylim(ylim)\n",
    "            \n",
    "    cond_data = dataset.make_trial_data(align_field='move_onset_time', align_range=(1000, 1500), ignored_trials=~cond_mask)\n",
    "    ax_3.plot(cond_data.groupby('align_time').mean()[plot_field][x_name].to_numpy(),cond_data.groupby('align_time').mean()[plot_field][y_name].to_numpy(),color=plt.cm.hsv(cond[1] / 360))\n",
    "    # for idx, trial in cond_data.groupby('trial_id'):\n",
    "    #     ax_3.plot(trial[plot_field][x_name], trial[plot_field][y_name], color=plt.cm.hsv(cond[1] / 360), linewidth=0.5)\n",
    "        # ax_3.set_xlim(xlim)\n",
    "        # ax_3.set_ylim(ylim)\n",
    "\n",
    "    cond_data = dataset.make_trial_data(align_field='move_onset_time', align_range=(1500, 2000), ignored_trials=~cond_mask)\n",
    "    ax_4.plot(cond_data.groupby('align_time').mean()[plot_field][x_name].to_numpy(),cond_data.groupby('align_time').mean()[plot_field][y_name].to_numpy(),color=plt.cm.hsv(cond[1] / 360))\n",
    "    # for idx, trial in cond_data.groupby('trial_id'):\n",
    "    #     ax_4.plot(trial[plot_field][x_name], trial[plot_field][y_name], color=plt.cm.hsv(cond[1] / 360), linewidth=0.5)\n",
    "        # ax_4.set_xlim(xlim)\n",
    "        # ax_4.set_ylim(ylim)\n",
    "            \n",
    "# Add labels\n",
    "ax_0.set_title('-200 to 0')\n",
    "ax_1.set_title('0 to 500')\n",
    "ax_2.set_title('500 to 1000')\n",
    "ax_3.set_title('1000 to 1500')\n",
    "ax_4.set_title('1500 to 2000')\n",
    "\n",
    "# ax_0.axis(\"off\")\n",
    "# ax_1.axis(\"off\")\n",
    "# ax_2.axis(\"off\")\n",
    "# ax_3.axis(\"off\")\n",
    "# ax_4.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_active_traj.pdf',dpi = 'figure')\n",
    "# plt.suptitle('Active Reach Trajectories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passive\n",
    "\n",
    "unique_conditions = [(True, 0.0), (True, 45.0), (True, 90.0), (True, 135.0),\n",
    "                     (True, 180.0), (True, 225.0), (True, 270.0), (True, 315.0)]\n",
    "# unique_conditions = [(True, 0.0),  (True, 90.0), (True, 180.0), (True, 270.0)]\n",
    "\n",
    "# Initialize figure\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax_0 = fig.add_subplot(1,3,1)\n",
    "ax_1 = fig.add_subplot(1, 3,2)\n",
    "ax_2 = fig.add_subplot(1, 3,3)\n",
    "# xlim = [-1.5, 1.5]\n",
    "# ylim = [-1.5, 1.5]\n",
    "\n",
    "for cond in unique_conditions:\n",
    "    # Filter out invalid trials (labeled 'none') and trials in other conditions\n",
    "    cond_mask = (dataset.trial_info['ctr_hold_bump']==cond[0]) & \\\n",
    "                (dataset.trial_info['cond_dir']%360==cond[1]) & \\\n",
    "                (dataset.trial_info.split != 'none')\n",
    "# cond_mask = (np.isnan(dataset.trial_info['ctr_hold_bump'])) & \\\n",
    "\n",
    "    # Extract relevant portion of selected trials\n",
    "    cond_data = dataset.make_trial_data(align_field='move_onset_time', align_range=(-200, 0), ignored_trials=~cond_mask)\n",
    "    ax_0.plot(cond_data.groupby('align_time').mean()[plot_field][x_name].to_numpy(),cond_data.groupby('align_time').mean()[plot_field][y_name].to_numpy(),color=plt.cm.hsv(cond[1] / 360))\n",
    "    # for idx, trial in cond_data.groupby('trial_id'):\n",
    "    #     ax_0.plot(trial[plot_field][x_name], trial[plot_field][y_name], color=plt.cm.hsv(cond[1] / 360), linewidth=0.5)\n",
    "        # ax_0.set_xlim(xlim)\n",
    "        # ax_0.set_ylim(ylim)\n",
    "    \n",
    "    cond_data = dataset.make_trial_data(align_field='move_onset_time', align_range=(0, 200), ignored_trials=~cond_mask)\n",
    "    ax_1.plot(cond_data.groupby('align_time').mean()[plot_field][x_name].to_numpy(),cond_data.groupby('align_time').mean()[plot_field][y_name].to_numpy(),color=plt.cm.hsv(cond[1] / 360))\n",
    "    # for idx, trial in cond_data.groupby('trial_id'):\n",
    "    #     ax_1.plot(trial[plot_field][x_name], trial[plot_field][y_name], color=plt.cm.hsv(cond[1] / 360), linewidth=0.5)\n",
    "        # ax_1.set_xlim(xlim)\n",
    "        # ax_1.set_ylim(ylim)\n",
    "\n",
    "    cond_data = dataset.make_trial_data(align_field='move_onset_time', align_range=(200, 500), ignored_trials=~cond_mask)\n",
    "    ax_2.plot(cond_data.groupby('align_time').mean()[plot_field][x_name].to_numpy(),cond_data.groupby('align_time').mean()[plot_field][y_name].to_numpy(),color=plt.cm.hsv(cond[1] / 360))\n",
    "    # for idx, trial in cond_data.groupby('trial_id'):\n",
    "    #     ax_2.plot(trial[plot_field][x_name], trial[plot_field][y_name], color=plt.cm.hsv(cond[1] / 360), linewidth=0.5)\n",
    "        # ax_2.set_xlim(xlim)\n",
    "        # ax_2.set_ylim(ylim)\n",
    "            \n",
    "# Add labels\n",
    "ax_0.set_title('-200 to 0')\n",
    "ax_1.set_title('0 to 200')\n",
    "ax_2.set_title('200 to 500')\n",
    "\n",
    "# ax_0.axis(\"off\")\n",
    "# ax_1.axis(\"off\")\n",
    "# ax_2.axis(\"off\")\n",
    "# ax_3.axis(\"off\")\n",
    "# ax_4.axis(\"off\")\n",
    "\n",
    "figDir = '/Users/sherryan/area2_population_analysis/figures_plus/'\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_active_traj.pdf',dpi = 'figure')\n",
    "# plt.suptitle('Active Reach Trajectories')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reaching directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = \"~/area2_population_analysis/s1-kinematics/actpas_NWB/\"\n",
    "monkey = \"Han_20171207\"\n",
    "filename = foldername + monkey + \"_COactpas_TD.nwb\"\n",
    "\n",
    "# monkey = \"Chips_20170913\"\n",
    "# filename = foldername + monkey + \"_COactpas_TD.nwb\"\n",
    "\n",
    "# monkey = 'Duncan_20190710'\n",
    "# filename = foldername + monkey + \"_COactpas_reformat.nwb\"\n",
    "\n",
    "dataset_50ms = NWBDataset(filename, split_heldout=False)\n",
    "# dataset_50ms.resample(50)\n",
    "# bin_width = dataset_50ms.bin_width\n",
    "# print(bin_width)\n",
    "\n",
    "dataset_50ms.resample(10)\n",
    "bin_width = dataset_50ms.bin_width\n",
    "print(bin_width)\n",
    "\n",
    "# filename = '/Users/sherryan/area2_population_analysis/s1-kinematics/'+monkey+'_COactpas_with_emg_TD.mat'\n",
    "# mat = scipy.io.loadmat(filename)\n",
    "# EMG = mat['trial_data']['emg'][0,0]\n",
    "# dataset_50ms.add_continuous_data(EMG,'EMG')\n",
    "\n",
    "# dataset_50ms.add_continuous_data(dataset_10ms.data.PCA_40.to_numpy(),'PCA_40')\n",
    "# dataset_50ms.add_continuous_data(dataset_10ms.data.spikes_smth_40_oneside.to_numpy(),'spikes_smth_40_oneside')\n",
    "# dataset_50ms.add_continuous_data(dataset_10ms.data.muscle_PCA.to_numpy(),'muscle_PCA')\n",
    "# dataset_50ms.add_continuous_data(dataset_10ms.data.joint_PCA.to_numpy(),'joint_PCA')\n",
    "\n",
    "x_field = 'spikes_smth_100_oneside'\n",
    "data = np.load(monkey+'_ac100_cdfb_data_'+x_field+'.npz')\n",
    "data.files\n",
    "dataset_50ms.add_continuous_data(data['CD_FB_proj'],'CD_FB_proj')\n",
    "dataset_50ms.add_continuous_data(data['CD_proj'],'CD_proj')\n",
    "dataset_50ms.add_continuous_data(data['FB_proj'],'FB_proj')\n",
    "dataset_50ms.resample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procX_train_test(X,y,training_set,test_set):\n",
    "    X_train = X[training_set,:]\n",
    "    X_test = X[test_set,:]\n",
    "    y_train = y[training_set,:]\n",
    "    y_test = y[test_set,:]    \n",
    "    \n",
    "    X_train_mean=np.nanmean(X_train,axis=0)\n",
    "    X_train_std=np.nanstd(X_train,axis=0)   \n",
    "\n",
    "    X_train=(X_train-X_train_mean)/X_train_std\n",
    "    X_test=(X_test-X_train_mean)/X_train_std\n",
    " \n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make dictionary for trial condition (reaching directions)\n",
    "dataset = dataset_50ms\n",
    "active_mask = (dataset.trial_info.ctr_hold_bump==0) & (dataset.trial_info['split'] != 'none')\n",
    "passive_mask = (dataset.trial_info.ctr_hold_bump==1) & (dataset.trial_info['split'] != 'none')\n",
    "nan_mask = (np.isnan(dataset.trial_info.ctr_hold_bump)) & (dataset.trial_info['split'] != 'none')\n",
    "all_mask = (dataset.trial_info['split'] != 'none')\n",
    "\n",
    "trial_mask = all_mask\n",
    "valid_n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "print(valid_n_trials,'valid trials')\n",
    "\n",
    "\n",
    "trial_mask = active_mask\n",
    "active_trials_idx = np.array(dataset.trial_info.loc[trial_mask]['trial_id'])\n",
    "active_n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "print(active_n_trials,'active trials')\n",
    "\n",
    "trial_mask = passive_mask\n",
    "passive_trials_idx = np.array(dataset.trial_info.loc[trial_mask]['trial_id'])\n",
    "passive_n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "print(passive_n_trials,'passive trials')\n",
    "\n",
    "trial_mask = nan_mask\n",
    "nan_trials_idx = np.array(dataset.trial_info.loc[trial_mask]['trial_id'])\n",
    "nan_n_trials = dataset.trial_info.loc[trial_mask].shape[0]\n",
    "print(nan_n_trials,'reach bump trials')\n",
    "\n",
    "active_cond_dir_idx = []\n",
    "passive_cond_dir_idx = []\n",
    "nan_cond_dir_idx = []\n",
    "nan_bump_cond_dir_idx = []\n",
    "for direction in [0,45,90,135,180,225,270,315]:\n",
    "# for direction in [0,90,180,270]:\n",
    "    active_cond_dir_idx.append(np.where((dataset.trial_info['cond_dir']%360 == direction) & (dataset.trial_info['ctr_hold_bump'] == 0) & \\\n",
    "           (dataset.trial_info['split'] != 'none'))[0])\n",
    "    passive_cond_dir_idx.append(np.where((dataset.trial_info['cond_dir']%360 == direction) & (dataset.trial_info['ctr_hold_bump'] == 1) & \\\n",
    "           (dataset.trial_info['split'] != 'none'))[0])\n",
    "    nan_cond_dir_idx.append(np.where((dataset.trial_info['cond_dir']%360 == direction) & (np.isnan(dataset.trial_info.ctr_hold_bump)) & \\\n",
    "           (dataset.trial_info['split'] != 'none'))[0])\n",
    "    nan_bump_cond_dir_idx.append(np.where((dataset.trial_info['bump_dir']%360 == direction) & (np.isnan(dataset.trial_info.ctr_hold_bump)) & \\\n",
    "           (dataset.trial_info['split'] != 'none'))[0])\n",
    "\n",
    "active_cond_dict = nans([active_n_trials])\n",
    "i = 0\n",
    "for idx in active_trials_idx:\n",
    "    for cond in range(0,len(active_cond_dir_idx)):\n",
    "        if idx in active_cond_dir_idx[cond]:\n",
    "            active_cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(active_cond_dict)\n",
    "print(len(active_cond_dict))\n",
    "\n",
    "passive_cond_dict = nans([passive_n_trials])\n",
    "i = 0\n",
    "for idx in passive_trials_idx:\n",
    "    for cond in range(0,len(passive_cond_dir_idx)):\n",
    "        if idx in passive_cond_dir_idx[cond]:\n",
    "            passive_cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(passive_cond_dict)\n",
    "print(len(passive_cond_dict))\n",
    "\n",
    "nan_cond_dict = nans([nan_n_trials])\n",
    "i = 0\n",
    "for idx in nan_trials_idx:\n",
    "    for cond in range(0,len(nan_cond_dir_idx)):\n",
    "        if idx in nan_cond_dir_idx[cond]:\n",
    "            nan_cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(nan_cond_dict)\n",
    "print(len(nan_cond_dict))\n",
    "\n",
    "nan_bump_cond_dict = nans([nan_n_trials])\n",
    "i = 0\n",
    "for idx in nan_trials_idx:\n",
    "    for cond in range(0,len(nan_bump_cond_dir_idx)):\n",
    "        if idx in nan_bump_cond_dir_idx[cond]:\n",
    "            nan_bump_cond_dict[i] = cond\n",
    "            break\n",
    "    i+=1\n",
    "print(nan_bump_cond_dict)\n",
    "print(len(nan_bump_cond_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_df = dataset_50ms.make_trial_data(align_field='move_onset_time', align_range = (-100,100), ignored_trials = ~active_mask)\n",
    "del_indices = list(set(active_trials_idx) - set(active_df['trial_id'].unique()))\n",
    "print('was',active_n_trials,'active trials')\n",
    "active_n_trials = active_n_trials - len(list(set(active_trials_idx) - set(active_df['trial_id'].unique())))\n",
    "active_cond_dict = np.delete(active_cond_dict,np.argwhere(active_trials_idx==del_indices)[0])\n",
    "print('now',active_n_trials,'active trials')\n",
    "print(len(active_cond_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dims = 20\n",
    "active_mask = (dataset_50ms.trial_info.ctr_hold_bump==0) & (dataset_50ms.trial_info.split != 'none')\n",
    "passive_mask = (dataset_50ms.trial_info.ctr_hold_bump==1) & (dataset_50ms.trial_info.split != 'none')\n",
    "\n",
    "all_data = np.array(dataset_50ms.data.spikes)\n",
    "print(all_data.shape)\n",
    "if not np.isnan(all_data).any():\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(all_data)\n",
    "    pca = PCA(n_components=n_dims,random_state = 42)\n",
    "    PCA_data = pca.fit_transform(X)\n",
    "print(PCA_data.shape)\n",
    "dataset_50ms.add_continuous_data(PCA_data,'20PC')\n",
    "print('PCA total var explained:',sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reach-bump trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_range = (-300, 1000)\n",
    "x_field = 'CD_proj'\n",
    "mask = nan_mask\n",
    "n_trials = nan_n_trials\n",
    "cond_dict = nan_cond_dict\n",
    "dim = dataset.data[x_field].shape[1]\n",
    "nan_df = dataset_50ms.make_trial_data(align_field='move_onset_time', align_range=pred_range, ignored_trials=~mask)\n",
    "dirs = [dataset_50ms.trial_info[dataset_50ms.trial_info.trial_id == i]['cond_dir'] for i in nan_df.trial_id]\n",
    "cos_x = [round(math.cos(math.radians(i)),3) for i in dirs]\n",
    "sin_y = [round(math.sin(math.radians(i)),3) for i in dirs]\n",
    "cos_sin = np.array([cos_x, sin_y]).T\n",
    "nan_trial_PCA = nan_df[x_field].to_numpy().reshape((n_trials, -1, dim))\n",
    "print(nan_trial_PCA.shape)\n",
    "nan_trial_ang = cos_sin.reshape((n_trials, -1, 2))\n",
    "# act_trial_ang = np.array(cos_x).reshape((n_trials,-1,1))\n",
    "# act_trial_ang = np.array(sin_y).reshape((n_trials,-1,1))\n",
    "\n",
    "print(nan_trial_ang.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cond_r2_arr = nans([n_bins])\n",
    "for i in range(n_bins):\n",
    "    X = nan_trial_PCA[:,i,:]\n",
    "    Y = nan_trial_ang[:,i,:]\n",
    "    X_proc = (X - np.nanmean(X,axis=0))/np.nanstd(X,axis=0)\n",
    "    lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)})\n",
    "    lr_all.fit(X_proc, Y)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)\n",
    "    true_concat = nans([n_trials,2])\n",
    "    pred_concat = nans([n_trials,2])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test, y_train, y_test = procX_train_test(X,Y,training_set,test_set)\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)}) \n",
    "        lr.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "\n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "        trial_save_idx += n\n",
    "\n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    nan_cond_r2_arr[i] = R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_bump_r2_arr = nans([n_bins])\n",
    "for i in range(n_bins):\n",
    "    X = nan_trial_PCA[:,i,:]\n",
    "    Y = nan_trial_ang[:,i,:]\n",
    "    X_proc = (X - np.nanmean(X,axis=0))/np.nanstd(X,axis=0)\n",
    "    lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)})\n",
    "    lr_all.fit(X_proc, Y)\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)\n",
    "    true_concat = nans([n_trials,2])\n",
    "    pred_concat = nans([n_trials,2])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test, y_train, y_test = procX_train_test(X,Y,training_set,test_set)\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)}) \n",
    "        lr.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "\n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "        trial_save_idx += n\n",
    "\n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    nan_bump_r2_arr[i] = R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fb_nan_cond_r2 = nan_cond_r2_arr\n",
    "# fb_nan_bump_r2 = nan_bump_r2_arr\n",
    "cd_nan_cond_r2 = nan_cond_r2_arr\n",
    "cd_nan_bump_r2 = nan_bump_r2_arr\n",
    "# cd_fb_nan_cond_r2 = nan_cond_r2_arr\n",
    "# cd_fb_nan_bump_r2 = nan_bump_r2_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_axis = np.arange(-300,1000,50)+50\n",
    "fig, ax = plt.subplots(figsize=(7.5,3))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.plot(lag_axis,cd_nan_cond_r2, \"-o\",color = 'green', label = 'CD')\n",
    "plt.plot(lag_axis,fb_nan_cond_r2, \"-o\",color = 'magenta', label = 'FB')\n",
    "plt.plot(lag_axis,cd_fb_nan_cond_r2, \"-o\",color = 'brown', label = 'CD+FB')\n",
    "\n",
    "plt.xlabel('Time after movement onset (ms)'); plt.ylabel('R2'); plt.title('Reach direction r2')\n",
    "plt.legend(fontsize=8)\n",
    "plt.xlim([-210, 1010])\n",
    "plt.ylim([-0.1, 1.0])\n",
    "plt.axvline(0, color = 'k',linestyle = '--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_axis = np.arange(-300,1000,50)+50\n",
    "fig, ax = plt.subplots(figsize=(7.5,3))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.plot(lag_axis,cd_nan_bump_r2, \"-o\",color = 'green', label = 'CD')\n",
    "plt.plot(lag_axis,fb_nan_bump_r2, \"-o\",color = 'magenta', label = 'FB')\n",
    "plt.plot(lag_axis,cd_fb_nan_bump_r2, \"-o\",color = 'brown', label = 'CD_FB')\n",
    "\n",
    "plt.xlabel('Time after movement onset (ms)'); plt.ylabel('R2'); plt.title('Bump direction r2')\n",
    "plt.legend(fontsize=8)\n",
    "plt.xlim([-210, 1010])\n",
    "plt.ylim([-0.1, 1.0])\n",
    "plt.axvline(0, color = 'k',linestyle = '--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active and Passive trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_range = (-300, 1000)\n",
    "x_field = 'CD_FB_proj'\n",
    "mask = active_mask\n",
    "n_trials = active_n_trials\n",
    "cond_dict = active_cond_dict\n",
    "dim = dataset_50ms.data[x_field].shape[1]\n",
    "active_df = dataset_50ms.make_trial_data(align_field='move_onset_time', align_range=pred_range, ignored_trials=~mask)\n",
    "dirs = [dataset_50ms.trial_info[dataset_50ms.trial_info.trial_id == i]['cond_dir'] for i in active_df.trial_id]\n",
    "cos_x = [round(math.cos(math.radians(i)),3) for i in dirs]\n",
    "sin_y = [round(math.sin(math.radians(i)),3) for i in dirs]\n",
    "cos_sin = np.array([cos_x, sin_y]).T\n",
    "act_trial_PCA = active_df[x_field].to_numpy().reshape((n_trials, -1, dim))\n",
    "print(act_trial_PCA.shape)\n",
    "act_trial_ang = cos_sin.reshape((n_trials, -1, 2))\n",
    "# act_trial_ang = np.array(cos_x).reshape((n_trials,-1,1))\n",
    "# act_trial_ang = np.array(sin_y).reshape((n_trials,-1,1))\n",
    "\n",
    "print(act_trial_ang.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # decoders angle\n",
    "# dataset = dataset_50ms\n",
    "# x_field = 'PCA_40'\n",
    "# y_field ='hand_acc'\n",
    "\n",
    "# lag_axis = np.arange(-200,1000,50)+50\n",
    "# lag_axis = np.arange(-200,1000,50)+50\n",
    "\n",
    "# act_t_label = lag_axis\n",
    "# act_X_coef_array = act_coefs_arr[:,0,:]\n",
    "# angDist_array = nans([len(act_t_label),len(act_t_label)])\n",
    "\n",
    "# for i in range(len(act_t_label)):\n",
    "#     for j in range(len(act_t_label)):\n",
    "#         angDist_array[i,j] = math.degrees(angle_between(act_X_coef_array[i,:],act_X_coef_array[j,:]))\n",
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# im = ax.imshow(angDist_array)\n",
    "# ax.set_xlabel('Active time (ms)')\n",
    "# ax.set_ylabel('Active time (ms)')\n",
    "\n",
    "# ax.set_xticks(np.arange(len(act_t_label)))\n",
    "# ax.set_yticks(np.arange(len(act_t_label)))\n",
    "# ax.set_xticklabels(labels=act_t_label,size=8)\n",
    "# ax.set_yticklabels(labels=act_t_label,size=8)\n",
    "\n",
    "# ax.set_title(\"Angle between CD+FB weights\")\n",
    "\n",
    "# for i in range(len(act_t_label)):\n",
    "#     for j in range(len(act_t_label)):\n",
    "#         text = ax.text(j, i, str(int(angDist_array[i, j])),\n",
    "#                         ha=\"center\", va=\"center\", color=\"w\", fontsize=14)\n",
    "# plt.tight_layout()\n",
    "# # figDir = '/Users/sherryan/area2_population_analysis/figures_plus/'\n",
    "# # plt.savefig(figDir + monkey + '_decoder_angle.pdf', dpi = 'figure')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = act_trial_PCA.shape[1]\n",
    "act_coefs_arr = nans([n_bins, 2, dim])\n",
    "act_offset_arr = nans([n_bins, 2])\n",
    "act_r2_arr = nans([n_bins])\n",
    "act_r2_xy_arr = nans([n_bins,2])\n",
    "\n",
    "for i in range(n_bins):\n",
    "    X = act_trial_PCA[:,i,:]\n",
    "    Y = act_trial_ang[:,i,:]\n",
    "    X_proc = (X - np.nanmean(X,axis=0))/np.nanstd(X,axis=0)\n",
    "    lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)})\n",
    "    lr_all.fit(X_proc, Y)\n",
    "    act_coefs_arr[i,:,:] = lr_all.best_estimator_.coef_\n",
    "    act_offset_arr[i,:] = lr_all.best_estimator_.intercept_\n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)\n",
    "    true_concat = nans([n_trials,2])\n",
    "    pred_concat = nans([n_trials,2])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test, y_train, y_test = procX_train_test(X,Y,training_set,test_set)\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)})\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "\n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "        trial_save_idx += n\n",
    "    for j in range(true_concat.shape[1]):\n",
    "        sses =get_sses_pred(true_concat[:,j],pred_concat[:,j])\n",
    "        sses_mean=get_sses_mean(true_concat[:,j])\n",
    "        act_r2_xy_arr[i,j] =1-np.sum(sses)/np.sum(sses_mean)   \n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    act_r2_arr[i] = R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(act_trial_ang)\n",
    "act_shuffle_r2_arr = nans([n_bins])\n",
    "for i in range(n_bins):\n",
    "    X = act_trial_PCA[:,i,:]\n",
    "    Y = act_trial_ang[:,i,:]\n",
    "    X_proc = (X - np.nanmean(X,axis=0))/np.nanstd(X,axis=0)\n",
    "    lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)})\n",
    "    lr_all.fit(X_proc, Y)\n",
    "    kf = KFold(n_splits=5,shuffle=True,random_state = 42)\n",
    "    true_concat = nans([n_trials,2])\n",
    "    pred_concat = nans([n_trials,2])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in kf.split(range(0,n_trials)):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test, y_train, y_test = procX_train_test(X,Y,training_set,test_set)\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)})\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "        trial_save_idx += n\n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    act_shuffle_r2_arr[i] = R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_range = (-300, 1000)\n",
    "mask = passive_mask\n",
    "n_trials = passive_n_trials\n",
    "cond_dict = passive_cond_dict\n",
    "passive_df = dataset_50ms.make_trial_data(align_field='move_onset_time', align_range=pred_range, ignored_trials=~mask)\n",
    "dirs = [dataset_50ms.trial_info[dataset_50ms.trial_info.trial_id == i]['cond_dir'] for i in passive_df.trial_id]\n",
    "cos_x = [round(math.cos(math.radians(i)),3) for i in dirs]\n",
    "sin_y = [round(math.sin(math.radians(i)),3) for i in dirs]\n",
    "cos_sin = np.array([cos_x, sin_y]).T\n",
    "pas_trial_PCA = passive_df[x_field].to_numpy().reshape((n_trials, -1, dim))\n",
    "print(pas_trial_PCA.shape)\n",
    "pas_trial_ang = cos_sin.reshape((n_trials, -1, 2))\n",
    "# pas_trial_ang = np.array(cos_x).reshape((n_trials,-1,1))\n",
    "# pas_trial_ang = np.array(sin_y).reshape((n_trials,-1,1))\n",
    "\n",
    "print(pas_trial_ang.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pas_coefs_arr = nans([n_bins, 2, dim])\n",
    "pas_offset_arr = nans([n_bins, 2])\n",
    "pas_r2_arr = nans([n_bins])\n",
    "pas_r2_xy_arr = nans([n_bins,2])\n",
    "\n",
    "for i in range(n_bins):\n",
    "    X = pas_trial_PCA[:,i,:]\n",
    "    Y = pas_trial_ang[:,i,:]\n",
    "    X_proc = (X - np.nanmean(X,axis=0))/np.nanstd(X,axis=0)\n",
    "    lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)})\n",
    "    lr_all.fit(X_proc, Y)\n",
    "    pas_coefs_arr[i,:,:] = lr_all.best_estimator_.coef_\n",
    "    pas_offset_arr[i,:] = lr_all.best_estimator_.intercept_\n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)\n",
    "    true_concat = nans([n_trials,2])\n",
    "    pred_concat = nans([n_trials,2])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test, y_train, y_test = procX_train_test(X,Y,training_set,test_set)\n",
    "        lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)})\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_test_predicted = lr.predict(X_test)\n",
    "\n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "        trial_save_idx += n\n",
    "    for j in range(true_concat.shape[1]):\n",
    "        sses =get_sses_pred(true_concat[:,j],pred_concat[:,j])\n",
    "        sses_mean=get_sses_mean(true_concat[:,j])\n",
    "        pas_r2_xy_arr[i,j] =1-np.sum(sses)/np.sum(sses_mean)   \n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "    pas_r2_arr[i] = R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.shuffle(pas_trial_ang)\n",
    "# pas_shuffle_r2_arr = nans([n_bins])\n",
    "# for i in range(n_bins):\n",
    "#     X = pas_trial_PCA[:,i,:]\n",
    "#     Y = pas_trial_ang[:,i,:]\n",
    "#     X_proc = (X - np.nanmean(X,axis=0))/np.nanstd(X,axis=0)\n",
    "#     lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)})\n",
    "#     lr_all.fit(X_proc, Y)\n",
    "#     kf = KFold(n_splits=5,shuffle=True,random_state = 42)\n",
    "#     true_concat = nans([n_trials,2])\n",
    "#     pred_concat = nans([n_trials,2])\n",
    "#     trial_save_idx = 0\n",
    "#     for training_set, test_set in kf.split(range(0,n_trials)):\n",
    "#         #split training and testing by trials\n",
    "#         X_train, X_test, y_train, y_test = procX_train_test(X,Y,training_set,test_set)\n",
    "#         lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-3, 3, 7)}) \n",
    "#         lr.fit(X_train, y_train)\n",
    "#         y_test_predicted = lr.predict(X_test)\n",
    "\n",
    "#         n = y_test_predicted.shape[0]\n",
    "#         true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "#         pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "#         trial_save_idx += n\n",
    "\n",
    "#     sses =get_sses_pred(true_concat,pred_concat)\n",
    "#     sses_mean=get_sses_mean(true_concat)\n",
    "#     R2 =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "#     pas_shuffle_r2_arr[i] = R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd_act_r2 = act_r2_arr\n",
    "# cd_pas_r2 = pas_r2_arr\n",
    "# fb_act_r2 = act_r2_arr\n",
    "# fb_pas_r2 = pas_r2_arr\n",
    "cd_fb_act_r2 = act_r2_arr\n",
    "cd_fb_pas_r2 = pas_r2_arr\n",
    "\n",
    "# neural_pc_act_r2 = act_r2_arr\n",
    "# neural_pc_pas_r2 = pas_r2_arr\n",
    "# neural_spikes_act_r2 = act_r2_arr\n",
    "# neural_spikes_pas_r2 = pas_r2_arr\n",
    "# emg_act_r2 = act_r2_arr\n",
    "# emg_pas_r2 = pas_r2_arr\n",
    "# muscle_pc_act_r2 = act_r2_arr\n",
    "# muscle_pc_pas_r2 = pas_r2_arr\n",
    "# joint_pc_act_r2 = act_r2_arr\n",
    "# joint_pc_pas_r2 = pas_r2_arr\n",
    "\n",
    "\n",
    "np.savez(monkey+'_cdfb_dir_r2_100oneside', \n",
    "         cd_act_r2 = cd_act_r2, cd_pas_r2 = cd_pas_r2, \\\n",
    "         fb_act_r2 = fb_act_r2,fb_pas_r2 = fb_pas_r2, \\\n",
    "         cd_fb_act_r2 = cd_fb_act_r2,cd_fb_pas_r2 = cd_fb_pas_r2)\n",
    "\n",
    "        #  neural_pc_act_r2 = neural_pc_act_r2, neural_pc_pas_r2 = neural_pc_pas_r2)\n",
    "        #  neural_spikes_act_r2 = neural_spikes_act_r2, neural_spikes_pas_r2 = neural_spikes_pas_r2,\\\n",
    "        #  emg_act_r2 = emg_act_r2, emg_pas_r2 = emg_pas_r2,\\\n",
    "        #  muscle_pc_act_r2 = act_r2_arr, muscle_pc_pas_r2 = pas_r2_arr,\\\n",
    "        #  joint_pc_act_r2 = act_r2_arr, joint_pc_pas_r2 = pas_r2_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_axis = np.arange(-300,1000,50)\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.plot(lag_axis,cd_act_r2, \"-o\",color = 'green', label = 'CD')\n",
    "plt.plot(lag_axis,fb_act_r2, \"-o\",color = 'magenta', label = 'FB')\n",
    "plt.plot(lag_axis,cd_fb_act_r2, \"-o\",color = 'brown', label = 'CD_FB')\n",
    "# plt.plot(lag_axis,neural_pc_act_r2, \"-o\",color = 'grey', label = 'Neural PC')\n",
    "# plt.plot(np.arange(-150,1000,50)+50,neural_spikes_act_r2, \"-o\",color = 'k', label = 'Neural')\n",
    "# plt.plot(lag_axis,emg_act_r2, \"-o\",color = 'orange', label = 'EMG')\n",
    "# plt.plot(lag_axis,muscle_pc_act_r2, \"-o\", label = 'muscle PC')\n",
    "# plt.plot(lag_axis,joint_pc_act_r2, \"-o\", color = 'red',label = 'joint PC')\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(lag_axis,act_shuffle_r2_arr, color = 'k', ls='--',label = 'shuffle')\n",
    "plt.xlabel('Time after movement onset (ms)'); plt.ylabel('R2'); plt.title('Active direction r2')\n",
    "plt.legend(fontsize=8)\n",
    "plt.xlim([-210, 1010])\n",
    "plt.ylim([-0.1, 1.0])\n",
    "plt.axvline(0, color = 'k',linestyle = '--')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_cdfb_dir_r2_active_.pdf',dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_axis = np.arange(-300,1000,50)\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.plot(lag_axis,cd_pas_r2, \"-o\",color = 'green', label = 'CD')\n",
    "plt.plot(lag_axis,fb_pas_r2, \"-o\",color = 'magenta', label = 'FB')\n",
    "plt.plot(lag_axis,cd_fb_pas_r2, \"-o\",color = 'brown', label = 'CD_FB')\n",
    "# plt.plot(lag_axis,neural_pc_pas_r2, \"-o\",color = 'grey', label = 'Neural PC')\n",
    "# plt.plot(np.arange(-150,1000,50)+50,neural_spikes_pas_r2, \"-o\",color = 'k', label = 'Neural')\n",
    "# plt.plot(lag_axis,emg_pas_r2, \"-o\",color = 'orange', label = 'EMG')\n",
    "# plt.plot(lag_axis,muscle_pc_pas_r2, \"-o\", label = 'muscle PC')\n",
    "# plt.plot(lag_axis,joint_pc_pas_r2, \"-o\", color = 'red',label = 'joint PC')\n",
    "\n",
    "\n",
    "plt.plot(lag_axis,act_shuffle_r2_arr, color = 'k', ls='--',label = 'shuffle')\n",
    "plt.xlabel('Time after movement onset (ms)'); plt.ylabel('R2'); plt.title(' Passive direction r2')\n",
    "plt.legend(fontsize=8)\n",
    "plt.xlim([-210, 1010])\n",
    "plt.ylim([-0.1, 1.0])\n",
    "plt.axvline(0, color = 'k',linestyle = '--')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_cdfb_dir_r2_passive.pdf',dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural_pc_act_r2 = act_r2_arr\n",
    "# neural_pc_pas_r2 = pas_r2_arr\n",
    "# neural_pc_act_xy_r2 = act_r2_xy_arr\n",
    "# neural_pc_pas_xy_r2 = pas_r2_xy_arr\n",
    "# vel_act_r2 = act_r2_arr\n",
    "# vel_pas_r2 = pas_r2_arr\n",
    "vel_act_xy_r2 = act_r2_xy_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_axis = np.arange(-300,1000,50)\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.plot(lag_axis,neural_pc_act_r2, \"-o\",color = 'k', label = 'Active, 20PC')\n",
    "plt.plot(lag_axis,neural_pc_act_xy_r2[:,0], \"-o\",label = 'Active, 20PC,x-dir')\n",
    "plt.plot(lag_axis,neural_pc_act_xy_r2[:,1], \"-o\", label = 'Active, 20PC,y-dir')\n",
    "plt.plot(lag_axis,vel_act_r2,\"-o\", color = 'gray',label = 'Active, velocity')\n",
    "plt.plot(lag_axis,vel_act_xy_r2[:,0], \"-o\",color = 'gray',label = 'Active, velocity,x-dir')\n",
    "plt.plot(lag_axis,vel_act_xy_r2[:,1], \"-o\", color = 'gray',label = 'Active, velocity,y-dir')\n",
    "\n",
    "# plt.plot(lag_axis,neural_pc_pas_r2,\"-o\", color = 'red', label = 'Passive, 20PC')\n",
    "# plt.plot(lag_axis,pas_shuffle_r2_arr, color = 'red', ls='--',label = 'Passive shuffle')\n",
    "# plt.plot(lag_axis,vel_pas_r2,\"-o\", color = 'gray',label = 'Passive, velocity')\n",
    "\n",
    "plt.plot(lag_axis,act_shuffle_r2_arr, color = 'k', ls='--',label = 'shuffle')\n",
    "\n",
    "plt.xlabel('Time after movement onset (ms)'); plt.ylabel('R2'); \n",
    "plt.title('Direction r2')\n",
    "plt.legend(fontsize=8)\n",
    "plt.xlim([-300, 610])\n",
    "plt.axvline(0, color = 'k',linestyle = '--')\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_direction_r2.pdf',dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single-lag decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_10ms\n",
    "dataset.data.keys().unique(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_field = 'spikes_smth_40_oneside'\n",
    "data = np.load(monkey+'_ac2_cdfb_data_'+x_field+'.npz')\n",
    "data.files\n",
    "dataset.add_continuous_data(data['CD_FB_proj'],'CD_FB_proj')\n",
    "dataset.add_continuous_data(data['CD_proj'],'CD_proj')\n",
    "dataset.add_continuous_data(data['FB_proj'],'FB_proj')\n",
    "dataset.data.keys().unique(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(monkey+'_cdfb_weights_spikes_smth_40.npz')\n",
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CD_FB_axes = np.vstack([CD_axes,FB_axes])\n",
    "# CD_FB_axes.shape\n",
    "\n",
    "CD_FB_axes = np.vstack([data['CD_axes'],data['FB_axes']])\n",
    "CD_FB_axes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, best_coef,_, _, _ = fit_and_predict(dataset, active_mask, 'move_onset_time',pred_range, 0, 'spikes_smth_40', 'hand_vel', cond_dict = cond_dict)\n",
    "X = CD_FB_axes.T #(n_samples, n_features)\n",
    "Y = best_coef.T\n",
    "reg = LinearRegression().fit(X, Y)\n",
    "reg.score(X,Y)\n",
    "reg.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,reg.coef_.shape[1]+1),reg.coef_[1,:])\n",
    "plt.title('y weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,reg.coef_.shape[1]+1),reg.coef_[0,:])\n",
    "plt.title('x weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Straight decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_10ms.data.keys().unique(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_field = 'ac150_CD_FB_proj_spikes_smth_150_oneside'\n",
    "y_field ='hand_vel'\n",
    "lag_axis = np.arange(-300,300,20)\n",
    "pred_range = (-100, 1000)\n",
    "trial_mask = active_mask\n",
    "cond_dict = active_cond_dict\n",
    "# pred_range = (-100, 120)\n",
    "# trial_mask = passive_mask\n",
    "# cond_dict = passive_cond_dict\n",
    "dataset=dataset_10ms\n",
    "dim = dataset.data[x_field].shape[1]\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_array = nans([len(lag_axis)]); r2_feature_array = nans([len(lag_axis),dataset.data[y_field].shape[1]])\n",
    "r_array = nans([len(lag_axis)])\n",
    "coef_array = nans([len(lag_axis),dataset.data[y_field].shape[1],dim])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    r2, coef,_,vel_df,r2_arr = fit_and_predict(dataset, trial_mask, 'move_onset_time',pred_range, lag, x_field, y_field,cond_dict)\n",
    "    # r2, vel_df,r2_arr = fit_and_predict_DNN(dataset, trial_mask, 'move_onset_time',pred_range, lag, x_field, y_field,cond_dict)\n",
    "    r2_array[i] = r2; r2_feature_array[i,:] = r2_arr\n",
    "    r = scipy.stats.pearsonr(vel_df[y_field].to_numpy().reshape(-1), vel_df['pred_vel'].to_numpy().reshape(-1))[0]\n",
    "    r_array[i] = r\n",
    "    coef_array[i,:,:] = coef\n",
    "time_max = lag_axis[np.argmax(r2_array)]\n",
    "print(np.max(r2_array))\n",
    "print(time_max)\n",
    "# _, best_coef,best_intercept, best_vel_df, r2_arr = fit_and_predict(dataset, trial_mask, 'move_onset_time',pred_range, time_max, x_field, y_field, cond_dict = cond_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lag_axis, r2_array)\n",
    "plt.plot(lag_axis, r2_feature_array[:,0],label='x')\n",
    "plt.plot(lag_axis, r2_feature_array[:,1],label='y')\n",
    "print(lag_axis[np.argmax(r2_feature_array[:,0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_time_max = lag_axis[np.argmax(r2_feature_array[:,0])]\n",
    "y_time_max = lag_axis[np.argmax(r2_feature_array[:,1])]\n",
    "print('x',x_time_max)\n",
    "print('y',y_time_max)\n",
    "if x_time_max != y_time_max:\n",
    "    _, x_best_coef,x_best_intercept, _, _ = fit_and_predict(dataset, trial_mask, 'move_onset_time',pred_range, x_time_max, x_field, y_field, cond_dict = cond_dict)\n",
    "    _, y_best_coef,y_best_intercept, _, _ = fit_and_predict(dataset, trial_mask, 'move_onset_time',pred_range, y_time_max, x_field, y_field, cond_dict = cond_dict)\n",
    "# r2_feature_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_cd_dims = 4\n",
    "# if x_time_max == y_time_max:\n",
    "#     x_cd_weight = np.sum(abs(best_coef[0,:n_cd_dims]))\n",
    "#     x_fb_weight = np.sum(abs(best_coef[0,n_cd_dims:]))\n",
    "#     y_cd_weight = np.sum(abs(best_coef[1,:n_cd_dims]))\n",
    "#     y_fb_weight = np.sum(abs(best_coef[1,n_cd_dims:]))\n",
    "# else:\n",
    "#     x_cd_weight = np.sum(abs(x_best_coef[0,:n_cd_dims]))\n",
    "#     x_fb_weight = np.sum(abs(x_best_coef[0,n_cd_dims:]))\n",
    "#     y_cd_weight = np.sum(abs(y_best_coef[1,:n_cd_dims]))\n",
    "#     y_fb_weight = np.sum(abs(y_best_coef[1,n_cd_dims:]))\n",
    "# print(x_cd_weight)\n",
    "# print(x_fb_weight)\n",
    "# print(y_cd_weight)\n",
    "# print(y_fb_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_cross_array = nans([len(lag_axis)]); x_r2_cross_array = nans([len(lag_axis)])\n",
    "# r_cross_array = nans([len(lag_axis)])\n",
    "# for i in range(len(lag_axis)):\n",
    "#     lag = lag_axis[i]\n",
    "#     r2, _, x_r2,_,vel_df = pred_with_new_weights(dataset, trial_mask, 'move_onset_time',pred_range, lag,x_field,\n",
    "#                                                 y_field, x_best_coef, x_best_intercept, 'move_onset_time',pred_range, (pred_range[0]+x_time_max, pred_range[1]+x_time_max), trial_mask)\n",
    "#     r2_cross_array[i] = r2; x_r2_cross_array[i] = x_r2\n",
    "#     r = scipy.stats.pearsonr(vel_df[y_field].to_numpy().reshape(-1), vel_df['pred_vel'].to_numpy().reshape(-1))[0]\n",
    "#     r_cross_array[i] = r\n",
    "# plt.plot(lag_axis,r_cross_array)\n",
    "# plt.xlabel('Time lag (ms)')\n",
    "# plt.ylabel('r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx_max_pos = np.argwhere(r2_array == np.max(r2_array[np.argwhere(lag_axis==0)[0,0]:]))[0,0]\n",
    "# idx_max_neg = np.argwhere(r2_array == np.max(r2_array[:np.argwhere(lag_axis==0)[0,0]]))[0,0]\n",
    "# print(lag_axis[idx_max_pos])\n",
    "# print(lag_axis[idx_max_neg])\n",
    "\n",
    "# #For velocity, override max identification\n",
    "# # idx_max_pos = np.argwhere(lag_axis==80)[0,0]\n",
    "# # idx_max_neg = np.argwhere(lag_axis==-40)[0,0]\n",
    "\n",
    "# ang_to_max_x = nans([len(lag_axis)])\n",
    "# ang_to_max_y = nans([len(lag_axis)])\n",
    "# # ang_to_max_z = nans([len(lag_axis)])\n",
    "# for i in range(0, len(coef_array)):\n",
    "#     ang_to_max_x[i] = math.degrees(angle_between(coef_array[i,0,:],coef_array[idx_max_neg,0,:]))\n",
    "#     ang_to_max_y[i] = math.degrees(angle_between(coef_array[i,1,:],coef_array[idx_max_neg,1,:]))\n",
    "#     # ang_to_max_z[i] = math.degrees(angle_between(coef_array[i,2,:],coef_array[idx_max_neg,2,:]))\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.spines['right'].set_visible(False)\n",
    "# ax.spines['top'].set_visible(False)\n",
    "# # plt.ylim([-5, 130])\n",
    "# plt.xlim([-310, 310])\n",
    "# plt.scatter(lag_axis, ang_to_max_x,label = 'x',color = 'green')\n",
    "# plt.scatter(lag_axis, ang_to_max_y,label = 'y',color = 'blue')\n",
    "# # plt.scatter(lag_axis, ang_to_max_z,label = 'wrist_abduction',color = 'orange')\n",
    "\n",
    "# plt.legend()\n",
    "# plt.xlabel('Time lag (ms)')\n",
    "# plt.ylabel('Angle (degrees)')\n",
    "# mean = np.mean([ang_to_max_x[idx_max_neg], ang_to_max_y[idx_max_neg]])\n",
    "# print(mean)\n",
    "# # plt.vlines(lag_axis[idx_max_pos],-5, mean, color = 'k',linestyle=\"dashed\")\n",
    "# # plt.hlines(mean, -310, lag_axis[idx_max_pos], color = 'k',linestyle=\"dashed\")\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig(figDir + monkey + label + str(0) +'_angle.pdf', dpi = 'figure')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_range_arr = [(-100, 0),(0, 200),(200, 400),(400, 600),(600, 800),(800, 1000)]\n",
    "# pred_range_arr = [(-100, 0),(0, 100),(100, 200),(200, 300),(300, 400),(400, 500)]\n",
    "\n",
    "r2_array_tw = nans([len(pred_range_arr)]); r2_feature_array_tw = nans([len(pred_range_arr),dataset.data[y_field].shape[1]])\n",
    "for tw in range(len(pred_range_arr)):\n",
    "    tw_range = pred_range_arr[tw]\n",
    "    if x_time_max == y_time_max:\n",
    "        r2, _, x_r2,y_r2,_ = pred_with_new_weights(dataset, trial_mask, 'move_onset_time',tw_range, time_max,x_field,\n",
    "                                                y_field, best_coef, best_intercept, 'move_onset_time',pred_range, (pred_range[0]+time_max, pred_range[1]+time_max), trial_mask)\n",
    "        r2_array_tw[tw] = r2; r2_feature_array_tw[tw,:] = np.array([x_r2,y_r2])\n",
    "    else:\n",
    "        r2, _, _,_,_ = pred_with_new_weights(dataset, trial_mask, 'move_onset_time',tw_range, time_max,x_field,\n",
    "                                                y_field, best_coef, best_intercept, 'move_onset_time',pred_range, (pred_range[0]+time_max, pred_range[1]+time_max), trial_mask)\n",
    "        _, _, x_r2,_,_ = pred_with_new_weights(dataset, trial_mask, 'move_onset_time',tw_range, x_time_max,x_field,\n",
    "                                                y_field, x_best_coef, x_best_intercept, 'move_onset_time',pred_range, (pred_range[0]+x_time_max, pred_range[1]+x_time_max), trial_mask)\n",
    "        _, _, _,y_r2,_ = pred_with_new_weights(dataset, trial_mask, 'move_onset_time',tw_range, y_time_max,x_field,\n",
    "                                        y_field, y_best_coef, y_best_intercept, 'move_onset_time',pred_range, (pred_range[0]+y_time_max, pred_range[1]+y_time_max), trial_mask)\n",
    "        r2_array_tw[tw] = r2; r2_feature_array_tw[tw,:] = np.array([x_r2,y_r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for plotting\n",
    "plot_dir = [0.0, 90.0, 180.0, 270.0] # limit plot directions to reduce cluttering\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "plot_dim = 'x' # plot x velocity \n",
    "\n",
    "x_axis = np.arange(-100,1000,dataset.bin_width)\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset.trial_info[dataset.trial_info.cond_dir %360 == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial[y_field][plot_dim], color=color, linewidth=0.5)\n",
    "        # plt.plot(x_axis, trial[y_field].to_numpy()[:,0], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time after movement onset (ms)')\n",
    "# plt.ylabel('Hand velocity (cm/s)')\n",
    "\n",
    "# plt.xlim([-100,500])\n",
    "# plt.ylim([-0.65,0.65])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + label + 'true.pdf', dpi = 'figure')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset.trial_info[dataset.trial_info.cond_dir %360 == trial_dir].trial_id\n",
    "    for _, trial in sub_vel_df[np.isin(sub_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "         plt.plot(x_axis, trial['pred_vel'][plot_dim], color=color, linewidth=0.5)\n",
    "        # plt.plot(x_axis, trial.pred_vel.to_numpy()[:,0], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time after movement onset (ms)')\n",
    "# plt.ylabel('Hand velocity (cm/s)')\n",
    "# plt.xlim([-100,500])\n",
    "# plt.ylim([-0.65,0.65])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + label + str(0) +'_pred.pdf', dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for plotting\n",
    "plot_dir = [0.0, 90.0, 180.0, 270.0] # limit plot directions to reduce cluttering\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "plot_dim = 'y' # plot x velocity \n",
    "\n",
    "x_axis = np.arange(-100,1000,dataset.bin_width)\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset.trial_info[dataset.trial_info.cond_dir %360 == trial_dir].trial_id\n",
    "    for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial[y_field][plot_dim], color=color, linewidth=0.5)\n",
    "        # plt.plot(x_axis, trial[y_field].to_numpy()[:,0], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time after movement onset (ms)')\n",
    "# plt.ylabel('Hand velocity (cm/s)')\n",
    "\n",
    "# plt.xlim([-100,500])\n",
    "# plt.ylim([-0.65,0.65])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + label + 'true.pdf', dpi = 'figure')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset.trial_info[dataset.trial_info.cond_dir %360 == trial_dir].trial_id\n",
    "    for _, trial in sub_vel_df[np.isin(sub_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "         plt.plot(x_axis, trial['pred_vel'][plot_dim], color=color, linewidth=0.5)\n",
    "        # plt.plot(x_axis, trial.pred_vel.to_numpy()[:,0], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time after movement onset (ms)')\n",
    "# plt.ylabel('Hand velocity (cm/s)')\n",
    "# plt.xlim([-100,500])\n",
    "# plt.ylim([-0.65,0.65])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + label + str(0) +'_pred.pdf', dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot some periods of predictions\n",
    "plot_dim='y'\n",
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.plot(vel_df['hand_vel']['y'][1000:5000],color = 'k')\n",
    "plt.plot(vel_df['pred_vel']['y'][1000:5000],color = 'brown')\n",
    "plt.tight_layout()\n",
    "plt.xlabel('Time after movement onset (ms)')\n",
    "plt.ylabel('Hand velocity (cm/s)')\n",
    "# plt.savefig(figDir + monkey+'_cd_pred_.pdf',dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dim= np.min([10, dataset.data[x_field].shape[1]])\n",
    "plt.plot(lag_axis,r2_feature_array)\n",
    "plt.legend(fontsize=8)\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('Variable R2')\n",
    "plt.title(x_field+' -> '+y_field)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.plot(lag_axis, r2_array)\n",
    "plt.title(x_field)\n",
    "\n",
    "# for i in range(dim):\n",
    "#     plt.plot(lag_axis,np.sum(abs(coef_array[:,:,order[i]]),axis=1),label = str(i+1))\n",
    "# plt.legend(fontsize=8)\n",
    "# plt.xlabel('Time lag (ms)')\n",
    "# plt.ylabel('Latent weight')\n",
    "# plt.title(x_field+' sum')\n",
    "# plt.show()\n",
    "\n",
    "# for i in range(dim):\n",
    "#     plt.plot(lag_axis,(coef_array[:,0,order[i]]),label = str(i+1))\n",
    "# plt.legend(fontsize=8)\n",
    "# plt.xlabel('Time lag (ms)')\n",
    "# plt.ylabel('Latent weight')\n",
    "# plt.title(x_field+' x-dir')\n",
    "# plt.show()\n",
    "# for i in range(dim):\n",
    "#     plt.plot(lag_axis,(coef_array[:,1,order[i]]),label = str(i+1))\n",
    "# plt.legend(fontsize=8)\n",
    "# plt.xlabel('Time lag (ms)')\n",
    "# plt.ylabel('Latent weight')\n",
    "# plt.title(x_field+' y-dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_r2_cd_only = r2_feature_array[:,0]\n",
    "# y_r2_cd_only = r2_feature_array[:,1]\n",
    "# r2_cd_only = r2_array\n",
    "# tmax_cd_only = time_max\n",
    "\n",
    "# x_r2_fb_only = r2_feature_array[:,0]\n",
    "# y_r2_fb_only = r2_feature_array[:,1]\n",
    "# r2_fb_only = r2_array\n",
    "# tmax_fb_only = time_max\n",
    "\n",
    "x_r2_cd_fb = r2_feature_array[:,0]\n",
    "y_r2_cd_fb = r2_feature_array[:,1]\n",
    "r2_cd_fb = r2_array\n",
    "tmax_cd_fb = time_max\n",
    "\n",
    "# x_r2_all_pc = r2_feature_array[:,0]\n",
    "# y_r2_all_pc = r2_feature_array[:,1]\n",
    "# r2_all_pc = r2_array\n",
    "# tmax_all_pc = time_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(monkey+'_ac150_spikes_'+y_field +'_act_r2s', \\\n",
    "         x_r2_cd_only = x_r2_cd_only, y_r2_cd_only = y_r2_cd_only, r2_cd_only = r2_cd_only, \\\n",
    "         x_r2_fb_only = x_r2_fb_only, y_r2_fb_only = y_r2_fb_only, r2_fb_only = r2_fb_only,\\\n",
    "         x_r2_cd_fb = x_r2_cd_fb, y_r2_cd_fb = y_r2_cd_fb, r2_cd_fb = r2_cd_fb)\n",
    "# ,\n",
    "        #  x_r2_all_pc = x_r2_all_pc, y_r2_all_pc = y_r2_all_pc,r2_all_pc=r2_all_pc) \n",
    "# monkey = \"Han_20171207\"\n",
    "data = np.load(monkey+'_ac150_spikes_hand_vel_act_r2s.npz')\n",
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(monkey+'_all_nrn_150oneside'+y_field +'_act_r2s', \\\n",
    "        r2_all_nrn_array = r2_array,\\\n",
    "        r2_feature_all_nrn_array = r2_feature_array)\n",
    "\n",
    "data_all_nrn = np.load(monkey+'_all_nrn_150onesidehand_vel_act_r2s.npz')\n",
    "data_all_nrn.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_axis = np.arange(-300,300,20)\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.axvline(0, color = 'k', linestyle='--')\n",
    "\n",
    "plt.plot(lag_axis, data['r2_cd_only'],color = 'green',label='cd')\n",
    "plt.plot(lag_axis, data['r2_fb_only'],color = 'magenta',label='fb')\n",
    "plt.plot(lag_axis, data['r2_cd_fb'],color = 'brown',label='cd+fb')\n",
    "# plt.plot(lag_axis, data['r2_all_pc'],color = 'k',label='20 PC')\n",
    "plt.plot(lag_axis, data_all_nrn['r2_all_nrn_array'],color = 'k',label='all nrn')\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_axis[np.argmax(data['r2_cd_only'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_axis = np.arange(-300,300,20)\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.plot(lag_axis, data['x_r2_cd_only'],color = 'green',label='cd')\n",
    "plt.plot(lag_axis, data['x_r2_fb_only'],color = 'magenta',label='fb')\n",
    "plt.plot(lag_axis, data['x_r2_cd_fb'],color = 'brown',label='cd+fb')\n",
    "# plt.plot(lag_axis,  data['x_r2_all_pc'],color = 'k',label='20 PC')\n",
    "plt.plot(lag_axis, data_all_nrn['r2_feature_all_nrn_array'][:,0],color = 'k',label='all nrn')\n",
    "\n",
    "plt.axvline(0, color = 'k', linestyle='--')\n",
    "# print(time_max)\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "# plt.title(monkey + x_field+' x-dir')\n",
    "# plt.ylim([0.05,0.8])\n",
    "# plt.legend()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey +'_act_vel_y_.pdf', dpi = 'figure')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.plot(lag_axis, data['y_r2_cd_only'],color = 'green',label='cd')\n",
    "plt.plot(lag_axis, data['y_r2_fb_only'],color = 'magenta',label='fb')\n",
    "plt.plot(lag_axis, data['y_r2_cd_fb'],color = 'brown',label='cd+fb')\n",
    "# plt.plot(lag_axis,  data['y_r2_all_pc'],color = 'k',label='20 PC')\n",
    "plt.plot(lag_axis, data_all_nrn['r2_feature_all_nrn_array'][:,1],color = 'k',label='all nrn')\n",
    "\n",
    "plt.axvline(0, color = 'k', linestyle='--')\n",
    "# print(time_max)\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "# plt.title(monkey + x_field+' y-dir')\n",
    "# plt.ylim([0.05,0.8])\n",
    "# plt.legend()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey +'_act_vel_y_.pdf', dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_field = '8020_CD_FB_proj_spikes_smth_40'\n",
    "y_field ='hand_vel'\n",
    "lag_axis = np.arange(-300,300,20)\n",
    "pred_range = (-100, 1000)\n",
    "trial_mask = active_mask\n",
    "cond_dict = active_cond_dict\n",
    "# pred_range = (-100, 500)\n",
    "# trial_mask = passive_mask\n",
    "# cond_dict = passive_cond_dict\n",
    "\n",
    "dim = dataset.data[x_field].shape[1]\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_range_arr = [(-100, 0),(0, 200),(200, 400),(400, 600),(600, 800),(800, 1000)]\n",
    "# pred_range_arr = [(-100, 0),(0, 100),(100, 200),(200, 300),(300, 400),(400, 500)]\n",
    "\n",
    "r2_array_dynam = nans([len(pred_range_arr),len(lag_axis)]); r2_feature_array_dynam = nans([len(pred_range_arr),len(lag_axis),dataset.data[y_field].shape[1]])\n",
    "coef_array_dynam = nans([len(pred_range_arr),len(lag_axis),dataset.data[y_field].shape[1],dim])\n",
    "time_max_array_dynam = nans([len(pred_range_arr)])\n",
    "vel_df_array_dynam = []\n",
    "for tw in range(len(pred_range_arr)):\n",
    "    tw_range = pred_range_arr[tw]\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef,_,vel_df,r2_arr = fit_and_predict(dataset, trial_mask, 'move_onset_time',tw_range, lag, x_field, y_field,cond_dict)\n",
    "        r2_array_dynam[tw,i] = r2; r2_feature_array_dynam[tw,i,:] = r2_arr\n",
    "        coef_array_dynam[tw,i,:,:] = coef\n",
    "    t_max = lag_axis[np.argmax(r2_array_dynam[tw,:])]\n",
    "    print(np.max(r2_array_dynam[tw,:]))\n",
    "    time_max_array_dynam[tw] = t_max\n",
    "    _, _,_, vel_df, _ = fit_and_predict(dataset, trial_mask, 'move_onset_time',tw_range, t_max, x_field, y_field, cond_dict = cond_dict)\n",
    "    vel_df_array_dynam.append(np.array(vel_df['pred_vel']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.plot(range(len(pred_range_arr)), r2_array_tw,'k',label='static')\n",
    "plt.plot(range(len(pred_range_arr)), r2_feature_array_tw[:,0],'blue')\n",
    "plt.plot(range(len(pred_range_arr)), r2_feature_array_tw[:,1],'orange')\n",
    "plt.plot(range(len(pred_range_arr)), np.max(r2_array_dynam,axis=1),'k--',label='dynamic')\n",
    "plt.plot(range(len(pred_range_arr)), np.max(r2_feature_array_dynam[:,:,0],axis=1),'blue',ls='--')\n",
    "plt.plot(range(len(pred_range_arr)), np.max(r2_feature_array_dynam[:,:,1],axis=1),'orange',ls='--')\n",
    "plt.xticks(range(len(pred_range_arr)),['-100','0','200','400','600','800'])\n",
    "plt.ylim([-0.1,1])\n",
    "plt.xlabel('Time window start (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(time_max_array_dynam,range(len(pred_range_arr)),'k--')\n",
    "plt.axvline(x=time_max,color='k')\n",
    "plt.yticks(range(len(pred_range_arr)),['-100','0','200','400','600','800'])\n",
    "plt.xlabel('Best time lag (ms)')\n",
    "plt.ylabel('Time window start (ms)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_array = []\n",
    "for i in range(len(vel_df_array_dynam)):\n",
    "    stack_array.append(vel_df_array_dynam[i].reshape(active_n_trials,-1,2))\n",
    "concat_pred = np.hstack(stack_array)\n",
    "print(concat_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dir = np.array([0.0, 45.0,90.0, 135.0, 180.0, 225.0, 270.0, 315.0])\n",
    "plot_dir = [0.0, 90.0, 180.0, 270.0] # limit plot directions to reduce cluttering\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "for i in range(len(plot_dir)):\n",
    "    idx = np.argwhere(all_dir==plot_dir[i])[0,0]\n",
    "    plt.plot(np.arange(-100, 1000, 10),concat_pred[active_cond_dict==idx,:,0].T,color=colors[i],alpha=0.5,linewidth=1)\n",
    "plt.xlabel('Time after move onset (ms)')\n",
    "plt.ylabel('Hand velocity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dir = np.array([0.0, 45.0,90.0, 135.0, 180.0, 225.0, 270.0, 315.0])\n",
    "plot_dir = [0.0, 90.0, 180.0, 270.0] # limit plot directions to reduce cluttering\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "for i in range(len(plot_dir)):\n",
    "    idx = np.argwhere(all_dir==plot_dir[i])[0,0]\n",
    "    plt.plot(np.arange(-100, 1000, 10),concat_pred[active_cond_dict==idx,:,1].T,color=colors[i],alpha=0.5,linewidth=1)\n",
    "plt.xlabel('Time after move onset (ms)')\n",
    "plt.ylabel('Hand velocity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "for i in range(len(pred_range_arr)):\n",
    "    plt.plot(lag_axis, r2_array_dynam[i,:].T,label=pred_range_arr[i])\n",
    "plt.legend(fontsize=8)\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "for i in range(len(pred_range_arr)):\n",
    "    plt.plot(lag_axis, r2_feature_array_dynam[i,:,0].T,label=pred_range_arr[i])\n",
    "plt.legend(fontsize=8)\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.title('x-dir')\n",
    "plt.show()\n",
    "\n",
    "x_time_max_array = lag_axis[np.argmax(r2_feature_array_dynam[:,:,0],axis=1)]\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(x_time_max_array,range(len(pred_range_arr)),'k--')\n",
    "plt.axvline(x=x_time_max,color='k')\n",
    "plt.yticks(range(len(pred_range_arr)),['-100','0','200','400','600','800'])\n",
    "plt.xlabel('Best time lag (ms)')\n",
    "plt.ylabel('Time window start (ms)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "for i in range(len(pred_range_arr)):\n",
    "    plt.plot(lag_axis, r2_feature_array_dynam[i,:,1].T,label=pred_range_arr[i])\n",
    "plt.legend(fontsize=8)\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.title('y-dir')\n",
    "\n",
    "y_time_max_array = lag_axis[np.argmax(r2_feature_array_dynam[:,:,1],axis=1)]\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(y_time_max_array,range(len(pred_range_arr)),'k--')\n",
    "plt.axvline(x=y_time_max,color='k')\n",
    "plt.yticks(range(len(pred_range_arr)),['-100','0','200','400','600','800'])\n",
    "plt.xlabel('Best time lag (ms)')\n",
    "plt.ylabel('Time window start (ms)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cd_dims = 4\n",
    "x_max_idx_arr = np.argmax(r2_feature_array_dynam[:,:,0],axis=1)\n",
    "x_cd_dynam_weight=[]\n",
    "x_fb_dynam_weight = []\n",
    "for i in range(len(pred_range_arr)):\n",
    "    x_cd_dynam_weight.append(coef_array_dynam[i,x_max_idx_arr[i],0,:n_cd_dims])\n",
    "    x_fb_dynam_weight.append(coef_array_dynam[i,x_max_idx_arr[i],0,n_cd_dims:])\n",
    "x_cd_dynam_weight = np.sum(abs(np.array((x_cd_dynam_weight))),axis=1)\n",
    "x_fb_dynam_weight = np.sum(abs(np.array((x_fb_dynam_weight))),axis=1)\n",
    "\n",
    "y_max_idx_arr = np.argmax(r2_feature_array_dynam[:,:,1],axis=1)\n",
    "y_cd_dynam_weight=[]\n",
    "y_fb_dynam_weight = []\n",
    "for i in range(len(pred_range_arr)):\n",
    "    y_cd_dynam_weight.append(coef_array_dynam[i,y_max_idx_arr[i],1,:n_cd_dims])\n",
    "    y_fb_dynam_weight.append(coef_array_dynam[i,y_max_idx_arr[i],1,n_cd_dims:])\n",
    "y_cd_dynam_weight = np.sum(abs(np.array((y_cd_dynam_weight))),axis=1)\n",
    "y_fb_dynam_weight = np.sum(abs(np.array((y_fb_dynam_weight))),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if x_time_max == y_time_max:\n",
    "    x_cd_weight = np.sum(abs(best_coef[0,:n_cd_dims]))\n",
    "    x_fb_weight = np.sum(abs(best_coef[0,n_cd_dims:]))\n",
    "    y_cd_weight = np.sum(abs(best_coef[1,:n_cd_dims]))\n",
    "    y_fb_weight = np.sum(abs(best_coef[1,n_cd_dims:]))\n",
    "else:\n",
    "    x_cd_weight = np.sum(abs(x_best_coef[0,:n_cd_dims]))\n",
    "    x_fb_weight = np.sum(abs(x_best_coef[0,n_cd_dims:]))\n",
    "    y_cd_weight = np.sum(abs(y_best_coef[1,:n_cd_dims]))\n",
    "    y_fb_weight = np.sum(abs(y_best_coef[1,n_cd_dims:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.array(range(len(pred_range_arr)))\n",
    "plt.bar(x_axis,x_cd_dynam_weight,width=0.2,color='green',label='CD')\n",
    "plt.bar(x_axis+0.2,x_fb_dynam_weight,width=0.2,color='magenta',label='FB')\n",
    "plt.axhline(x_cd_weight,color='green')\n",
    "plt.axhline(x_fb_weight,color='magenta')\n",
    "\n",
    "plt.xticks(range(len(pred_range_arr)),['-100','0','200','400','600','800'])\n",
    "plt.ylabel('Sum signal dim weight in decoder')\n",
    "plt.xlabel('Time window start (ms)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.array(range(len(pred_range_arr)))\n",
    "plt.bar(x_axis+0,y_cd_dynam_weight,width=0.2,color='green',label='CD')\n",
    "plt.bar(x_axis+0.2,y_fb_dynam_weight,width=0.2,color='magenta',label='FB')\n",
    "plt.axhline(y_cd_weight,color='green')\n",
    "plt.axhline(y_fb_weight,color='magenta')\n",
    "plt.xticks(range(len(pred_range_arr)),['-100','0','200','400','600','800'])\n",
    "plt.ylabel('Sum signal weight in decoder')\n",
    "plt.xlabel('Time window start (ms)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey = \"Han_20171207\"\n",
    "# monkey = 'Duncan_20190710'\n",
    "data = np.load(monkey+'_ac150_spikes_hand_vel_act_r2s.npz')\n",
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_axis = np.arange(-300,300,20)\n",
    "print(lag_axis[np.argmax(data['x_r2_cd_only'])])\n",
    "print(lag_axis[np.argmax(data['x_r2_fb_only'])])\n",
    "# print(lag_axis[np.argmax(data['x_r2_cd_fb'])])\n",
    "print(lag_axis[np.argmax(data['y_r2_cd_only'])])\n",
    "print(lag_axis[np.argmax(data['y_r2_fb_only'])])\n",
    "# print(lag_axis[np.argmax(data['y_r2_cd_fb'])])\n",
    "print()\n",
    "print(lag_axis[np.argmax(data['r2_cd_only'])])\n",
    "print(lag_axis[np.argmax(data['r2_fb_only'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.data.keys().unique(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_field = 'spikes_smth_40'\n",
    "data = np.load(monkey+'_X_cdfb_data_proj_out.npz')\n",
    "data.files\n",
    "dataset.add_continuous_data(data['CD_FB_proj'],'CD_FB_proj')\n",
    "dataset.add_continuous_data(data['CD_proj'],'CD_proj')\n",
    "dataset.add_continuous_data(data['FB_proj'],'FB_proj')\n",
    "dataset.data.keys().unique(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "negative_lag = -180\n",
    "positive_lag = 60\n",
    "both_lag = 0\n",
    "cond_dict = active_cond_dict\n",
    "n_trials = active_n_trials\n",
    "\n",
    "y_field ='hand_vel'\n",
    "train_range = (-100,1000)\n",
    "train_pos_lag_range = (train_range[0]+positive_lag, train_range[1]+positive_lag)\n",
    "train_neg_lag_range = (train_range[0]+negative_lag, train_range[1]+negative_lag)\n",
    "train_both_lag_range = (train_range[0]+both_lag, train_range[1]+both_lag)\n",
    "n_timepoints = int((train_range[1] - train_range[0])/dataset.bin_width)\n",
    "\n",
    "train_mask = active_mask\n",
    "# _, eff_weights, eff_offset, _,_ = fit_and_predict(dataset, train_mask, 'move_onset_time',train_range, negative_lag, 'CD_proj', y_field, cond_dict = cond_dict)\n",
    "# _, _, _,_,act_eff_vel_df = pred_with_new_weights(dataset, train_mask, 'move_onset_time',train_range, 0,'CD_proj',\n",
    "#                                                  y_field, eff_weights, eff_offset, 'move_onset_time',train_range, train_neg_lag_range, train_mask)\n",
    "\n",
    "# _, aff_weights, aff_offset, _,_ = fit_and_predict(dataset, train_mask, 'move_onset_time',train_range, positive_lag, 'FB_proj', y_field, cond_dict = cond_dict)\n",
    "# _, _, _,_,act_aff_vel_df = pred_with_new_weights(dataset, train_mask, 'move_onset_time',train_range, 0,'FB_proj',\n",
    "#                                                  y_field, aff_weights, aff_offset, 'move_onset_time',train_range, train_pos_lag_range, train_mask)\n",
    "\n",
    "_, all_weights, all_offset, _,_ = fit_and_predict(dataset, train_mask, 'move_onset_time',train_range, both_lag, 'spikes_smth_40', y_field, cond_dict = cond_dict)\n",
    "_, _, _,_,act_all_vel_df = pred_with_new_weights(dataset, train_mask, 'move_onset_time',train_range, 0,'spikes_smth_40',\n",
    "                                                 y_field, all_weights, all_offset, 'move_onset_time',train_range, train_both_lag_range, train_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range=train_range, ignored_trials=~active_mask, allow_overlap=True)\n",
    "latents = np.array(df.CD_FB_proj).reshape(n_trials, n_timepoints, -1)\n",
    "latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(act_all_vel_df.pred_vel).reshape(active_n_trials, n_timepoints, -1)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Neural_Decoding.decoders import DenseNNDecoder\n",
    "Y = predictions\n",
    "data_field = 'CD_FB_proj'\n",
    "lag_axis = np.arange(-100,200,50)\n",
    "regressed_r2_array = nans([len(lag_axis)])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    print(lag)\n",
    "    lag_train_range = (train_range[0]+lag, train_range[1]+lag)\n",
    "    df = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range=lag_train_range, ignored_trials=~active_mask, allow_overlap=True)\n",
    "    latents = np.array(df[data_field]).reshape(n_trials, n_timepoints, -1)\n",
    "    X = X = latents \n",
    "    skf = StratifiedKFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "    true_concat = nans([n_trials*n_timepoints,predictions.shape[-1]])\n",
    "    pred_concat = nans([n_trials*n_timepoints,predictions.shape[-1]])\n",
    "    trial_save_idx = 0\n",
    "    for training_set, test_set in skf.split(range(0,n_trials),cond_dict):\n",
    "        #split training and testing by trials\n",
    "        X_train, X_test, y_train, y_test = process_train_test(X,Y,training_set,test_set)\n",
    "        # lr = LinearRegression().fit(X_train, y_train)\n",
    "        # y_test_predicted = lr.predict(X_test)\n",
    "        dnn = DenseNNDecoder(units=400,dropout=0.25,num_epochs=10)\n",
    "        dnn.fit(X_train, y_train)\n",
    "        y_test_predicted = dnn.predict(X_test)\n",
    "\n",
    "        n = y_test_predicted.shape[0]\n",
    "        true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "        pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "        trial_save_idx += n\n",
    "        \n",
    "    sses =get_sses_pred(true_concat,pred_concat)\n",
    "    sses_mean=get_sses_mean(true_concat)\n",
    "    R2 =1-np.sum(sses)/np.sum(sses_mean)  \n",
    "    regressed_r2_array[i] = R2\n",
    "    print(R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lag_axis,regressed_r2_array)\n",
    "plt.ylabel('R2')\n",
    "plt.xlabel('Latent lag relative to prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "best_lag = lag_axis[np.argmax(regressed_r2_array)]\n",
    "lag_train_range = (train_range[0]+best_lag, train_range[1]+best_lag)\n",
    "df = dataset_10ms.make_trial_data(align_field='move_onset_time', align_range=lag_train_range, ignored_trials=~active_mask, allow_overlap=True)\n",
    "X = np.array(df[data_field])\n",
    "Y = np.array(act_all_vel_df.pred_vel)\n",
    "lr = LinearRegression().fit(X, Y)\n",
    "pred = lr.predict(X)\n",
    "act_all_vel_df = pd.concat([act_all_vel_df, pd.DataFrame(pred, columns=dataset._make_midx('regr_vel_dnn_CDFB', ['x', 'y'], 2))], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = act_all_vel_df\n",
    "# Prepare for plotting\n",
    "plot_dir = [0.0, 90.0, 180.0, 270.0] # limit plot directions to reduce cluttering\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "plot_dim = 'x' # plot x velocity \n",
    "\n",
    "x_axis = np.arange(-100,1000,dataset.bin_width)\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset.trial_info[dataset.trial_info.cond_dir %360 == trial_dir].trial_id\n",
    "    for _, trial in df[np.isin(df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        plt.plot(x_axis, trial[y_field][plot_dim], color=color, linewidth=0.5)\n",
    "        # plt.plot(x_axis, trial[y_field].to_numpy()[:,0], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time after movement onset (ms)')\n",
    "# plt.ylabel('Hand velocity (cm/s)')\n",
    "\n",
    "# plt.xlim([-100,500])\n",
    "# plt.ylim([-0.65,0.65])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + label + 'true.pdf', dpi = 'figure')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset.trial_info[dataset.trial_info.cond_dir %360 == trial_dir].trial_id\n",
    "    for _, trial in df[np.isin(df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "         plt.plot(x_axis, trial['pred_vel'][plot_dim], color=color, linewidth=0.5)\n",
    "        # plt.plot(x_axis, trial.pred_vel.to_numpy()[:,0], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time after movement onset (ms)')\n",
    "# plt.ylabel('Hand velocity (cm/s)')\n",
    "# plt.xlim([-100,500])\n",
    "# plt.ylim([-0.65,0.65])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + label + str(0) +'_pred.pdf', dpi = 'figure')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset.trial_info[dataset.trial_info.cond_dir %360 == trial_dir].trial_id\n",
    "    for _, trial in df[np.isin(df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "         plt.plot(x_axis, trial['regr_vel_dnn_CDFB'][plot_dim], color=color, linewidth=0.5)\n",
    "        # plt.plot(x_axis, trial.pred_vel.to_numpy()[:,0], color=color, linewidth=0.5)\n",
    "plt.xlabel('Time after movement onset (ms)')\n",
    "# plt.ylabel('Hand velocity (cm/s)')\n",
    "# plt.xlim([-100,500])\n",
    "# plt.ylim([-0.65,0.65])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + label + str(0) +'_pred.pdf', dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_field ='hand_vel'\n",
    "lag_axis = np.arange(-300,300,20)\n",
    "pred_range = (0, 120)\n",
    "trial_mask = active_mask\n",
    "cond_dict = active_cond_dict\n",
    "\n",
    "# Note it differs for x- and y-dir\n",
    "cd_lag = -60\n",
    "fb_lag = 40\n",
    "cdfb_lag = 60\n",
    "\n",
    "_, active_cd_coef,active_cd_intercept, cd_vel_df, _ = fit_and_predict(dataset, trial_mask, 'move_onset_time',pred_range, cd_lag, 'CD_proj', y_field, cond_dict = cond_dict)\n",
    "_, active_fb_coef,active_fb_intercept, fb_vel_df, _ = fit_and_predict(dataset, trial_mask, 'move_onset_time',pred_range, fb_lag, 'FB_proj', y_field, cond_dict = cond_dict)\n",
    "_, active_cdfb_coef,active_cdfb_intercept, cdfb_vel_df, _ = fit_and_predict(dataset, trial_mask, 'move_onset_time',pred_range, cdfb_lag, 'CD_FB_proj', y_field, cond_dict = cond_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pas_cd_r2_array = nans([len(lag_axis)]); pas_cd_x_r2_array = nans([len(lag_axis)]); pas_cd_y_r2_array = nans([len(lag_axis)])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    r2, _, x_r2,y_r2,_ = pred_with_new_weights(dataset, passive_mask, 'move_onset_time',(-100,120), lag,'CD_proj',\n",
    "                                                    y_field, active_cd_coef, active_cd_intercept, 'move_onset_time',pred_range, (pred_range[0]+cd_lag, pred_range[1]+cd_lag), active_mask)\n",
    "    # r2, _, x_r2,y_r2,_ = pred_with_new_weights(dataset, nan_mask, 'bump_time',(0,120), lag,'CD_proj',\n",
    "    #                                             y_field, active_cd_coef, active_cd_intercept, 'move_onset_time',pred_range, (pred_range[0]+cd_lag, pred_range[1]+cd_lag), active_mask)\n",
    "    pas_cd_r2_array[i] = r2; pas_cd_x_r2_array[i] = x_r2; pas_cd_y_r2_array[i] = y_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pas_fb_r2_array = nans([len(lag_axis)]); pas_fb_x_r2_array = nans([len(lag_axis)]); pas_fb_y_r2_array = nans([len(lag_axis)])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    r2, _, x_r2,y_r2,_ = pred_with_new_weights(dataset, passive_mask, 'move_onset_time',(-100,120), lag,'FB_proj',\n",
    "                                                    y_field, active_fb_coef, active_fb_intercept, 'move_onset_time',pred_range, (pred_range[0]+fb_lag, pred_range[1]+fb_lag), active_mask)\n",
    "    # r2, _, x_r2,y_r2,_ = pred_with_new_weights(dataset, nan_mask, 'bump_time',(0,120), lag,'FB_proj',\n",
    "    #                                            y_field, active_fb_coef, active_fb_intercept, 'move_onset_time',pred_range, (pred_range[0]+fb_lag, pred_range[1]+fb_lag), active_mask)\n",
    "    pas_fb_r2_array[i] = r2; pas_fb_x_r2_array[i] = x_r2; pas_fb_y_r2_array[i] = y_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pas_cdfb_r2_array = nans([len(lag_axis)]); pas_cdfb_x_r2_array = nans([len(lag_axis)]); pas_cdfb_y_r2_array = nans([len(lag_axis)])\n",
    "for i in range(len(lag_axis)):\n",
    "    lag = lag_axis[i]\n",
    "    r2, _, x_r2,y_r2,_ = pred_with_new_weights(dataset, passive_mask, 'move_onset_time',(-100,120), lag,'CD_FB_proj',\n",
    "                                                    y_field, active_cdfb_coef, active_cdfb_intercept, 'move_onset_time',pred_range, (pred_range[0]+cdfb_lag, pred_range[1]+cdfb_lag), active_mask)\n",
    "    # r2, _, x_r2,y_r2,_ = pred_with_new_weights(dataset, nan_mask, 'bump_time',(0,120), lag,'CD_FB_proj',\n",
    "    #                                        y_field, active_cdfb_coef, active_cdfb_intercept, 'move_onset_time',pred_range, (pred_range[0]+cdfb_lag, pred_range[1]+cdfb_lag), active_mask)\n",
    "    pas_cdfb_r2_array[i] = r2; pas_cdfb_x_r2_array[i] = x_r2; pas_cdfb_y_r2_array[i] = y_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez(monkey+'_hand_vel_bestx_act120_pas120_r2s_cross', \\\n",
    "#          pas_cd_r2_array = pas_cd_r2_array, pas_cd_x_r2_array = pas_cd_x_r2_array, pas_cd_y_r2_array = pas_cd_y_r2_array, \\\n",
    "#          pas_fb_r2_array = pas_fb_r2_array, pas_fb_x_r2_array = pas_fb_x_r2_array, pas_fb_y_r2_array = pas_fb_y_r2_array, \\\n",
    "#          pas_cdfb_r2_array = pas_cdfb_r2_array, pas_cdfb_x_r2_array = pas_cdfb_x_r2_array, pas_cdfb_y_r2_array = pas_cdfb_y_r2_array)\n",
    "\n",
    "# data = np.load(monkey+'_hand_vel_bestx_act120_pas120_r2s_cross.npz')\n",
    "# data.files\n",
    "\n",
    "np.savez(monkey+'_hand_vel_besty_act120_pas120_r2s_cross', \\\n",
    "         pas_cd_r2_array = pas_cd_r2_array, pas_cd_x_r2_array = pas_cd_x_r2_array, pas_cd_y_r2_array = pas_cd_y_r2_array, \\\n",
    "         pas_fb_r2_array = pas_fb_r2_array, pas_fb_x_r2_array = pas_fb_x_r2_array, pas_fb_y_r2_array = pas_fb_y_r2_array, \\\n",
    "         pas_cdfb_r2_array = pas_cdfb_r2_array, pas_cdfb_x_r2_array = pas_cdfb_x_r2_array, pas_cdfb_y_r2_array = pas_cdfb_y_r2_array)\n",
    "\n",
    "\n",
    "data = np.load(monkey+'_hand_vel_besty_act120_pas120_r2s_cross.npz')\n",
    "data.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_axis = np.arange(-300,300,20)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.plot(lag_axis, data['pas_cd_x_r2_array'],color = 'green',label='cd')\n",
    "plt.plot(lag_axis, data['pas_fb_x_r2_array'],color = 'magenta',label='fb')\n",
    "plt.plot(lag_axis, data['pas_cdfb_x_r2_array'],color = 'brown',label='cd+fb')\n",
    "plt.axvline(0, color = 'k', linestyle='--')\n",
    "# print(time_max)\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.title(x_field)\n",
    "plt.ylim([-0.7,0.7])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey +'_pas_vel_x_cross.pdf', dpi = 'figure')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.plot(lag_axis, data['pas_cd_y_r2_array'],color = 'green',label='cd')\n",
    "plt.plot(lag_axis, data['pas_fb_y_r2_array'],color = 'magenta',label='fb')\n",
    "plt.plot(lag_axis, data['pas_cdfb_y_r2_array'],color = 'brown',label='cd+fb')\n",
    "plt.axvline(0, color = 'k', linestyle='--')\n",
    "# print(time_max)\n",
    "plt.xlabel('Time lag (ms)')\n",
    "plt.ylabel('R2')\n",
    "plt.title(x_field)\n",
    "plt.ylim([-0.7,0.7])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey +'_pas_vel_y_cross.pdf', dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-decoding\n",
    "\n",
    "dataset = dataset_10ms\n",
    "# all_mask = dataset.trial_info.split != 'none'\n",
    "\n",
    "\n",
    "negative_lag = -100\n",
    "positive_lag = 60\n",
    "both_lag = 0\n",
    "\n",
    "y_field ='hand_vel'\n",
    "train_range = (-100,1000)\n",
    "train_pos_lag_range = (train_range[0]+positive_lag, train_range[1]+positive_lag)\n",
    "train_neg_lag_range = (train_range[0]+negative_lag, train_range[1]+negative_lag)\n",
    "train_mask = active_mask\n",
    "# train_mask = passive_mask\n",
    "_, aff_weights, aff_offset, act_aff_vel_df,_ = fit_and_predict(dataset, train_mask, 'move_onset_time', train_range, positive_lag, 'ac150_FB_proj_spikes_smth_150_oneside', y_field)\n",
    "_, eff_weights, eff_offset, act_eff_vel_df,_ = fit_and_predict(dataset, train_mask, 'move_onset_time', train_range, negative_lag,'ac150_CD_proj_spikes_smth_150_oneside',y_field)\n",
    "_, both_weights, both_offset, act_both_vel_df,_ = fit_and_predict(dataset, train_mask, 'move_onset_time', train_range, both_lag,'ac150_CD_FB_proj_spikes_smth_150_oneside',y_field)\n",
    "\n",
    "#pred active\n",
    "pred_range = (-100,1000)\n",
    "active_x_axis = np.arange(pred_range[0], pred_range[1], dataset.bin_width)\n",
    "_, _, _,_,act_aff_vel_df = pred_with_new_weights(dataset, active_mask, 'move_onset_time',pred_range, positive_lag,'ac150_FB_proj_spikes_smth_150_oneside',\n",
    "                                                 y_field, aff_weights, aff_offset, 'move_onset_time',train_range, train_pos_lag_range, train_mask)\n",
    "_, _, _,_,act_eff_vel_df = pred_with_new_weights(dataset, active_mask, 'move_onset_time',pred_range, negative_lag,'ac150_CD_proj_spikes_smth_150_oneside',\n",
    "                                                 y_field, eff_weights, eff_offset, 'move_onset_time',train_range, train_neg_lag_range, train_mask)\n",
    "_, _, _,_,act_both_vel_df = pred_with_new_weights(dataset, active_mask, 'move_onset_time',pred_range, both_lag,'ac150_CD_FB_proj_spikes_smth_150_oneside',\n",
    "                                                 y_field, both_weights, both_offset, 'move_onset_time',train_range, train_neg_lag_range, train_mask)\n",
    "#pred passive\n",
    "pred_range = (-100, 500)\n",
    "passive_x_axis = np.arange(pred_range[0], pred_range[1], dataset.bin_width)\n",
    "_, _, _,_,pas_aff_vel_df = pred_with_new_weights(dataset, passive_mask, 'move_onset_time',pred_range, positive_lag,'ac150_FB_proj_spikes_smth_150_oneside',\n",
    "                                                 y_field, aff_weights, aff_offset, 'move_onset_time',train_range, train_pos_lag_range, train_mask)\n",
    "_, _, _,_,pas_eff_vel_df = pred_with_new_weights(dataset, passive_mask, 'move_onset_time',pred_range, negative_lag,'ac150_CD_proj_spikes_smth_150_oneside',\n",
    "                                                 y_field, eff_weights, eff_offset, 'move_onset_time',train_range, train_neg_lag_range, train_mask)\n",
    "_, _, _,_,pas_both_vel_df = pred_with_new_weights(dataset, passive_mask, 'move_onset_time',pred_range, both_lag,'ac150_CD_FB_proj_spikes_smth_150_oneside',\n",
    "                                                 y_field, both_weights, both_offset, 'move_onset_time',train_range, train_neg_lag_range, train_mask)\n",
    "\n",
    "# #pred nan\n",
    "# pred_range = (-100, 1000)\n",
    "# passive_x_axis = np.arange(pred_range[0], pred_range[1], dataset.bin_width)\n",
    "# _, _, _,_,pas_aff_vel_df = pred_with_new_weights(dataset, nan_mask, 'move_onset_time',pred_range, positive_lag,'FB_proj',\n",
    "#                                                  y_field, aff_weights, aff_offset, 'move_onset_time',train_range, train_pos_lag_range, train_mask)\n",
    "# _, _, _,_,pas_eff_vel_df = pred_with_new_weights(dataset, nan_mask, 'move_onset_time',pred_range, negative_lag,'CD_proj',\n",
    "#                                                  y_field, eff_weights, eff_offset, 'move_onset_time',train_range, train_neg_lag_range, train_mask)\n",
    "# _, _, _,_,pas_both_vel_df = pred_with_new_weights(dataset, nan_mask, 'move_onset_time',pred_range, both_lag,'CD_FB_proj',\n",
    "#                                                  y_field, both_weights, both_offset, 'move_onset_time',train_range, train_neg_lag_range, train_mask)\n",
    "\n",
    "plot_dir = [0.0, 180.0] # limit plot directions to reduce cluttering\n",
    "colors = ['gray','gray']\n",
    "plot_dim = 'x'\n",
    "fig, axs = plt.subplots(6, 4, sharex=False, sharey=True, figsize=(18, 18))\n",
    "# plt.ylim(-50,50)\n",
    "i = 0\n",
    "alpha = 0.5\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset.trial_info[dataset.trial_info.cond_dir%360 == trial_dir].trial_id\n",
    "    for _, trial in act_eff_vel_df[np.isin(act_eff_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[0][i].plot(active_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[0][i].plot(active_x_axis, trial.pred_vel[plot_dim], color='green', alpha = alpha, linewidth=0.5)\n",
    "        axs[0][i].axvline(x=300, ls='--')\n",
    "    for _, trial in act_aff_vel_df[np.isin(act_aff_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[1][i].plot(active_x_axis, trial.pred_vel[plot_dim], color='magenta', alpha = alpha, linewidth=0.5)\n",
    "        axs[1][i].plot(active_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[1][i].axvline(x=300, ls='--')\n",
    "    for _, trial in act_both_vel_df[np.isin(act_both_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[2][i].plot(active_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[2][i].plot(active_x_axis, trial.pred_vel[plot_dim], color='brown', alpha = alpha, linewidth=0.5)    \n",
    "        axs[2][i].spines[['right', 'top']].set_visible(False) \n",
    "        axs[2][i].axvline(x=300, ls='--')\n",
    "    # cond_ids = dataset.trial_info[dataset.trial_info.bump_dir%360 == trial_dir].trial_id\n",
    "    for _, trial in pas_eff_vel_df[np.isin(pas_eff_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[3][i].plot(passive_x_axis, trial.pred_vel[plot_dim], color='green', alpha = alpha, linewidth=0.5)\n",
    "        axs[3][i].plot(passive_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[3][i].axvline(x=120, ls='--')\n",
    "    for _, trial in pas_aff_vel_df[np.isin(pas_aff_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[4][i].plot(passive_x_axis, trial.pred_vel[plot_dim], color='magenta', alpha = alpha, linewidth=0.5)\n",
    "        axs[4][i].plot(passive_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[4][i].axvline(x=120, ls='--')\n",
    "    for _, trial in pas_both_vel_df[np.isin(pas_both_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[5][i].plot(passive_x_axis, trial.pred_vel[plot_dim], color='brown', alpha = alpha, linewidth=0.5)\n",
    "        axs[5][i].plot(passive_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[5][i].spines[['right', 'top']].set_visible(False)\n",
    "        axs[5][i].axvline(x=120, ls='--')\n",
    "    i+=2\n",
    "\n",
    "\n",
    "negative_lag = -100\n",
    "positive_lag = 120\n",
    "both_lag = 0\n",
    "\n",
    "y_field ='hand_vel'\n",
    "train_range = (-100,1000)\n",
    "train_pos_lag_range = (train_range[0]+positive_lag, train_range[1]+positive_lag)\n",
    "train_neg_lag_range = (train_range[0]+negative_lag, train_range[1]+negative_lag)\n",
    "train_mask = active_mask\n",
    "# train_mask = passive_mask\n",
    "\n",
    "_, aff_weights, aff_offset, act_aff_vel_df,_ = fit_and_predict(dataset, train_mask, 'move_onset_time', train_range, positive_lag, 'ac150_FB_proj_spikes_smth_150_oneside', y_field)\n",
    "_, eff_weights, eff_offset, act_eff_vel_df,_ = fit_and_predict(dataset, train_mask, 'move_onset_time', train_range, negative_lag,'ac150_CD_proj_spikes_smth_150_oneside',y_field)\n",
    "_, both_weights, both_offset, act_both_vel_df,_ = fit_and_predict(dataset, train_mask, 'move_onset_time', train_range, both_lag,'ac150_CD_FB_proj_spikes_smth_150_oneside',y_field)\n",
    "\n",
    "#pred active\n",
    "pred_range = (-100, 1000)\n",
    "active_x_axis = np.arange(pred_range[0], pred_range[1], dataset.bin_width)\n",
    "_, _, _,_,act_aff_vel_df = pred_with_new_weights(dataset, active_mask, 'move_onset_time',pred_range, positive_lag,'ac150_FB_proj_spikes_smth_150_oneside',\n",
    "                                                 y_field, aff_weights, aff_offset, 'move_onset_time',train_range, train_pos_lag_range, train_mask)\n",
    "_, _, _,_,act_eff_vel_df = pred_with_new_weights(dataset, active_mask, 'move_onset_time',pred_range, negative_lag,'ac150_CD_proj_spikes_smth_150_oneside',\n",
    "                                                 y_field, eff_weights, eff_offset, 'move_onset_time',train_range, train_neg_lag_range, train_mask)\n",
    "_, _, _,_,act_both_vel_df = pred_with_new_weights(dataset, active_mask, 'move_onset_time',pred_range, both_lag,'ac150_CD_FB_proj_spikes_smth_150_oneside',\n",
    "                                                 y_field, both_weights, both_offset, 'move_onset_time',train_range, train_neg_lag_range, train_mask)\n",
    "#pred passive\n",
    "pred_range = (-100, 500)\n",
    "passive_x_axis = np.arange(pred_range[0], pred_range[1], dataset.bin_width)\n",
    "_, _, _,_,pas_aff_vel_df = pred_with_new_weights(dataset, passive_mask, 'move_onset_time',pred_range, positive_lag,'ac150_FB_proj_spikes_smth_150_oneside',\n",
    "                                                 y_field, aff_weights, aff_offset, 'move_onset_time',train_range, train_pos_lag_range, train_mask)\n",
    "_, _, _,_,pas_eff_vel_df = pred_with_new_weights(dataset, passive_mask, 'move_onset_time',pred_range, negative_lag,'ac150_CD_proj_spikes_smth_150_oneside',\n",
    "                                                 y_field, eff_weights, eff_offset, 'move_onset_time',train_range, train_neg_lag_range, train_mask)\n",
    "_, _, _,_,pas_both_vel_df = pred_with_new_weights(dataset, passive_mask, 'move_onset_time',pred_range, both_lag,'ac150_CD_FB_proj_spikes_smth_150_oneside',\n",
    "                                                 y_field, both_weights, both_offset, 'move_onset_time',train_range, train_neg_lag_range, train_mask)\n",
    "\n",
    "#pred nan\n",
    "# pred_range = (-100, 1000)\n",
    "# passive_x_axis = np.arange(pred_range[0], pred_range[1], dataset.bin_width)\n",
    "# _, _, _,_,pas_aff_vel_df = pred_with_new_weights(dataset, nan_mask, 'move_onset_time',pred_range, positive_lag,'FB_proj',\n",
    "#                                                  y_field, aff_weights, aff_offset, 'move_onset_time',train_range, train_pos_lag_range, train_mask)\n",
    "# _, _, _,_,pas_eff_vel_df = pred_with_new_weights(dataset, nan_mask, 'move_onset_time',pred_range, negative_lag,'CD_proj',\n",
    "#                                                  y_field, eff_weights, eff_offset, 'move_onset_time',train_range, train_neg_lag_range, train_mask)\n",
    "# _, _, _,_,pas_both_vel_df = pred_with_new_weights(dataset, nan_mask, 'move_onset_time',pred_range,both_lag,'CD_FB_proj',\n",
    "#                                                  y_field, both_weights, both_offset, 'move_onset_time',train_range, train_neg_lag_range, train_mask)\n",
    "\n",
    "\n",
    "plot_dir = [90.0, 270.0] # limit plot directions to reduce cluttering\n",
    "colors = ['gray', 'gray']\n",
    "plot_dim = 'y'\n",
    "i = 1\n",
    "alpha = 0.5\n",
    "for trial_dir, color in zip(plot_dir, colors):\n",
    "    cond_ids = dataset.trial_info[dataset.trial_info.cond_dir%360 == trial_dir].trial_id\n",
    "    for _, trial in act_eff_vel_df[np.isin(act_eff_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[0][i].plot(active_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[0][i].plot(active_x_axis, trial.pred_vel[plot_dim], color='green', alpha = alpha, linewidth=0.5)\n",
    "        axs[0][i].axvline(x=300, ls='--')\n",
    "    for _, trial in act_aff_vel_df[np.isin(act_aff_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[1][i].plot(active_x_axis, trial.pred_vel[plot_dim], color='magenta', alpha = alpha, linewidth=0.5)\n",
    "        axs[1][i].plot(active_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[1][i].axvline(x=300, ls='--')\n",
    "    for _, trial in act_both_vel_df[np.isin(act_both_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[2][i].plot(active_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[2][i].plot(active_x_axis, trial.pred_vel[plot_dim], color='brown', alpha = alpha, linewidth=0.5)    \n",
    "        axs[2][i].spines[['right', 'top']].set_visible(False) \n",
    "        axs[2][i].axvline(x=300, ls='--')\n",
    "    # cond_ids = dataset.trial_info[dataset.trial_info.bump_dir%360 == trial_dir].trial_id\n",
    "    for _, trial in pas_eff_vel_df[np.isin(pas_eff_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[3][i].plot(passive_x_axis, trial.pred_vel[plot_dim], color='green', alpha = alpha, linewidth=0.5)\n",
    "        axs[3][i].plot(passive_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[3][i].axvline(x=120, ls='--')\n",
    "    for _, trial in pas_aff_vel_df[np.isin(pas_aff_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[4][i].plot(passive_x_axis, trial.pred_vel[plot_dim], color='magenta', alpha = alpha, linewidth=0.5)\n",
    "        axs[4][i].plot(passive_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[4][i].axvline(x=120, ls='--')\n",
    "    for _, trial in pas_both_vel_df[np.isin(pas_both_vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "        axs[5][i].plot(passive_x_axis, trial.pred_vel[plot_dim], color='brown', alpha = alpha, linewidth=0.5)\n",
    "        axs[5][i].plot(passive_x_axis, trial[y_field][plot_dim], color=color, alpha = alpha, linewidth=0.5)\n",
    "        axs[5][i].spines[['right', 'top']].set_visible(False)\n",
    "        axs[5][i].axvline(x=120, ls='--')\n",
    "    i+=2\n",
    "\n",
    "fig.supxlabel('Time after movement onset (ms)')\n",
    "# axs[0][0].set_ylabel('Prediction',fontsize=14)\n",
    "# axs[1][0].set_ylabel('Prediction',fontsize=14)\n",
    "# axs[0][0].set_ylabel('Hand acceleration \\n (cm/s^2)',fontsize=14)\n",
    "# axs[1][0].set_ylabel('Hand acceleration \\n (cm/s^2)',fontsize=14)\n",
    "axs[0][0].set_ylabel('Hand velocity \\n (cm/s)',fontsize=14)\n",
    "axs[1][0].set_ylabel('Hand velocity \\n (cm/s)',fontsize=14)\n",
    "\n",
    "\n",
    "axs[0][0].set_title('0 deg')\n",
    "axs[0][1].set_title('90 deg')\n",
    "axs[0][2].set_title('180 deg')\n",
    "axs[0][3].set_title('270 deg')\n",
    "\n",
    "\n",
    "# legend_elements = [Patch(facecolor='magenta', label='Afferent prediction'),\n",
    "#                     Patch(facecolor='k', label='Efferent prediction')]\n",
    "# legend_elements = [Patch(facecolor='magenta', label='Afferent prediction')]\n",
    "# plt.legend(handles=legend_elements)\n",
    "plt.tight_layout()\n",
    "# figDir = '/Users/sherryan/area2_population_analysis/'\n",
    "# plt.savefig(figDir + monkey + '_cross_vel_both_early_aligned.pdf', dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PC proj_back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(monkey+'_CDFB_weights_'+'PCA_40'+'.npz')\n",
    "X = data['CD_axes']\n",
    "eff_weights = pca.inverse_transform(X)\n",
    "print(eff_weights.shape)\n",
    "X = data['FB_axes']\n",
    "aff_weights = pca.inverse_transform(X)\n",
    "print(aff_weights.shape)\n",
    "np.savez(monkey+'_CDFB_weights_pc_proj_back', CD_axes = eff_weights, FB_axes = aff_weights) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff_weights_mean = np.mean(abs(aff_weights),axis=0)\n",
    "print(aff_weights_mean.shape)\n",
    "plt.hist(aff_weights_mean)\n",
    "plt.show()\n",
    "eff_weights_mean = np.mean(abs(eff_weights),axis=0)\n",
    "print(eff_weights_mean.shape)\n",
    "plt.hist(eff_weights_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neuron weights plot\n",
    "\n",
    "def adjacent_values(vals, q1, q3):\n",
    "    upper_adjacent_value = q3 + (q3 - q1) * 1.5\n",
    "    upper_adjacent_value = np.clip(upper_adjacent_value, q3, vals[-1])\n",
    "    lower_adjacent_value = q1 - (q3 - q1) * 1.5\n",
    "    lower_adjacent_value = np.clip(lower_adjacent_value, vals[0], q1)\n",
    "    return lower_adjacent_value, upper_adjacent_value\n",
    "    \n",
    "plt.hist(aff_weights_mean)\n",
    "plt.show()\n",
    "plt.hist(eff_weights_mean)\n",
    "plt.show()\n",
    "\n",
    "Ki_x = []\n",
    "for i in range(n_neurons):\n",
    "    Wa = aff_weights_mean[i]\n",
    "    We = eff_weights_mean[i]\n",
    "    if abs(Wa) > 0.02 or abs(We) > 0.02:\n",
    "        Ki_x.append((abs(Wa) - abs(We)) / (abs(Wa)+abs(We)))\n",
    "    else:\n",
    "        Ki_x.append(np.nan)\n",
    "print(len(Ki_x))\n",
    "\n",
    "Ki_x = np.array(Ki_x)\n",
    "Ki_x_plot = Ki_x[~np.isnan(Ki_x)]\n",
    "print(len(Ki_x_plot))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "# fig.suptitle('Relative contribution to acc decoder between Afference and Efference')\n",
    "import seaborn as sns\n",
    "parts = ax.violinplot(Ki_x_plot,showmeans = False, showextrema=False)\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_facecolor('grey')\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_alpha(.5)\n",
    "\n",
    "\n",
    "quartile1, medians, quartile3 = np.percentile(Ki_x_plot, [25, 50, 75])\n",
    "whiskers = adjacent_values(sorted(Ki_x_plot), quartile1, quartile3)\n",
    "whiskers_min, whiskers_max = whiskers[0], whiskers[1]\n",
    "ax.scatter(1, medians, marker='o', color='white', s=20, zorder=3)\n",
    "ax.vlines(1, quartile1, quartile3, color='k', linestyle='-', lw=5)\n",
    "ax.vlines(1, whiskers_min, whiskers_max, color='k', linestyle='-', lw=1)\n",
    "\n",
    "ax.set_ylabel('Relative contribution')\n",
    "ax.set_xticks([])\n",
    "# ax.set_xlabel('All neurons')\n",
    "ax.set_ylim([-1,1])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_contrib_violin_vel.pdf', dpi = 'figure')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.hist(sorted(Ki_x_plot),10,rwidth=0.8,color = 'grey')\n",
    "plt.xlabel('Relative contribution')\n",
    "plt.ylabel('Neuron count')\n",
    "plt.xlim([-1.01,1.01])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_contrib_bar_vel.pdf', dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.argwhere(np.isnan(np.array(Ki_x))).squeeze()\n",
    "# np.argsort(np.array(Ki_x))\n",
    "valid_sort = np.array([x for x in np.argsort(np.array(Ki_x)) if x not in np.argwhere(np.isnan(np.array(Ki_x))).squeeze()])\n",
    "valid_sort\n",
    "\n",
    "#To pick exammple single neuron \n",
    "# np.array(Ki_x)[47]\n",
    "\n",
    "np.savez(monkey+'_cdfb_contrib'+'_pc_proj', relative_contrib = np.array(Ki_x), valid_sort=valid_sort)\n",
    "data = np.load(monkey+'_cdfb_contrib_pc_proj.npz')\n",
    "data.files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monkey = 'Duncan_20190710'\n",
    "# monkey = 'Han_20171207'\n",
    "data = np.load(monkey+'_8020_cdfb_weights_'+'spikes_smth_40'+'.npz')\n",
    "eff_weights = data['CD_axes']\n",
    "print(eff_weights.shape)\n",
    "aff_weights = data['FB_axes']\n",
    "print(aff_weights.shape)\n",
    "\n",
    "n_neurons = dataset_10ms.data.spikes.shape[1]\n",
    "print(n_neurons,'neurons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff_weights_mean = np.mean(abs(aff_weights),axis=0)\n",
    "print(aff_weights_mean.shape)\n",
    "plt.hist(aff_weights_mean)\n",
    "plt.show()\n",
    "eff_weights_mean = np.mean(abs(eff_weights),axis=0)\n",
    "print(eff_weights_mean.shape)\n",
    "plt.hist(eff_weights_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neuron weights plot\n",
    "\n",
    "def adjacent_values(vals, q1, q3):\n",
    "    upper_adjacent_value = q3 + (q3 - q1) * 1.5\n",
    "    upper_adjacent_value = np.clip(upper_adjacent_value, q3, vals[-1])\n",
    "    lower_adjacent_value = q1 - (q3 - q1) * 1.5\n",
    "    lower_adjacent_value = np.clip(lower_adjacent_value, vals[0], q1)\n",
    "    return lower_adjacent_value, upper_adjacent_value\n",
    "    \n",
    "plt.hist(aff_weights_mean)\n",
    "plt.show()\n",
    "plt.hist(eff_weights_mean)\n",
    "plt.show()\n",
    "\n",
    "Ki_x = []\n",
    "for i in range(n_neurons):\n",
    "    Wa = aff_weights_mean[i]\n",
    "    We = eff_weights_mean[i]\n",
    "    if abs(Wa) > 0.1 or abs(We) > 0.1:\n",
    "        Ki_x.append((abs(Wa) - abs(We)) / (abs(Wa)+abs(We)))\n",
    "    else:\n",
    "        Ki_x.append(np.nan)\n",
    "print(len(Ki_x))\n",
    "\n",
    "Ki_x = np.array(Ki_x)\n",
    "Ki_x_plot = Ki_x[~np.isnan(Ki_x)]\n",
    "print(len(Ki_x_plot))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "# fig.suptitle('Relative contribution to acc decoder between Afference and Efference')\n",
    "import seaborn as sns\n",
    "parts = ax.violinplot(Ki_x_plot,showmeans = False, showextrema=False)\n",
    "for pc in parts['bodies']:\n",
    "    pc.set_facecolor('grey')\n",
    "    pc.set_edgecolor('black')\n",
    "    pc.set_alpha(.5)\n",
    "\n",
    "\n",
    "quartile1, medians, quartile3 = np.percentile(Ki_x_plot, [25, 50, 75])\n",
    "whiskers = adjacent_values(sorted(Ki_x_plot), quartile1, quartile3)\n",
    "whiskers_min, whiskers_max = whiskers[0], whiskers[1]\n",
    "ax.scatter(1, medians, marker='o', color='white', s=20, zorder=3)\n",
    "ax.vlines(1, quartile1, quartile3, color='k', linestyle='-', lw=5)\n",
    "ax.vlines(1, whiskers_min, whiskers_max, color='k', linestyle='-', lw=1)\n",
    "\n",
    "ax.set_ylabel('Relative contribution')\n",
    "ax.set_xticks([])\n",
    "# ax.set_xlabel('All neurons')\n",
    "ax.set_ylim([-1,1])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_contrib_violin_vel.pdf', dpi = 'figure')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "plt.hist(sorted(Ki_x_plot),10,rwidth=0.8,color = 'grey')\n",
    "plt.xlabel('Relative contribution')\n",
    "plt.ylabel('Neuron count')\n",
    "plt.xlim([-1.01,1.01])\n",
    "plt.tight_layout()\n",
    "# plt.savefig(figDir + monkey + '_contrib_bar_vel.pdf', dpi = 'figure')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.argwhere(np.isnan(np.array(Ki_x))).squeeze()\n",
    "# np.argsort(np.array(Ki_x))\n",
    "valid_sort = np.array([x for x in np.argsort(np.array(Ki_x)) if x not in np.argwhere(np.isnan(np.array(Ki_x))).squeeze()])\n",
    "print(valid_sort)\n",
    "print(len(valid_sort),'neurons')\n",
    "\n",
    "#To pick exammple single neuron \n",
    "print(np.array(Ki_x)[47])\n",
    "print(np.array(Ki_x)[69])\n",
    "print(np.array(Ki_x)[89])\n",
    "print(np.array(Ki_x)[0])\n",
    "\n",
    "# np.savez(monkey+'_cdfb_contrib'+'_neuron', relative_contrib = np.array(Ki_x), valid_sort=valid_sort)\n",
    "# data = np.load(monkey+'_cdfb_contrib_neuron.npz')\n",
    "# data.files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdt_env",
   "language": "python",
   "name": "sdt_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
