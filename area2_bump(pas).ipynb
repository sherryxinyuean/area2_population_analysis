{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d2edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlb_tools.nwb_interface import NWBDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Import function to get the covariate matrix that includes spike history from previous bins\n",
    "from Neural_Decoding.preprocessing_funcs import get_spikes_with_history\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from Area2_analysis.funcs import process_train_test\n",
    "from Area2_analysis.funcs import get_sses_pred, get_sses_mean, nans, fit_and_predict\n",
    "from Area2_analysis.funcs import sub_and_predict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dca024",
   "metadata": {},
   "source": [
    "# Single Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc8cc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "foldername = \"~/area2_population_analysis/s1-kinematics/actpas_NWB/\"\n",
    "monkey = \"Chips_20170913\"\n",
    "filename = foldername + monkey + \"_COactpas_TD.nwb\"\n",
    "\n",
    "dataset_5ms = NWBDataset(filename, split_heldout=False)\n",
    "\n",
    "xy_vel = dataset_5ms.data['hand_vel'].to_numpy()\n",
    "xy_acc = np.diff(xy_vel, axis = 0, prepend=[xy_vel[0]])\n",
    "dataset_5ms.add_continuous_data(xy_acc,'hand_acc',chan_names = ['x','y'])\n",
    "\n",
    "dataset_5ms.resample(5)\n",
    "dataset_5ms.smooth_spk(40, name='smth_40')\n",
    "# dataset_5ms.smooth_spk(20, name='smth_20')\n",
    "bin_width = dataset_5ms.bin_width\n",
    "print(bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b3102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dims = 20 # for PCA\n",
    "\n",
    "passive_mask = (dataset_5ms.trial_info.ctr_hold_bump) & (dataset_5ms.trial_info.split != 'none')\n",
    "\n",
    "trial_mask = passive_mask\n",
    "n_trials = dataset_5ms.trial_info.loc[trial_mask].shape[0]\n",
    "print(n_trials,'trials')\n",
    "n_neurons = dataset_5ms.data.spikes.shape[1]\n",
    "print(n_neurons,'neurons')\n",
    "\n",
    "all_data = np.array(dataset_5ms.data.spikes_smth_40)\n",
    "print(all_data.shape)\n",
    "data_for_pca = all_data[~np.isnan(all_data).any(axis=1)]\n",
    "print(data_for_pca.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data_for_pca)\n",
    "pca = PCA(n_components=n_dims)\n",
    "X = pca.fit(X)\n",
    "\n",
    "PCA_data = nans([all_data.shape[0],n_dims])\n",
    "idx = 0\n",
    "for dp in all_data:\n",
    "    dp = dp.reshape((1, -1))\n",
    "    if np.isnan(dp).any():\n",
    "        dp_pca = nans([1,n_dims])\n",
    "    else:\n",
    "        dp_pca = pca.transform(scaler.transform(dp))\n",
    "    PCA_data[idx,:] = dp_pca\n",
    "    idx+=1\n",
    "print(PCA_data.shape)\n",
    "dataset_5ms.add_continuous_data(PCA_data,'PCA')\n",
    "print('PCA total var explained:',sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257bacfe",
   "metadata": {},
   "source": [
    "## with Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106dc233",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag_axis = np.arange(-300,300,20)\n",
    "x_field = 'spikes_smth_40'\n",
    "y_field ='hand_acc'\n",
    "trial_mask = passive_mask\n",
    "\n",
    "# Prepare for plotting\n",
    "plot_dir = [0.0, 90.0, 180.0, 270.0] # limit plot directions to reduce cluttering\n",
    "plot_dim = 'x' # plot x velocity\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/neurons/pas/\"\n",
    "dim = n_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b9c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [(0,120),(-100,120)]\n",
    "labels = ['_early_acc_','_long_acc_']\n",
    "\n",
    "for pred_range, label in zip(ranges, labels):\n",
    "    x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "    curr_r2_array = nans([len(lag_axis)])\n",
    "    curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "        curr_r2_array[i] = r2\n",
    "        curr_coef_array[i,:,:] = coef\n",
    "\n",
    "    idx_max = np.argmax(curr_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    _, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial[y_field][plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel(plot_dim + '_' + y_field)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + 'true.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel(plot_dim + '_' + y_field)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(lag_axis, curr_r2_array)\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.title('R2 score predicting ' + y_field + ' ' + str(pred_range))\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    weights = curr_coef_array[idx_max,:,:]\n",
    "    for iter in range(0,3):  \n",
    "        #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "        sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "        sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "        for i in range(len(lag_axis)):\n",
    "            lag = lag_axis[i]\n",
    "            r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "            sub_r2_array[i] = r2\n",
    "            sub_coef_array[i,:,:] = coef\n",
    "\n",
    "        plt.plot(lag_axis,sub_r2_array)\n",
    "        plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "        idx_max = np.argmax(sub_r2_array)\n",
    "        time_max = lag_axis[idx_max]\n",
    "        plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "        plt.legend()\n",
    "        plt.xlabel('Time lag (ms)')\n",
    "        plt.ylabel('R2')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "        plt.close()\n",
    "\n",
    "        _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "        for trial_dir, color in zip(plot_dir, colors):\n",
    "            cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "            for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "                plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "        plt.xlabel('Time (ms)')\n",
    "        plt.ylabel(plot_dim + '_' + y_field)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "        plt.close()\n",
    "        \n",
    "        #stack the decoding dimensions to be projected out\n",
    "        weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f030f4",
   "metadata": {},
   "source": [
    "## with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d6d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_field = 'PCA'\n",
    "y_field ='hand_acc'\n",
    "lag_axis = np.arange(-300,300,20)\n",
    "\n",
    "# Prepare for plotting\n",
    "plot_dir = [0.0, 90.0, 180.0, 270.0] # limit plot directions to reduce cluttering\n",
    "plot_dim = 'x' # plot x velocity\n",
    "colors = ['red', 'blue', 'green', 'orange']\n",
    "\n",
    "\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/PCA/pas/\"\n",
    "dim = n_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b2f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot PCs\n",
    "# plot_range = (-100, 120)\n",
    "# vel_df = dataset_5ms.make_trial_data(align_field='move_onset_time', align_range=plot_range, ignored_trials=~passive_mask)\n",
    "\n",
    "# x_axis = np.arange(plot_range[0], plot_range[1], dataset_5ms.bin_width)\n",
    "# plot_dims = 10\n",
    "# fig,ax=plt.subplots(plot_dims,1,figsize=(10,20))\n",
    "\n",
    "# for i in range(plot_dims):\n",
    "#     for _, trial in vel_df.groupby('trial_id'):\n",
    "#         ax[i].plot(x_axis,trial.PCA.to_numpy()[:,i], color = 'k',linewidth = 0.5)\n",
    "#         ax[i].axvline(0,color ='k',ls = '--')\n",
    "#         if i<plot_dims-1:\n",
    "#             ax[i].set_xticks([])\n",
    "#         else:\n",
    "#             ax[i].set_xlabel('Time (ms)')\n",
    "#         ax[i].set_ylabel('Dim. '+str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f37ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = [(0,120),(-100,120)]\n",
    "labels = ['_early_acc_','_long_acc_']\n",
    "\n",
    "for pred_range, label in zip(ranges, labels):\n",
    "    x_axis = np.arange(pred_range[0], pred_range[1], dataset_5ms.bin_width)\n",
    "    curr_r2_array = nans([len(lag_axis)])\n",
    "    curr_coef_array = nans([len(lag_axis),2,dim])\n",
    "    for i in range(len(lag_axis)):\n",
    "        lag = lag_axis[i]\n",
    "        r2, coef, _ = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag, x_field, y_field)\n",
    "        curr_r2_array[i] = r2\n",
    "        curr_coef_array[i,:,:] = coef\n",
    "\n",
    "    idx_max = np.argmax(curr_r2_array)\n",
    "    time_max = lag_axis[idx_max]\n",
    "    _, _, vel_df = fit_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field)\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial[y_field][plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel(plot_dim + '_' + y_field)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + 'true.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    for trial_dir, color in zip(plot_dir, colors):\n",
    "        cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "        for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "            plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (ms)')\n",
    "    plt.ylabel(plot_dim + '_' + y_field)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(0) +'_pred.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    plt.plot(lag_axis, curr_r2_array)\n",
    "    plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "    plt.legend()\n",
    "    plt.title('R2 score predicting ' + y_field + ' ' + str(pred_range))\n",
    "    plt.xlabel('Time lag (ms)')\n",
    "    plt.ylabel('R2')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + label + str(0) +'.png', dpi = 'figure')\n",
    "    plt.close()\n",
    "\n",
    "    weights = curr_coef_array[idx_max,:,:]\n",
    "    for iter in range(0,3):  \n",
    "        #subtract predictions with primary decoding dimensions (at time with max R2)\n",
    "        sub_coef_array = nans([len(lag_axis),2,dim])\n",
    "        sub_r2_array = nans([len(lag_axis)])\n",
    "\n",
    "        for i in range(len(lag_axis)):\n",
    "            lag = lag_axis[i]\n",
    "            r2, coef,_ = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, lag,x_field,y_field,weights)\n",
    "            sub_r2_array[i] = r2\n",
    "            sub_coef_array[i,:,:] = coef\n",
    "\n",
    "        plt.plot(lag_axis,sub_r2_array)\n",
    "        plt.title('R2 score projecting out #'+ str(iter+1) +' t_max dim')\n",
    "        idx_max = np.argmax(sub_r2_array)\n",
    "        time_max = lag_axis[idx_max]\n",
    "        plt.axvline(time_max, color = 'r', label='t_max = ' + str(time_max))\n",
    "        plt.legend()\n",
    "        plt.xlabel('Time lag (ms)')\n",
    "        plt.ylabel('R2')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figDir + monkey + label + str(iter+1) +'.png', dpi = 'figure')\n",
    "        plt.close()\n",
    "\n",
    "        _, _, vel_df = sub_and_predict(dataset_5ms, trial_mask, 'move_onset_time', pred_range, time_max, x_field, y_field,weights)\n",
    "        for trial_dir, color in zip(plot_dir, colors):\n",
    "            cond_ids = dataset_5ms.trial_info[dataset_5ms.trial_info.cond_dir == trial_dir].trial_id\n",
    "            for _, trial in vel_df[np.isin(vel_df.trial_id, cond_ids)].groupby('trial_id'):\n",
    "                plt.plot(x_axis, trial.pred_vel[plot_dim], color=color, linewidth=0.5)\n",
    "        plt.xlabel('Time (ms)')\n",
    "        plt.ylabel(plot_dim + '_' + y_field)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figDir + monkey + label + str(iter+1) +'_pred.png', dpi = 'figure')\n",
    "        plt.close()\n",
    "        \n",
    "        #stack the decoding dimensions to be projected out\n",
    "        weights = np.vstack((weights,sub_coef_array[idx_max,:,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e66b89",
   "metadata": {},
   "source": [
    "# Multi Lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8649848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_50ms = NWBDataset(filename, split_heldout=False)\n",
    "xy_vel = dataset_50ms.data['hand_vel'].to_numpy()\n",
    "xy_acc = np.diff(xy_vel, axis = 0, prepend=[xy_vel[0]])\n",
    "dataset_50ms.add_continuous_data(xy_acc,'hand_acc',chan_names = ['x','y'])\n",
    "\n",
    "dataset_50ms.resample(50)\n",
    "print(dataset_50ms.bin_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda3bfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dims = 20 # for PCA\n",
    "\n",
    "passive_mask = (dataset_50ms.trial_info.ctr_hold_bump) & (dataset_50ms.trial_info.split != 'none')\n",
    "\n",
    "trial_mask = passive_mask\n",
    "n_trials = dataset_50ms.trial_info.loc[trial_mask].shape[0]\n",
    "print(n_trials,'trials')\n",
    "n_neurons = dataset_50ms.data.spikes.shape[1]\n",
    "print(n_neurons,'neurons')\n",
    "\n",
    "all_data = np.array(dataset_50ms.data.spikes)\n",
    "print(all_data.shape)\n",
    "data_for_pca = all_data[~np.isnan(all_data).any(axis=1)]\n",
    "print(data_for_pca.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data_for_pca)\n",
    "pca = PCA(n_components=n_dims)\n",
    "X = pca.fit(X)\n",
    "\n",
    "PCA_data = nans([all_data.shape[0],n_dims])\n",
    "idx = 0\n",
    "for dp in all_data:\n",
    "    dp = dp.reshape((1, -1))\n",
    "    if np.isnan(dp).any():\n",
    "        dp_pca = nans([1,n_dims])\n",
    "    else:\n",
    "        dp_pca = pca.transform(scaler.transform(dp))\n",
    "    PCA_data[idx,:] = dp_pca\n",
    "    idx+=1\n",
    "print(PCA_data.shape)\n",
    "dataset_50ms.add_continuous_data(PCA_data,'PCA')\n",
    "print('PCA total var explained:',sum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a348315",
   "metadata": {},
   "outputs": [],
   "source": [
    "passive_data = dataset_50ms.make_trial_data(align_field='move_onset_time', align_range=(-400, 700), ignored_trials=~trial_mask)\n",
    "for idx, trial in passive_data.groupby('trial_id'):\n",
    "    n_timepoints = trial.shape[0]\n",
    "    break\n",
    "print(n_timepoints,'time bins')\n",
    "\n",
    "passive_trials_neuron = nans([n_trials,n_timepoints,n_neurons])\n",
    "passive_trials_vel = nans([n_trials,n_timepoints,2])\n",
    "passive_trials_acc = nans([n_trials,n_timepoints,2])\n",
    "passive_trials_pca = nans([n_trials,n_timepoints,n_dims])\n",
    "i = 0\n",
    "for idx, trial in passive_data.groupby('trial_id'):\n",
    "    passive_trials_neuron[i,:,:]=trial.spikes.to_numpy()\n",
    "    passive_trials_vel[i,:,:]=trial.hand_vel.to_numpy()\n",
    "    passive_trials_acc[i,:,:]=trial.hand_acc.to_numpy()\n",
    "    passive_trials_pca[i,:,:]=trial.PCA.to_numpy()\n",
    "    i+=1\n",
    "print(passive_trials_neuron.shape)\n",
    "print(passive_trials_vel.shape)\n",
    "print(passive_trials_acc.shape)\n",
    "print(passive_trials_pca.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef332cd6",
   "metadata": {},
   "source": [
    "## with Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5500a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_range = [-400,700]\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/neurons/pas/\"\n",
    "passive_x = passive_trials_neuron\n",
    "passive_y = passive_trials_acc\n",
    "y_type = 'acceleration'\n",
    "\n",
    "ranges = [(0,120),(-100,120)]\n",
    "labels = ['early_acc','long_acc']\n",
    "\n",
    "dim = n_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8378b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pred_range, label in zip(ranges, labels):\n",
    "\n",
    "    idx1 = int((pred_range[0] - data_range[0])/dataset_50ms.bin_width)\n",
    "    idx2 = int(n_timepoints - (data_range[1]-pred_range[1])/dataset_50ms.bin_width)\n",
    "\n",
    "    t_before_range = range(0,301,50);\n",
    "    t_after_range = range(0,501,50);\n",
    "\n",
    "    multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "    multi_coefs = []\n",
    "    j,k=0,0\n",
    "    for time_before in t_before_range:\n",
    "        coef_arr = []\n",
    "        for time_after in t_after_range:\n",
    "            print('Predicting with',-time_before, 'to', time_after,'ms neural data')\n",
    "\n",
    "            bins_before= int(time_before/dataset_50ms.bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "            bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "            bins_after= int(time_after/dataset_50ms.bin_width) #How many bins of neural data after the output are used for decoding\n",
    "\n",
    "            n_total_bins = bins_before + bins_current + bins_after\n",
    "\n",
    "            X =  nans([n_trials,idx2-idx1,n_total_bins*dim])\n",
    "            i = 0\n",
    "            for trial_data in passive_x:\n",
    "                trial_hist=get_spikes_with_history(trial_data,bins_before,bins_after,bins_current)\n",
    "                trial_hist = trial_hist[idx1:idx2,:,:]\n",
    "                trial_hist_flat=trial_hist.reshape(trial_hist.shape[0],(trial_hist.shape[1]*trial_hist.shape[2]))\n",
    "                X[i,:,:] = trial_hist_flat\n",
    "                i+=1\n",
    "            y = passive_y[:,idx1:idx2,:]\n",
    "\n",
    "            lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)})\n",
    "            X_reshaped = X.reshape((X.shape[0]*X.shape[1]),X.shape[2])\n",
    "            y_reshaped = y.reshape((y.shape[0]*y.shape[1]),y.shape[2])\n",
    "            lr_all.fit(X_reshaped, y_reshaped)\n",
    "            print(lr_all.best_params_['alpha'])\n",
    "\n",
    "            kf = KFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "            true_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "            pred_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "            trial_save_idx = 0\n",
    "            for training_set, test_set in kf.split(range(0,n_trials)):\n",
    "                #split training and testing by trials\n",
    "                X_train, X_test, y_train, y_test = process_train_test(X,y,training_set,test_set)\n",
    "                lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)}) \n",
    "                lr.fit(X_train, y_train)\n",
    "                y_test_predicted = lr.predict(X_test)\n",
    "                n = y_test_predicted.shape[0]\n",
    "                true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "                pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "                trial_save_idx += n\n",
    "\n",
    "            sses =get_sses_pred(true_concat,pred_concat)\n",
    "            sses_mean=get_sses_mean(true_concat)\n",
    "            multi_R2s[j,k] =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "            print('R2:',multi_R2s[j,k])\n",
    "            coef_arr.append(lr_all.best_estimator_.coef_)\n",
    "            k += 1\n",
    "        j += 1\n",
    "        k = 0\n",
    "        multi_coefs.append(coef_arr)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(multi_R2s)\n",
    "    ax.set_xlabel('Length of lagging info')\n",
    "    ax.set_ylabel('Length of leading info')\n",
    "\n",
    "    ax.set_xticks(np.arange(len(t_after_range)))\n",
    "    ax.set_yticks(np.arange(len(t_before_range)))\n",
    "    ax.set_xticklabels(labels=t_after_range)\n",
    "    ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "    ax.set_title('R2 predicting ' + str(pred_range) + ' ' + y_type +'\\nwith different lagging/leading info')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for i in range(len(t_before_range)):\n",
    "        for j in range(len(t_after_range)):\n",
    "            text = ax.text(j, i, str(int(multi_R2s[i, j]*1000)/1000),\n",
    "                           ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + '_multi_' + label + '.png', dpi = 'figure')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8958e911",
   "metadata": {},
   "source": [
    "## with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7170769",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_range = [-400,700]\n",
    "figDir = \"/Users/sherryan/area2_population_analysis/figures/PCA/pas/\"\n",
    "passive_x = passive_trials_pca\n",
    "passive_y = passive_trials_acc\n",
    "y_type = 'acceleration'\n",
    "\n",
    "ranges = [(0,120),(-100,120)]\n",
    "labels = ['early_acc','long_acc']\n",
    "\n",
    "dim = n_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred_range, label in zip(ranges, labels):\n",
    "\n",
    "    idx1 = int((pred_range[0] - data_range[0])/dataset_50ms.bin_width)\n",
    "    idx2 = int(n_timepoints - (data_range[1]-pred_range[1])/dataset_50ms.bin_width)\n",
    "\n",
    "    t_before_range = range(0,301,50);\n",
    "    t_after_range = range(0,501,50);\n",
    "\n",
    "    multi_R2s = nans([len(t_before_range),len(t_after_range)])\n",
    "    multi_coefs = []\n",
    "    j,k=0,0\n",
    "    for time_before in t_before_range:\n",
    "        coef_arr = []\n",
    "        for time_after in t_after_range:\n",
    "            print('Predicting with',-time_before, 'to', time_after,'ms neural data')\n",
    "\n",
    "            bins_before= int(time_before/dataset_50ms.bin_width) #How many bins of neural data prior to the output are used for decoding\n",
    "            bins_current= 1 #Whether to use concurrent time bin of neural data\n",
    "            bins_after= int(time_after/dataset_50ms.bin_width) #How many bins of neural data after the output are used for decoding\n",
    "\n",
    "            n_total_bins = bins_before + bins_current + bins_after\n",
    "\n",
    "            X =  nans([n_trials,idx2-idx1,n_total_bins*dim])\n",
    "            i = 0\n",
    "            for trial_data in passive_x:\n",
    "                trial_hist=get_spikes_with_history(trial_data,bins_before,bins_after,bins_current)\n",
    "                trial_hist = trial_hist[idx1:idx2,:,:]\n",
    "                trial_hist_flat=trial_hist.reshape(trial_hist.shape[0],(trial_hist.shape[1]*trial_hist.shape[2]))\n",
    "                X[i,:,:] = trial_hist_flat\n",
    "                i+=1\n",
    "            y = passive_y[:,idx1:idx2,:]\n",
    "\n",
    "            lr_all = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)})\n",
    "            X_reshaped = X.reshape((X.shape[0]*X.shape[1]),X.shape[2])\n",
    "            y_reshaped = y.reshape((y.shape[0]*y.shape[1]),y.shape[2])\n",
    "            lr_all.fit(X_reshaped, y_reshaped)\n",
    "            print(lr_all.best_params_['alpha'])\n",
    "\n",
    "            kf = KFold(n_splits=5,shuffle=True,random_state = 42)   \n",
    "            true_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "            pred_concat = nans([(n_trials*(idx2-idx1)),2])\n",
    "            trial_save_idx = 0\n",
    "            for training_set, test_set in kf.split(range(0,n_trials)):\n",
    "                #split training and testing by trials\n",
    "                X_train, X_test, y_train, y_test = process_train_test(X,y,training_set,test_set)\n",
    "                lr = GridSearchCV(Ridge(), {'alpha': np.logspace(-4, 4, 9)}) \n",
    "                lr.fit(X_train, y_train)\n",
    "                y_test_predicted = lr.predict(X_test)\n",
    "                n = y_test_predicted.shape[0]\n",
    "                true_concat[trial_save_idx:trial_save_idx+n,:] = y_test\n",
    "                pred_concat[trial_save_idx:trial_save_idx+n,:] = y_test_predicted\n",
    "                trial_save_idx += n\n",
    "\n",
    "            sses =get_sses_pred(true_concat,pred_concat)\n",
    "            sses_mean=get_sses_mean(true_concat)\n",
    "            multi_R2s[j,k] =1-np.sum(sses)/np.sum(sses_mean)     \n",
    "            print('R2:',multi_R2s[j,k])\n",
    "            coef_arr.append(lr_all.best_estimator_.coef_)\n",
    "            k += 1\n",
    "        j += 1\n",
    "        k = 0\n",
    "        multi_coefs.append(coef_arr)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(multi_R2s)\n",
    "    ax.set_xlabel('Length of lagging info')\n",
    "    ax.set_ylabel('Length of leading info')\n",
    "\n",
    "    ax.set_xticks(np.arange(len(t_after_range)))\n",
    "    ax.set_yticks(np.arange(len(t_before_range)))\n",
    "    ax.set_xticklabels(labels=t_after_range)\n",
    "    ax.set_yticklabels(labels=t_before_range)\n",
    "\n",
    "    ax.set_title('R2 predicting ' + str(pred_range) + ' ' + y_type +'\\nwith different lagging/leading info')\n",
    "    fig.tight_layout()\n",
    "\n",
    "    for i in range(len(t_before_range)):\n",
    "        for j in range(len(t_after_range)):\n",
    "            text = ax.text(j, i, str(int(multi_R2s[i, j]*1000)/1000),\n",
    "                           ha=\"center\", va=\"center\", color=\"w\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figDir + monkey + '_multi_' + label + '.png', dpi = 'figure')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
